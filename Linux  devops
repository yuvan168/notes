# Linux Complete Notes with Theory

## Table of Contents
1. [Introduction to Linux](#introduction-to-linux)
2. [Linux File System](#linux-file-system)
3. [File Permissions](#file-permissions)
4. [Command Line Interface](#command-line-interface)
5. [Users and Groups](#users-and-groups)
6. [Processes and Services](#processes-and-services)
7. [Package Management](#package-management)
8. [Networking](#networking)
9. [Shell Scripting](#shell-scripting)
10. [System Administration](#system-administration)
11. [Security](#security)
12. [Monitoring and Performance](#monitoring-and-performance)
13. [Advanced Topics](#advanced-topics)
14. [Practical Applications](#practical-applications)
15. [Interview Questions](#interview-questions)

---

## Introduction to Linux

### What is Linux?

Linux is a free, open-source operating system kernel created by Linus Torvalds in 1991. It manages hardware resources and allows programs to run.

**Key Characteristics:**
- **Open Source**: Source code freely available
- **Multi-user**: Multiple users can use simultaneously
- **Multitasking**: Multiple processes run concurrently
- **Portable**: Runs on various hardware platforms
- **Secure**: Strong security features and permissions
- **Stable**: Can run for years without restart
- **Lightweight**: Efficient resource utilization

### Linux Distributions

**Major Distributions:**

1. **Debian-based:**
   - Ubuntu (Most popular)
   - Linux Mint
   - Pop!_OS
   - Elementary OS

2. **Red Hat-based:**
   - CentOS
   - Fedora
   - RHEL (Red Hat Enterprise Linux)
   - AlmaLinux

3. **Arch-based:**
   - Arch Linux
   - Manjaro
   - EndeavourOS

4. **Independent:**
   - Slackware
   - Gentoo
   - openSUSE

### Kernel vs. Distribution

```
┌─────────────────────────────────────┐
│   Distribution (Ubuntu, CentOS)     │
│  - Package manager                  │
│  - Tools and utilities              │
│  - Desktop environment              │
├─────────────────────────────────────┤
│   Linux Kernel                      │
│  - Hardware management              │
│  - Process scheduling               │
│  - Memory management                │
│  - I/O operations                   │
├─────────────────────────────────────┤
│   Hardware (CPU, RAM, Disk)         │
└─────────────────────────────────────┘
```

### History and Philosophy

**Timeline:**
- **1969**: Unix created at AT&T Bell Labs
- **1983**: GNU Project started
- **1991**: Linux kernel created by Linus Torvalds
- **1992**: GNU/Linux combination
- **1994**: Linux version 1.0
- **2003**: Ubuntu first released
- **Present**: Linux dominates servers (99% of supercomputers)

**Linux Philosophy:**
1. Small, modular programs
2. Do one thing well
3. Unix pipes for composition
4. Text-based configuration
5. Open source collaboration

---

## Linux File System

### File System Hierarchy

```
/ (Root)
├── /bin               → Essential user command binaries
├── /sbin              → System administration binaries
├── /lib               → System libraries
├── /usr               → User programs and data
│   ├── /usr/bin       → User binaries
│   ├── /usr/lib       → User libraries
│   ├── /usr/local     → Locally installed software
│   └── /usr/share     → Documentation and data
├── /home              → User home directories
│   └── /home/username → User's personal files
├── /root              → Root user's home directory
├── /etc               → System configuration files
├── /var               → Variable data (logs, temp)
│   ├── /var/log       → System and application logs
│   ├── /var/tmp       → Temporary files
│   └── /var/cache     → Cache files
├── /tmp               → Temporary files (cleared on reboot)
├── /boot              → Boot loader and kernel
├── /dev               → Device files
├── /proc              → Process and system information
├── /sys               → System hardware information
├── /opt               → Optional software packages
├── /srv               → Service data
└── /media             → Removable media mount points
```

### File Types

```bash
- (regular file)       Text or binary file
d (directory)          Folder containing files
l (symbolic link)      Pointer to another file
c (character device)   Raw device (terminal, USB)
b (block device)       Block device (disk, USB)
s (socket)             Inter-process communication
p (pipe/FIFO)          Named pipe for data transfer
```

### Inodes

**Concept:** Inode = Index Node, stores file metadata

```
Inode Structure:
┌─────────────────────────────┐
│ Inode Number: 12345         │
│ File Type: Regular File     │
│ Permissions: 644            │
│ Owner UID: 1000             │
│ Group GID: 1000             │
│ File Size: 4096 bytes       │
│ Created Time: 2025-12-24    │
│ Modified Time: 2025-12-24   │
│ Accessed Time: 2025-12-24   │
│ Data Block Pointers: [...]  │
└─────────────────────────────┘
```

**Key Points:**
- Filename NOT stored in inode
- Inode linked to filename in directory
- Multiple filenames can point to same inode (hard links)
- Deleting filename removes link, inode freed when links = 0

### File Paths

**Absolute Path:** Starts from root (/)
```bash
/home/user/documents/file.txt
```

**Relative Path:** Relative to current directory
```bash
documents/file.txt
../file.txt
./documents/file.txt
```

**Special Path References:**
```bash
~          Home directory (~user = user's home)
.          Current directory
..         Parent directory
-          Previous directory (for cd command)
```

---

## File Permissions

### Permission Structure

```
-rw-r--r-- 1 user group 4096 Dec 24 10:30 file.txt
││││││││││ │ │    │     │    │   │  │  │   │
││││││││││ │ │    │     │    │   │  │  │   └─ Filename
││││││││││ │ │    │     │    │   │  │  └───── Time
││││││││││ │ │    │     │    │   │  └──────── Day
││││││││││ │ │    │     │    │   └─────────── Month
││││││││││ │ │    │     │    └────────────── File size
││││││││││ │ │    │     └──────────────────── Date
││││││││││ │ │    └──────────────────────────── Group name
││││││││││ │ └────────────────────────────────── Owner name
││││││││││ └──────────────────────────────────── Link count
││├─┤├─┤├─┤
││ │ │ │ └────────────────────────── Others permissions
││ │ └───────────────────────────── Group permissions
││ └──────────────────────────────── Owner permissions
└┴────────────────────────────────── File type
```

### Permission Bits

```
rwx = 111 (binary) = 7 (decimal) = Full permissions
rw- = 110 (binary) = 6 (decimal) = Read + Write
r-x = 101 (binary) = 5 (decimal) = Read + Execute
r-- = 100 (binary) = 4 (decimal) = Read only
-wx = 011 (binary) = 3 (decimal) = Write + Execute
-w- = 010 (binary) = 2 (decimal) = Write only
--x = 001 (binary) = 1 (decimal) = Execute only
--- = 000 (binary) = 0 (decimal) = No permissions
```

**Permission Examples:**
```bash
755 = rwxr-xr-x  (File executable by owner, readable by all)
644 = rw-r--r--  (File readable/writable by owner, readable by all)
700 = rwx------  (Only owner can access)
777 = rwxrwxrwx  (Everyone can do everything)
```

### Special Permissions

**Setuid (Set User ID):**
```bash
chmod u+s file
# File executes with owner's permissions
# Example: passwd command runs with root permissions
```

**Setgid (Set Group ID):**
```bash
chmod g+s directory
# Files created in directory inherit group ownership
```

**Sticky Bit:**
```bash
chmod +t directory
# Only owner can delete files (used for /tmp)
```

### Changing Permissions

```bash
# Symbolic method
chmod u+rwx file           # Add permissions to owner
chmod g-w file             # Remove write from group
chmod o=rx file            # Set others to read+execute
chmod a-x file             # Remove execute from all

# Numeric method
chmod 755 file             # rwxr-xr-x
chmod 644 file             # rw-r--r--
chmod 700 directory        # rwx------

# Recursive
chmod -R 755 directory/    # Apply to all files/subdirs

# Changing ownership
chown user file            # Change owner
chown user:group file      # Change owner and group
chown -R user:group dir/   # Recursive change
```

---

## Command Line Interface

### Basic Commands

**Navigation:**
```bash
pwd                        # Print working directory
cd /path/to/dir           # Change directory
cd ~                      # Go to home directory
cd ..                     # Go to parent directory
cd -                      # Go to previous directory
ls                        # List files
ls -la                    # List with details and hidden
tree                      # Show directory tree
```

**File Operations:**
```bash
touch file.txt            # Create empty file
cat file.txt              # Display file contents
less file.txt             # View with pagination
head -n 20 file.txt       # Show first 20 lines
tail -n 20 file.txt       # Show last 20 lines
tail -f file.txt          # Follow file (realtime)

cp source dest            # Copy file
cp -r dir1 dir2           # Copy directory recursively
mv source dest            # Move/rename file
rm file                   # Delete file
rm -r directory           # Delete directory recursively
rm -f file                # Force delete

mkdir directory           # Create directory
mkdir -p a/b/c            # Create nested directories
rmdir directory           # Remove empty directory
```

**File Search:**
```bash
find /path -name "*.txt"             # Find by name
find /path -type f                   # Find files only
find /path -size +10M                # Find larger than 10MB
find /path -mtime -7                 # Modified in last 7 days
find /path -user username            # Find files owned by user

locate filename                      # Fast search (uses database)
which command                        # Find command location
whereis command                      # Find command/source/manual
```

**Text Processing:**
```bash
grep "pattern" file           # Search for pattern
grep -r "pattern" dir/        # Search recursively
grep -c "pattern" file        # Count matches
grep -v "pattern" file        # Inverse match

sed 's/old/new/' file         # Replace first occurrence per line
sed 's/old/new/g' file        # Replace all occurrences
sed -i 's/old/new/g' file     # In-place edit

awk '{print $1}' file         # Print first column
awk -F: '{print $1}' /etc/passwd  # Use : as separator

sort file                     # Sort lines
sort -r file                  # Sort reverse
sort -n file                  # Numeric sort
uniq file                     # Remove duplicate lines
```

**File Comparison:**
```bash
diff file1 file2             # Show differences
diff -u file1 file2          # Unified format
cmp file1 file2              # Compare byte by byte
```

### Piping and Redirection

**Redirection:**
```bash
command > file           # Redirect stdout to file (overwrite)
command >> file          # Redirect stdout to file (append)
command < file           # Redirect stdin from file
command 2> error.log     # Redirect stderr to file
command &> combined.log  # Redirect stdout and stderr
command > /dev/null      # Discard output
```

**Piping:**
```bash
command1 | command2      # Send stdout of command1 to command2

# Examples
cat file.txt | grep "pattern" | sort | uniq
ps aux | grep process | grep -v grep
find . -name "*.txt" | xargs wc -l
```

**Command Substitution:**
```bash
$(command)               # Execute command and use output
`command`                # Backtick version (older)

# Example
echo "Files: $(ls -1 | wc -l)"
```

### Wildcards and Globbing

```bash
*              Any characters (0 or more)
?              Single character
[abc]          Any character in brackets
[a-z]          Any character in range
[!abc]         Any character NOT in brackets
{a,b,c}        Alternation

# Examples
ls *.txt                 # All .txt files
rm file?.txt             # file1.txt, file2.txt, etc.
cp dir[123]/* backup/    # Copy from dir1, dir2, dir3
```

### Useful Command Combinations

**Count lines in files:**
```bash
wc -l *.txt
find . -name "*.py" | xargs wc -l
```

**Search and replace in multiple files:**
```bash
find . -name "*.txt" -exec sed -i 's/old/new/g' {} \;
```

**List files by size:**
```bash
du -sh * | sort -h
ls -lS      # Sort by file size
```

**Find large files:**
```bash
find . -type f -size +100M -exec ls -lh {} \;
```

---

## Users and Groups

### User Management

**User File Structure:**
```bash
# /etc/passwd format
username:password:uid:gid:fullname:homedirectory:shell

# Example
john:x:1000:1000:John Doe:/home/john:/bin/bash
root:x:0:0:root:/root:/bin/bash
```

**Create Users:**
```bash
useradd username                    # Create user
useradd -m username                 # Create with home directory
useradd -m -s /bin/bash username    # Specify shell
useradd -m -u 1500 username         # Specify UID
useradd -m -G sudo,docker user      # Add to groups

userdel username                    # Delete user
userdel -r username                 # Delete with home directory
```

**Modify Users:**
```bash
usermod -aG group username          # Add to group
usermod -aG sudo,docker user        # Add to multiple groups
usermod -s /bin/zsh username        # Change shell
usermod -d /new/home user           # Change home directory
usermod -l newname oldname          # Rename user
passwd username                     # Change password
passwd -l username                  # Lock user
passwd -u username                  # Unlock user
```

**Switch Users:**
```bash
su - username                       # Switch with login shell
su username                         # Switch without login shell
sudo command                        # Run as root/sudo user
sudo -i                            # Interactive root shell
sudo -u username command            # Run as specific user
```

### Group Management

**Group File Structure:**
```bash
# /etc/group format
groupname:password:gid:members

# Example
sudo:x:27:john,alice
docker:x:999:john
```

**Group Operations:**
```bash
groupadd groupname                  # Create group
groupadd -g 1500 groupname          # Specify GID
groupdel groupname                  # Delete group

# Add user to group
usermod -aG groupname username

# Remove user from group
delgroup username groupname

# Check groups
groups username                     # Show groups for user
id username                        # Show user and groups info
```

**Sudo Configuration:**
```bash
# /etc/sudoers (edit with visudo)
username ALL=(ALL) ALL              # Full sudo access
username ALL=(ALL) NOPASSWD: ALL    # No password required
%groupname ALL=(ALL) ALL            # All users in group

# Specific commands
user1 ALL=/usr/bin/restart          # Only restart command
user1 ALL=/usr/bin/restart, /usr/bin/stop
```

---

## Processes and Services

### Process Basics

**Process Information:**
```bash
ps                 # Currently running processes
ps aux             # All processes with details
ps aux | grep command  # Find specific process
top                # Real-time process monitor
htop               # Enhanced top (if installed)

# Show process tree
pstree
pstree -p          # With process IDs
```

**Process Control:**
```bash
# Run process
command                              # Run in foreground
command &                            # Run in background
nohup command &                      # Run immune to hangups

# Job control
jobs                                # List background jobs
bg %1                               # Resume job 1 in background
fg %1                               # Bring job 1 to foreground
ctrl+z                              # Suspend current process
```

**Signal Processes:**
```bash
kill PID                            # Kill process (SIGTERM)
kill -9 PID                         # Force kill (SIGKILL)
kill -STOP PID                      # Pause process
kill -CONT PID                      # Resume process

killall processname                 # Kill by name
pkill -f "pattern"                  # Kill by pattern
```

### Services and Daemons

**Systemd (Modern Linux):**
```bash
# Service management
systemctl start service             # Start service
systemctl stop service              # Stop service
systemctl restart service           # Restart service
systemctl reload service            # Reload configuration
systemctl status service            # Check status

# Enable/disable at boot
systemctl enable service            # Enable at boot
systemctl disable service           # Disable at boot
systemctl is-enabled service        # Check if enabled

# List services
systemctl list-units --type=service
systemctl list-units --type=service --state=running
systemctl list-units --type=service --state=failed
```

**Service Files (Systemd):**
```bash
# Location
/etc/systemd/system/
/lib/systemd/system/

# Example: /etc/systemd/system/myapp.service
[Unit]
Description=My Application
After=network.target

[Service]
Type=simple
User=appuser
WorkingDirectory=/opt/myapp
ExecStart=/opt/myapp/run.sh
Restart=on-failure
RestartSec=10

[Install]
WantedBy=multi-user.target
```

**Service Commands:**
```bash
systemctl daemon-reload             # Reload service files
systemctl enable service            # Enable service
systemctl start service             # Start service
systemctl status service            # Check status
systemctl restart service           # Restart service
journalctl -u service               # View service logs
journalctl -u service -f            # Follow logs
```

### Cron and Scheduling

**Crontab Format:**
```bash
# Crontab entry format
# minute hour day month dayofweek command
# (0-59)  (0-23) (1-31) (1-12)  (0-6, 0=Sun)

# Examples
0 2 * * *       /path/to/backup.sh      # 2:00 AM daily
30 12 * * 1-5   /path/to/cleanup.sh     # 12:30 PM weekdays
0 0 1 * *       /path/to/monthly.sh     # 1st day of month
*/15 * * * *    /path/to/frequent.sh    # Every 15 minutes

# Special shortcuts
@reboot         /path/to/startup.sh     # At boot
@hourly         /path/to/command.sh     # Every hour
@daily          /path/to/command.sh     # Every day
@weekly         /path/to/command.sh     # Every week
@monthly        /path/to/command.sh     # Every month
```

**Crontab Management:**
```bash
crontab -e                          # Edit crontab
crontab -l                          # List crontab
crontab -r                          # Remove crontab
crontab -i                          # Interactive remove

# System crontab
/etc/crontab                        # System-wide crontab
/etc/cron.d/                        # Additional system cron jobs
/etc/cron.daily/                    # Daily scripts
/etc/cron.hourly/                   # Hourly scripts
/etc/cron.weekly/                   # Weekly scripts
/etc/cron.monthly/                  # Monthly scripts
```

---

## Package Management

### APT (Debian/Ubuntu)

**Basic Operations:**
```bash
apt update                          # Update package list
apt install package                # Install package
apt remove package                 # Remove package
apt autoremove                      # Remove unused packages
apt upgrade                         # Upgrade packages
apt full-upgrade                    # Full system upgrade

apt search keyword                  # Search packages
apt show package                    # Show package info
apt list --installed                # List installed packages
```

**Advanced APT:**
```bash
apt install package=version         # Install specific version
apt-cache search keyword            # Search packages
apt-cache show package              # Show package details
apt-cache depends package           # Show dependencies
apt-cache rdepends package          # Show reverse dependencies

# Sources management
/etc/apt/sources.list                # Primary sources
/etc/apt/sources.list.d/             # Additional sources
apt-add-repository ppa:user/ppa      # Add PPA
apt-key adv --keyserver ... --recv-keys KEYID  # Add key
```

### YUM/DNF (Red Hat/CentOS/Fedora)

**Basic Operations:**
```bash
yum check-update                    # Check for updates
yum install package                 # Install package
yum remove package                  # Remove package
yum update                          # Update packages
yum update-to package               # Update to specific package

yum search keyword                  # Search packages
yum info package                    # Show package info
yum list installed                  # List installed packages
```

**Advanced YUM:**
```bash
yum install /path/to/package.rpm    # Install local RPM
yum localinstall package.rpm        # Install local RPM
yum groupinstall "Group Name"       # Install group
yum repolist                        # List repositories
yum-config-manager --add-repo url   # Add repository
```

### Pacman (Arch Linux)

```bash
pacman -Sy                          # Sync database
pacman -Su                          # Update packages
pacman -Syu                         # Sync and update

pacman -S package                   # Install package
pacman -R package                   # Remove package
pacman -Rs package                  # Remove with dependencies

pacman -Q                           # List installed packages
pacman -Ss keyword                  # Search packages
```

---

## Networking

### Network Configuration

**Network Interfaces:**
```bash
ip addr show                        # Show IP addresses
ip link show                        # Show network interfaces
ifconfig                           # Show interface config (deprecated)

# Static IP configuration
/etc/netplan/01-netcfg.yaml
network:
  version: 2
  renderer: networkd
  ethernets:
    eth0:
      dhcp4: no
      addresses:
        - 192.168.1.100/24
      gateway4: 192.168.1.1
      nameservers:
        addresses: [8.8.8.8, 8.8.4.4]
```

**Temporary Network Configuration:**
```bash
ip addr add 192.168.1.100/24 dev eth0      # Add IP
ip addr del 192.168.1.100/24 dev eth0      # Remove IP
ip link set eth0 up                        # Bring interface up
ip link set eth0 down                      # Bring interface down
ip route add 192.168.2.0/24 via 192.168.1.1  # Add route
```

### DNS Configuration

```bash
# /etc/resolv.conf (automatic with DHCP)
nameserver 8.8.8.8
nameserver 8.8.4.4

# Check DNS
nslookup google.com
dig google.com
host google.com
getent hosts google.com
```

### Network Commands

**Testing Connectivity:**
```bash
ping google.com                     # Test reachability
traceroute google.com               # Trace route
mtr google.com                      # Continuous trace route
netstat -tuln                       # Show listening ports
ss -tuln                           # Modern netstat
```

**DNS and HTTP:**
```bash
curl http://example.com             # Fetch URL
curl -O http://example.com/file     # Download file
wget http://example.com/file        # Download with wget
nslookup domain                     # DNS lookup
dig domain                          # DNS query details
whois domain                        # Domain info
```

**Firewall (UFW):**
```bash
sudo ufw enable                     # Enable firewall
sudo ufw disable                    # Disable firewall
sudo ufw status                     # Show status

sudo ufw allow 22                   # Allow port 22
sudo ufw allow ssh                  # Allow SSH
sudo ufw deny 23                    # Deny port 23
sudo ufw delete allow 22            # Delete rule
sudo ufw allow from 192.168.1.0/24  # Allow from subnet
```

**Firewall (iptables):**
```bash
# View rules
iptables -L                         # List rules
iptables -L -n                      # List with IPs
iptables -L -n -v                   # Verbose

# Add rules
iptables -A INPUT -p tcp --dport 22 -j ACCEPT
iptables -A INPUT -p tcp --dport 80 -j ACCEPT
iptables -A INPUT -j DROP

# Save rules
iptables-save > /etc/iptables.rules
iptables-restore < /etc/iptables.rules
```

---

## Shell Scripting

### Shell Basics

**Shebang:**
```bash
#!/bin/bash
# Makes script executable by OS
```

**Variables:**
```bash
name="value"                        # Assign variable
echo $name                          # Access variable
echo ${name}                        # Safe access

# Built-in variables
$0      Current script name
$1-$9   Arguments 1-9
$@      All arguments
$#      Number of arguments
$?      Exit code of last command
$$      Process ID of script
$!      Process ID of last background process
```

**String Operations:**
```bash
${var}           Variable value
${var:-default}  Default if unset
${var:=default}  Set default if unset
${var:?error}    Error if unset
${var#pattern}   Remove prefix
${var%pattern}   Remove suffix
${var/old/new}   Replace first occurrence
${var//old/new}  Replace all occurrences
${#var}          Length of variable
```

### Control Flow

**Conditionals:**
```bash
# if statement
if [ condition ]; then
    echo "true"
elif [ condition ]; then
    echo "elif"
else
    echo "false"
fi

# Ternary-like
[ condition ] && echo "true" || echo "false"

# case statement
case $var in
    pattern1)
        echo "match 1"
        ;;
    pattern2|pattern3)
        echo "match 2 or 3"
        ;;
    *)
        echo "no match"
        ;;
esac
```

**Test Conditions:**
```bash
# String conditions
[ -z "$var" ]           # Empty string
[ -n "$var" ]           # Non-empty string
[ "$var" = "value" ]    # String equality
[ "$var" != "value" ]   # String inequality
[ "$var1" < "$var2" ]   # String comparison

# Numeric conditions
[ $num -eq 0 ]          # Equal
[ $num -ne 0 ]          # Not equal
[ $num -lt 10 ]         # Less than
[ $num -le 10 ]         # Less than or equal
[ $num -gt 10 ]         # Greater than
[ $num -ge 10 ]         # Greater than or equal

# File conditions
[ -f $file ]            # File exists and is regular
[ -d $file ]            # File exists and is directory
[ -r $file ]            # File readable
[ -w $file ]            # File writable
[ -x $file ]            # File executable
[ -s $file ]            # File exists and non-empty
```

**Loops:**
```bash
# for loop
for i in 1 2 3 4 5; do
    echo $i
done

for i in $(seq 1 10); do
    echo $i
done

for ((i=1; i<=10; i++)); do
    echo $i
done

# while loop
while [ $count -lt 10 ]; do
    echo $count
    ((count++))
done

# until loop
until [ $count -ge 10 ]; do
    echo $count
    ((count++))
done

# for loop over files
for file in *.txt; do
    echo "Processing $file"
done
```

### Functions

```bash
# Define function
function greet() {
    echo "Hello, $1"
}

# Or without function keyword
greet() {
    echo "Hello, $1"
}

# Call function
greet "World"

# Return value
get_sum() {
    local sum=$(($1 + $2))
    echo $sum        # This is the return value
}

result=$(get_sum 5 10)
echo $result    # 15

# Local variables
my_function() {
    local var="local scope"
    global_var="global scope"
}
```

### Script Examples

**Example 1: Backup Script**
```bash
#!/bin/bash

SOURCE_DIR="/home/user/documents"
BACKUP_DIR="/backup"
DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="${BACKUP_DIR}/backup_${DATE}.tar.gz"

# Create backup
tar -czf "$BACKUP_FILE" "$SOURCE_DIR"

if [ $? -eq 0 ]; then
    echo "Backup successful: $BACKUP_FILE"
else
    echo "Backup failed!"
    exit 1
fi

# Remove backups older than 30 days
find "$BACKUP_DIR" -name "backup_*.tar.gz" -mtime +30 -delete
```

**Example 2: Log Rotation Script**
```bash
#!/bin/bash

LOGDIR="/var/log/myapp"
LOGFILE="$LOGDIR/app.log"
MAXSIZE=$((10 * 1024 * 1024))  # 10MB

if [ -f "$LOGFILE" ]; then
    SIZE=$(stat -f%z "$LOGFILE" 2>/dev/null || stat -c%s "$LOGFILE")
    
    if [ $SIZE -gt $MAXSIZE ]; then
        TIMESTAMP=$(date +%Y%m%d_%H%M%S)
        mv "$LOGFILE" "$LOGFILE.$TIMESTAMP"
        gzip "$LOGFILE.$TIMESTAMP"
        touch "$LOGFILE"
        echo "Log rotated to $LOGFILE.$TIMESTAMP.gz"
    fi
fi
```

---

## System Administration

### System Information

```bash
uname -a                           # System information
lsb_release -a                     # Distribution info
hostnamectl                        # Hostname info
timedatectl                        # Time and date info
systemd-analyze                    # System startup time

# Hardware info
lscpu                              # CPU information
free -h                            # Memory info
df -h                              # Disk space
du -sh /path                       # Directory size
lsblk                              # Block devices
hwinfo                             # Full hardware info
```

### Disk and Storage

**Mounting:**
```bash
mount                              # Show mounted filesystems
mount /dev/sda1 /mnt/point        # Mount filesystem
umount /mnt/point                  # Unmount filesystem

# Persistent mounts (/etc/fstab)
/dev/sda1  /mnt/data  ext4  defaults  0  0
# device    mount     type  options   dump pass
```

**Filesystem Operations:**
```bash
mkfs.ext4 /dev/sda1                # Format filesystem
fsck /dev/sda1                     # Check filesystem
e2fsck /dev/sda1                   # Extended check
tune2fs -l /dev/sda1               # Show filesystem info

# Partitioning
fdisk /dev/sda                     # Interactive partition editor
parted /dev/sda                    # GNU parted (better interface)
gdisk /dev/sda                     # GPT partitioning
```

### User and Group Administration

```bash
# Quota management
quotaon /dev/sda1                  # Enable quotas
quotaoff /dev/sda1                 # Disable quotas
edquota -u username                # Edit user quota
quota username                     # Show user quota
```

### Log Management

**System Logs:**
```bash
# Systemd journal
journalctl                         # Show all logs
journalctl -n 50                   # Last 50 entries
journalctl -f                      # Follow logs (like tail -f)
journalctl -u service              # Logs for specific service
journalctl --since "2 hours ago"   # Logs from timeframe
journalctl -p err                  # Only error level

# Older syslog (/var/log/)
/var/log/syslog                    # System log
/var/log/auth.log                  # Authentication log
/var/log/kern.log                  # Kernel messages
tail -f /var/log/syslog            # Follow system log
```

**Logrotate:**
```bash
# /etc/logrotate.conf
/var/log/myapp/*.log {
    daily                          # Rotate daily
    rotate 7                       # Keep 7 days
    compress                       # Compress old logs
    delaycompress                  # Compress next day
    missingok                      # OK if missing
    notifempty                     # Don't rotate if empty
    create 0640 user group         # Create with permissions
    sharedscripts                  # Run scripts once
    postrotate                     # Script after rotation
        systemctl reload myapp
    endscript
}

logrotate /etc/logrotate.conf       # Run logrotate
logrotate -f /etc/logrotate.conf    # Force rotation
```

---

## Security

### SSH

**SSH Configuration:**
```bash
# SSH client
ssh user@host                      # Connect to host
ssh -p 2222 user@host             # Connect to custom port
ssh -i ~/.ssh/id_rsa user@host    # Use specific key
ssh -v user@host                   # Verbose output

# SSH server config (/etc/ssh/sshd_config)
Port 22
PermitRootLogin no
PubkeyAuthentication yes
PasswordAuthentication no
X11Forwarding no
PermitUserEnvironment no
MaxAuthTries 3
```

**Key Management:**
```bash
ssh-keygen -t rsa -b 4096 -f ~/.ssh/id_rsa
ssh-copy-id user@host              # Copy public key to host
ssh-add ~/.ssh/id_rsa              # Add key to agent
ssh-agent bash                     # Start SSH agent

chmod 600 ~/.ssh/id_rsa            # Private key permissions
chmod 644 ~/.ssh/id_rsa.pub        # Public key permissions
chmod 700 ~/.ssh                   # SSH directory permissions
```

### Sudo

**Sudoers Configuration:**
```bash
# Edit with visudo (safer)
visudo

# Examples
john ALL=(ALL) ALL                 # Full sudo
john ALL=(ALL) NOPASSWD: /usr/bin/restart
%admin ALL=(ALL) ALL               # All admin group
john host1=(root) /bin/ls          # Specific host/user/command
```

### Firewall

**UFW (Uncomplicated Firewall):**
```bash
ufw enable                         # Enable firewall
ufw status                         # Show status
ufw allow 22                       # Allow port
ufw allow ssh                      # Allow service
ufw deny 23                        # Deny port
ufw delete allow 22                # Delete rule
ufw reset                          # Reset to defaults

# Source-based rules
ufw allow from 192.168.1.0/24     # Allow subnet
ufw allow from 10.0.0.1           # Allow specific IP
ufw allow from 10.0.0.0/8 to any port 22  # Complex rule
```

### User Account Security

```bash
# Password policy (/etc/login.defs)
PASS_MAX_DAYS   90                 # Max password age
PASS_MIN_DAYS   1                  # Min before change
PASS_WARN_AGE   7                  # Warn days before

# Lock account
passwd -l username                 # Lock user
passwd -u username                 # Unlock user

# Force password change
chage -d 0 username                # Expire password
chage -M 90 username               # Max age 90 days
chage -W 7 username                # Warn 7 days

# Check password expiration
chage -l username
```

---

## Monitoring and Performance

### System Monitoring

```bash
top                                # Real-time monitoring
htop                               # Enhanced top
atop                               # All-inclusive monitoring

vmstat 1 5                         # Memory stats every 1s, 5 times
iostat 1 5                         # I/O stats
iotop                              # Top for disk I/O

# Load average
uptime                             # Show load average
cat /proc/loadavg
```

**Load Average:**
```
Load 1.5 on 4-core system:
- 1.5 / 4 = 37.5% CPU utilization
- Good: < number of cores
- Warning: >= number of cores
- Critical: >> number of cores
```

### Memory Management

```bash
free -h                            # Memory overview
free -h -s 1                       # Update every 1 second
ps aux | sort -k4 -rn | head -10  # Top 10 by memory
vmstat 1                           # Virtual memory stats

# Check swap
swapon -s                          # Show swap usage
swapon /dev/sda2                  # Enable swap
swapoff /dev/sda2                 # Disable swap
```

### CPU Monitoring

```bash
ps aux | sort -k3 -rn | head -10  # Top 10 by CPU
mpstat 1 5                         # Per-CPU stats
pidstat 1 5                        # Per-process CPU stats
```

### Disk Monitoring

```bash
df -h                              # Disk space usage
du -sh *                           # Directory sizes
du -sh .[^.]* *                    # Include hidden
iostat -x 1                        # Detailed I/O stats
iotop                              # I/O top process
lsof +D /                          # Open files on filesystem
```

### Network Monitoring

```bash
netstat -tuln                      # Listening ports
ss -tuln                          # Socket stats (newer)
netstat -tupn                      # With process info
iftop                              # Top for network traffic
nethogs                            # Network top per process
```

---

## Advanced Topics

### Container and Virtualization

**Docker:**
```bash
docker version                     # Docker info
docker run -d -p 80:8080 image    # Run container
docker ps                          # List running
docker ps -a                       # List all
docker stop container              # Stop container
docker rm container                # Remove container

docker images                      # List images
docker build -t tag .              # Build image
docker push tag                    # Push to registry
docker pull image                  # Pull from registry
```

**Virtual Machines:**
```bash
qemu-system-x86_64 disk.qcow2     # QEMU VM
kvm -m 1024 disk.img               # KVM VM
virsh list                         # List KVM VMs
virsh start vm-name                # Start VM
```

### LVM (Logical Volume Manager)

```bash
# Create physical volume
pvcreate /dev/sda1
pvs                                # List physical volumes

# Create volume group
vgcreate vg0 /dev/sda1
vgs                                # List volume groups

# Create logical volume
lvcreate -L 10G -n lv0 vg0
lvs                                # List logical volumes

# Extend logical volume
lvextend -L +5G /dev/vg0/lv0
resize2fs /dev/vg0/lv0             # Resize filesystem
```

### SELinux

```bash
getenforce                         # Current mode
setenforce 0                       # Set to permissive
setenforce 1                       # Set to enforcing

# Check file contexts
ls -Z
chcon -t type file                 # Change context

# Check policies
getsebool -a                       # List booleans
setsebool -P boolean on/off        # Set permanently
```

### AppArmor

```bash
aa-status                          # Show AppArmor status
aa-enforce /path/to/profile        # Enforce profile
aa-complain /path/to/profile       # Permissive mode
```

---

## Shell Scripting - Complete Concepts Explanation

### SECTION 1: BASIC SHELL SCRIPTING CONCEPTS

#### 1.1 Script Structure and Basics

**Concept:** Every shell script has a structure and execution model

**Script Template:**
```bash
#!/bin/bash
# Script description
# Author: Name
# Date: YYYY-MM-DD

# Enable strict mode (recommended)
set -euo pipefail

# Variable definitions
readonly CONFIG_DIR="/etc/myapp"
readonly LOG_FILE="/var/log/myapp.log"

# Function definitions
log_message() {
    echo "[$(date +'%Y-%m-%d %H:%M:%S')] $1" | tee -a "$LOG_FILE"
}

# Main script
main() {
    log_message "Script started"
    # Main logic here
    log_message "Script completed"
}

# Error handling
trap 'log_message "Error on line $LINENO"' ERR
trap 'log_message "Script interrupted"' INT

# Execute main
main "$@"
```

**Theory: Execution Model**

```
Script execution:
1. Interpreter reads shebang: #!/bin/bash
2. OS launches /bin/bash with script as argument
3. Bash reads script line by line
4. Commands executed sequentially
5. Variables expanded
6. Exit code returned
```

**Key Points:**
- `set -e`: Exit on error
- `set -u`: Error on undefined variable
- `set -o pipefail`: Pipe error propagation
- `trap`: Handle signals (errors, interrupts)

---

#### 1.2 Variables: Theory and Practice

**Concept:** Variables store data, can be expanded in commands

**Variable Types:**

```bash
# 1. User Variables (created by user)
name="John"
age=30
path="/home/user"

# 2. Environment Variables (system-wide)
export APP_ENV="production"
export DB_HOST="localhost"

# 3. Special Variables
$0     Script name
$1-$9  Positional arguments
$@     All arguments (array)
$#     Number of arguments
$?     Exit code of last command
$$     Process ID of script
$!     Process ID of last background job
$_     Last argument

# 4. Variable Scope
global_var="I'm global"    # Accessible everywhere

function_scope() {
    local local_var="I'm local"    # Only in this function
    echo $local_var
    echo $global_var              # Can access global
}
```

**Theory: Variable Expansion**

```bash
# Simple expansion
name="world"
echo "Hello, $name"              # Output: Hello, world

# Brace expansion (safer)
echo "Hello, ${name}"            # Same result
echo "${name}_backup"            # Prevents ambiguity

# Expansion with default
${var:-default}      # Use default if unset
${var:=default}      # Set and use default
${var:?error msg}    # Error if unset
${var:+value}        # Use value if set

# Example
config_file="${CONFIG_DIR}/app.conf"
backup_dir="${BACKUP_DIR:-/backup}"
app_name="${APP_NAME:?ERROR: APP_NAME not set}"
```

**Theory: Parameter Substitution**

```bash
filename="document.txt"

${filename#*.}        # Remove from start to dot: "txt"
${filename%.*}        # Remove dot to end: "document"
${filename/txt/md}    # Replace first: "document.md"
${filename//t/T}      # Replace all: "documenT.TxT"

# Remove directory path
path="/home/user/file.txt"
${path##*/}           # "file.txt" (remove longest path)

# Extract directory
${path%/*}            # "/home/user" (remove filename)
```

**String Operations Examples:**

```bash
#!/bin/bash

# Example 1: Validate input
validate_email() {
    local email="$1"
    
    # Check if contains @
    if [[ "$email" == *"@"* ]]; then
        echo "Valid email format"
    else
        echo "Invalid email"
        return 1
    fi
}

# Example 2: Extract parts
parse_url() {
    local url="$1"
    # URL: https://user:pass@host:port/path
    
    local protocol="${url%%://*}"           # https
    local after_protocol="${url#*://}"      # user:pass@host:port/path
    local host="${after_protocol%%/*}"      # user:pass@host:port
    local path="${url##*/}"                 # path
    
    echo "Protocol: $protocol"
    echo "Host: $host"
    echo "Path: $path"
}

# Example 3: String manipulation
convert_to_uppercase() {
    local input="$1"
    echo "${input^^}"      # Converts to uppercase (bash 4+)
}

convert_to_lowercase() {
    local input="$1"
    echo "${input,,}"      # Converts to lowercase (bash 4+)
}
```

---

#### 1.3 Arrays: Complete Guide

**Concept:** Arrays store multiple values indexed by position (or key for associative)

**Indexed Arrays:**

```bash
# Declaration
arr=(val1 val2 val3)
arr[0]="first"
arr[1]="second"

# Access
echo ${arr[0]}         # First element
echo ${arr[*]}         # All elements (string)
echo ${arr[@]}         # All elements (array)
echo ${#arr[@]}        # Array length

# Iteration
for element in "${arr[@]}"; do
    echo "$element"
done

# Add elements
arr+=(val4 val5)       # Append

# Slice
${arr[@]:1:2}          # Elements from index 1, length 2
```

**Associative Arrays (Hash Maps):**

```bash
#!/bin/bash

# Declaration
declare -A users
users[john]="30"
users[alice]="25"
users[bob]="35"

# Access
echo ${users[john]}         # "30"

# Iterate keys
for name in "${!users[@]}"; do
    echo "$name: ${users[$name]}"
done

# Check if key exists
if [[ -v users[john] ]]; then
    echo "John exists"
fi

# Example: Configuration parser
parse_config() {
    local config_file="$1"
    declare -A config
    
    while IFS='=' read -r key value; do
        [[ "$key" =~ ^[[:space:]]*# ]] && continue  # Skip comments
        [[ -z "$key" ]] && continue                 # Skip empty lines
        config["$key"]="$value"
    done < "$config_file"
    
    echo "${config[database_host]}"
    echo "${config[database_user]}"
}
```

**Array Processing Examples:**

```bash
#!/bin/bash

# Example 1: Filter array
filter_numbers() {
    local -a arr=("$@")
    local -a filtered=()
    
    for num in "${arr[@]}"; do
        if ((num > 50)); then
            filtered+=("$num")
        fi
    done
    
    echo "${filtered[@]}"
}

# Example 2: Remove duplicates
remove_duplicates() {
    local -a arr=("$@")
    printf '%s\n' "${arr[@]}" | sort -u
}

# Example 3: Join array elements
join_array() {
    local separator="$1"
    shift
    local -a arr=("$@")
    
    local result=""
    for i in "${!arr[@]}"; do
        result+="${arr[$i]}"
        if ((i < ${#arr[@]} - 1)); then
            result+="$separator"
        fi
    done
    
    echo "$result"
}

# Usage
result=$(join_array "," "${arr[@]}")
echo "$result"  # val1,val2,val3
```

---

### SECTION 2: CONTROL FLOW STRUCTURES

#### 2.1 Conditionals: Theory and Applications

**Concept:** Conditionals execute code based on conditions

**If-Elif-Else Structure:**

```bash
#!/bin/bash

# Basic if
if [ $age -ge 18 ]; then
    echo "Adult"
fi

# If-else
if [ $age -ge 18 ]; then
    echo "Adult"
else
    echo "Minor"
fi

# If-elif-else
if [ $age -lt 13 ]; then
    echo "Child"
elif [ $age -lt 18 ]; then
    echo "Teen"
else
    echo "Adult"
fi
```

**Test Conditions - Complete Reference:**

```bash
# String tests
-z "$str"           # String is empty
-n "$str"           # String is not empty
"$str1" = "$str2"   # Strings equal
"$str1" != "$str2"  # Strings not equal
"$str1" < "$str2"   # String1 less than string2 (lexicographic)
"$str1" > "$str2"   # String1 greater than string2

# Numeric tests
-eq     Equal
-ne     Not equal
-lt     Less than
-le     Less than or equal
-gt     Greater than
-ge     Greater than or equal

# File tests
-f      File exists and is regular file
-d      File exists and is directory
-L      File exists and is symbolic link
-r      File exists and is readable
-w      File exists and is writable
-x      File exists and is executable
-s      File exists and has size > 0
-e      File exists (any type)
-O      File owned by current user
-G      File owned by current group
file1 -nt file2  File1 newer than file2
file1 -ot file2  File1 older than file2

# Logical operators
! condition        # NOT
condition1 && condition2  # AND
condition1 || condition2  # OR
```

**Practical Examples:**

```bash
#!/bin/bash

# Example 1: File validation
validate_file() {
    local file="$1"
    
    if [ ! -e "$file" ]; then
        echo "Error: File does not exist"
        return 1
    fi
    
    if [ ! -r "$file" ]; then
        echo "Error: File not readable"
        return 1
    fi
    
    if [ ! -f "$file" ]; then
        echo "Error: Not a regular file"
        return 1
    fi
    
    echo "File validation passed"
    return 0
}

# Example 2: Complex conditions
check_service_health() {
    local service="$1"
    
    if systemctl is-active --quiet "$service"; then
        echo "Service is running"
        return 0
    elif systemctl is-enabled --quiet "$service"; then
        echo "Service is enabled but not running"
        return 2
    else
        echo "Service is not running and not enabled"
        return 1
    fi
}

# Example 3: Input validation
validate_input() {
    local input="$1"
    
    if [ -z "$input" ]; then
        echo "Error: Input is empty"
        return 1
    fi
    
    if ! [[ "$input" =~ ^[0-9]+$ ]]; then
        echo "Error: Input must be numeric"
        return 1
    fi
    
    if (( input < 0 || input > 100 )); then
        echo "Error: Input must be between 0 and 100"
        return 1
    fi
    
    echo "Valid input: $input"
    return 0
}
```

**Case Statement:**

```bash
#!/bin/bash

# Example 1: Command routing
case "$1" in
    start)
        systemctl start myservice
        ;;
    stop)
        systemctl stop myservice
        ;;
    restart)
        systemctl restart myservice
        ;;
    status)
        systemctl status myservice
        ;;
    *)
        echo "Usage: $0 {start|stop|restart|status}"
        exit 1
        ;;
esac

# Example 2: Pattern matching
check_file_type() {
    local file="$1"
    
    case "$file" in
        *.txt)
            echo "Text file"
            ;;
        *.py)
            echo "Python file"
            ;;
        *.sh)
            echo "Shell script"
            ;;
        *.jpg|*.png|*.gif)
            echo "Image file"
            ;;
        *)
            echo "Unknown type"
            ;;
    esac
}

# Example 3: OS detection
detect_os() {
    case "$(uname -s)" in
        Linux)
            echo "Linux"
            ;;
        Darwin)
            echo "macOS"
            ;;
        CYGWIN*|MINGW*|MSYS*)
            echo "Windows"
            ;;
        *)
            echo "Unknown"
            ;;
    esac
}
```

---

#### 2.2 Loops: Patterns and Best Practices

**Concept:** Loops execute code repeatedly, essential for batch processing

**For Loop Patterns:**

```bash
#!/bin/bash

# Pattern 1: Iterate over list
for item in apple banana cherry; do
    echo "Processing: $item"
done

# Pattern 2: Iterate over command output
for file in $(find . -name "*.log"); do
    echo "Found: $file"
done

# Pattern 3: Iterate with C-style syntax
for ((i=1; i<=5; i++)); do
    echo "Count: $i"
done

# Pattern 4: Iterate over array
arr=(1 2 3 4 5)
for element in "${arr[@]}"; do
    echo "Element: $element"
done

# Pattern 5: Process files
for file in /var/log/*.log; do
    if [ -f "$file" ]; then
        echo "Processing: $file"
    fi
done

# Pattern 6: Loop with index
for ((i=0; i<${#arr[@]}; i++)); do
    echo "Index $i: ${arr[$i]}"
done

# Pattern 7: Infinite loop
for ((;;)); do
    echo "Infinite loop (press Ctrl+C)"
    sleep 1
done
```

**While Loop Patterns:**

```bash
#!/bin/bash

# Pattern 1: Simple while
count=1
while [ $count -le 5 ]; do
    echo "Count: $count"
    ((count++))
done

# Pattern 2: Read file line by line
while IFS= read -r line; do
    echo "Line: $line"
done < input.txt

# Pattern 3: Process output
while read -r line; do
    echo "Processing: $line"
done < <(find . -name "*.txt")

# Pattern 4: Until (opposite of while)
count=1
until [ $count -gt 5 ]; do
    echo "Count: $count"
    ((count++))
done

# Pattern 5: Infinite loop with break
counter=0
while true; do
    ((counter++))
    echo "Iteration $counter"
    
    if ((counter >= 5)); then
        break
    fi
done

# Pattern 6: Nested loops with continue
for ((i=1; i<=3; i++)); do
    for ((j=1; j<=3; j++)); do
        if ((j == 2)); then
            continue    # Skip j=2
        fi
        echo "i=$i, j=$j"
    done
done
```

**Practical Loop Examples:**

```bash
#!/bin/bash

# Example 1: Batch file processing
process_files() {
    local source_dir="$1"
    local output_dir="$2"
    
    for file in "$source_dir"/*.jpg; do
        if [ -f "$file" ]; then
            filename=$(basename "$file")
            # Resize image (requires ImageMagick)
            convert "$file" -resize 800x600 \
                "$output_dir/thumb_$filename"
            echo "Processed: $filename"
        fi
    done
}

# Example 2: Monitor log files
monitor_logs() {
    local log_file="$1"
    local pattern="$2"
    
    # Process existing content
    while IFS= read -r line; do
        if [[ "$line" =~ $pattern ]]; then
            echo "Alert: $line"
        fi
    done < "$log_file"
    
    # Monitor new entries
    tail -f "$log_file" | while IFS= read -r line; do
        if [[ "$line" =~ $pattern ]]; then
            echo "Alert: $line"
        fi
    done
}

# Example 3: Retry mechanism
retry_command() {
    local max_attempts=3
    local timeout=5
    local attempt=1
    
    while ((attempt <= max_attempts)); do
        echo "Attempt $attempt of $max_attempts..."
        
        if timeout $timeout command_to_run; then
            echo "Success!"
            return 0
        fi
        
        ((attempt++))
        if ((attempt <= max_attempts)); then
            echo "Failed, retrying in 2 seconds..."
            sleep 2
        fi
    done
    
    echo "Command failed after $max_attempts attempts"
    return 1
}

# Example 4: Process lines from CSV
process_csv() {
    local csv_file="$1"
    
    # Skip header
    tail -n +2 "$csv_file" | while IFS=',' read -r name age email; do
        echo "Name: $name, Age: $age, Email: $email"
    done
}
```

---

### SECTION 3: FUNCTIONS AND MODULARITY

#### 3.1 Function Basics and Patterns

**Concept:** Functions encapsulate logic for reusability and maintainability

**Function Definition and Calling:**

```bash
#!/bin/bash

# Function definition (two styles)
function greet() {
    echo "Hello, $1!"
}

# Or without 'function' keyword
greet() {
    echo "Hello, $1!"
}

# Function call
greet "World"           # Output: Hello, World!
greet "Alice"           # Output: Hello, Alice!

# Return values
get_sum() {
    local result=$(($1 + $2))
    echo "$result"      # This is captured
}

sum=$(get_sum 5 10)
echo "Sum: $sum"        # Output: Sum: 15

# Exit codes
validate_number() {
    if [[ "$1" =~ ^[0-9]+$ ]]; then
        return 0        # Success
    else
        return 1        # Failure
    fi
}

if validate_number "123"; then
    echo "Valid number"
else
    echo "Invalid number"
fi
```

**Theory: Local vs Global Scope**

```bash
#!/bin/bash

# Global variable
GLOBAL_VAR="I'm global"

my_function() {
    # Local variable - only in this function
    local LOCAL_VAR="I'm local"
    
    # Can access global
    echo "$GLOBAL_VAR"
    
    # Modify local (doesn't affect function scope outside)
    LOCAL_VAR="Modified locally"
    
    # Modify global (affects everywhere)
    GLOBAL_VAR="Modified globally"
}

echo "$GLOBAL_VAR"           # "I'm global"
my_function
echo "$GLOBAL_VAR"           # "Modified globally"
echo "$LOCAL_VAR"            # "I'm local" (NOT "Modified locally")
```

**Practical Function Examples:**

```bash
#!/bin/bash

# Example 1: Logging function
log() {
    local level="$1"
    shift
    local message="$@"
    local timestamp=$(date '+%Y-%m-%d %H:%M:%S')
    
    case "$level" in
        INFO)
            echo "[$timestamp] INFO: $message"
            ;;
        ERROR)
            echo "[$timestamp] ERROR: $message" >&2
            ;;
        WARN)
            echo "[$timestamp] WARN: $message"
            ;;
        *)
            echo "[$timestamp] DEBUG: $message"
            ;;
    esac
}

log INFO "Application started"
log ERROR "Connection failed"
log WARN "High CPU usage detected"

# Example 2: Error handling wrapper
run_with_error_handling() {
    local command="$@"
    
    log INFO "Executing: $command"
    
    if ! eval "$command"; then
        log ERROR "Command failed: $command"
        return 1
    fi
    
    log INFO "Command succeeded"
    return 0
}

# Example 3: Configuration management
load_config() {
    local config_file="$1"
    
    if [ ! -f "$config_file" ]; then
        log ERROR "Config file not found: $config_file"
        return 1
    fi
    
    # Source the config file
    source "$config_file"
    
    log INFO "Configuration loaded from $config_file"
    return 0
}

# Example 4: Validation functions
validate_required() {
    local var_name="$1"
    local var_value="$2"
    
    if [ -z "$var_value" ]; then
        log ERROR "Required variable not set: $var_name"
        return 1
    fi
}

validate_file_exists() {
    local file="$1"
    
    if [ ! -f "$file" ]; then
        log ERROR "File not found: $file"
        return 1
    fi
}

validate_directory_exists() {
    local dir="$1"
    
    if [ ! -d "$dir" ]; then
        log ERROR "Directory not found: $dir"
        return 1
    fi
}

# Example 5: Cleanup function (run on exit)
cleanup() {
    log INFO "Running cleanup..."
    
    # Remove temporary files
    rm -f /tmp/myapp_*.tmp
    
    # Close connections
    # Stop services
    
    log INFO "Cleanup completed"
}

trap cleanup EXIT INT TERM
```

---

#### 3.2 Advanced Function Techniques

**Named Parameters Pattern:**

```bash
#!/bin/bash

# Pattern: Using named parameters instead of positional
backup_database() {
    local db_name=""
    local backup_path=""
    local compress=false
    
    # Parse arguments
    while (($#)); do
        case "$1" in
            --db-name)
                db_name="$2"
                shift 2
                ;;
            --backup-path)
                backup_path="$2"
                shift 2
                ;;
            --compress)
                compress=true
                shift
                ;;
            *)
                echo "Unknown option: $1"
                return 1
                ;;
        esac
    done
    
    # Validate
    if [ -z "$db_name" ] || [ -z "$backup_path" ]; then
        echo "Error: --db-name and --backup-path required"
        return 1
    fi
    
    # Create backup
    local timestamp=$(date +%Y%m%d_%H%M%S)
    local backup_file="$backup_path/${db_name}_${timestamp}.sql"
    
    pg_dump "$db_name" > "$backup_file"
    
    if [ "$compress" = true ]; then
        gzip "$backup_file"
        echo "Backup created: $backup_file.gz"
    else
        echo "Backup created: $backup_file"
    fi
}

# Usage
backup_database --db-name myapp --backup-path /backups --compress
```

**Output Capture and Processing:**

```bash
#!/bin/bash

# Capture output
get_file_count() {
    local dir="$1"
    find "$dir" -type f | wc -l
}

count=$(get_file_count /home/user)
echo "Total files: $count"

# Process multiple outputs
get_system_info() {
    echo "Linux"              # Line 1: OS
    echo "$(nproc)"           # Line 2: CPU cores
    echo "$(free -h | awk 'NR==2 {print $2}')"  # Line 3: Total RAM
}

# Read multiple outputs
read -r os cores ram <<< "$(get_system_info)"
echo "OS: $os"
echo "Cores: $cores"
echo "RAM: $ram"
```

---

### SECTION 4: PRACTICAL SHELL SCRIPTS

#### 4.1 System Monitoring Script

```bash
#!/bin/bash

# System Monitoring Script
# Monitors CPU, memory, disk, and provides alerts

set -euo pipefail

# Configuration
readonly LOG_FILE="/var/log/sysmon.log"
readonly ALERT_EMAIL="admin@example.com"
readonly CPU_THRESHOLD=80
readonly MEM_THRESHOLD=85
readonly DISK_THRESHOLD=90

# Logging function
log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a "$LOG_FILE"
}

# Get CPU usage
get_cpu_usage() {
    # Average CPU usage percentage
    top -bn1 | grep "Cpu(s)" | awk '{print 100 - $8}' | cut -d. -f1
}

# Get memory usage
get_memory_usage() {
    free | grep Mem | awk '{printf("%.0f", $3/$2 * 100.0)}'
}

# Get disk usage
get_disk_usage() {
    df -h / | awk 'NR==2 {print $5}' | sed 's/%//'
}

# Send alert email
send_alert() {
    local subject="$1"
    local message="$2"
    
    echo "$message" | mail -s "$subject" "$ALERT_EMAIL"
    log "Alert sent: $subject"
}

# Check thresholds and alert
check_thresholds() {
    local cpu=$(get_cpu_usage)
    local mem=$(get_memory_usage)
    local disk=$(get_disk_usage)
    
    log "CPU: ${cpu}%, Memory: ${mem}%, Disk: ${disk}%"
    
    if ((cpu > CPU_THRESHOLD)); then
        send_alert "CPU Alert" "CPU usage is ${cpu}%, threshold is ${CPU_THRESHOLD}%"
    fi
    
    if ((mem > MEM_THRESHOLD)); then
        send_alert "Memory Alert" "Memory usage is ${mem}%, threshold is ${MEM_THRESHOLD}%"
    fi
    
    if ((disk > DISK_THRESHOLD)); then
        send_alert "Disk Alert" "Disk usage is ${disk}%, threshold is ${DISK_THRESHOLD}%"
    fi
}

# Main
log "System monitoring started"
check_thresholds
log "System monitoring completed"
```

#### 4.2 Backup and Rotation Script

```bash
#!/bin/bash

# Backup Script with Rotation
# Backs up files and rotates old backups

set -euo pipefail

readonly SOURCE_DIR="${1:-.}"
readonly BACKUP_DIR="${2:-.backups}"
readonly RETENTION_DAYS=30
readonly MAX_BACKUPS=5

# Create backup directory
mkdir -p "$BACKUP_DIR"

# Generate backup filename
generate_backup_name() {
    echo "${BACKUP_DIR}/backup_$(date +%Y%m%d_%H%M%S).tar.gz"
}

# Create backup
create_backup() {
    local backup_file
    backup_file=$(generate_backup_name)
    
    echo "Creating backup: $backup_file"
    
    tar -czf "$backup_file" \
        --exclude='.git' \
        --exclude='node_modules' \
        --exclude='__pycache__' \
        "$SOURCE_DIR"
    
    echo "Backup completed: $backup_file"
    echo "$backup_file"
}

# Remove old backups by date
cleanup_by_date() {
    echo "Removing backups older than $RETENTION_DAYS days"
    find "$BACKUP_DIR" -name "backup_*.tar.gz" -mtime +"$RETENTION_DAYS" -delete
}

# Remove excess backups (keep only N newest)
cleanup_excess() {
    local count
    count=$(find "$BACKUP_DIR" -name "backup_*.tar.gz" -type f | wc -l)
    
    if ((count > MAX_BACKUPS)); then
        echo "Removing excess backups (keeping $MAX_BACKUPS)"
        find "$BACKUP_DIR" -name "backup_*.tar.gz" -type f -printf '%T+ %p\n' | \
            sort | \
            head -n $((count - MAX_BACKUPS)) | \
            cut -d' ' -f2- | \
            xargs rm -f
    fi
}

# Get backup statistics
show_stats() {
    echo "=== Backup Statistics ==="
    local count=$(find "$BACKUP_DIR" -name "backup_*.tar.gz" -type f | wc -l)
    local total_size=$(du -sh "$BACKUP_DIR" | cut -f1)
    
    echo "Total backups: $count"
    echo "Total size: $total_size"
    echo
    echo "Recent backups:"
    ls -lh "$BACKUP_DIR"/backup_*.tar.gz 2>/dev/null | tail -5
}

# Main
backup_file=$(create_backup)
cleanup_by_date
cleanup_excess
show_stats

echo "Backup script completed successfully"
```

#### 4.3 Log Analysis Script

```bash
#!/bin/bash

# Log Analysis Script
# Analyzes application logs for patterns

readonly LOG_FILE="${1:-/var/log/app.log}"
readonly ERROR_PATTERN="ERROR|FATAL|EXCEPTION"
readonly WARNING_PATTERN="WARN|WARNING"

# Validate log file
if [ ! -f "$LOG_FILE" ]; then
    echo "Error: Log file not found: $LOG_FILE"
    exit 1
fi

# Count errors
count_errors() {
    grep -ic "$ERROR_PATTERN" "$LOG_FILE" || echo 0
}

# Count warnings
count_warnings() {
    grep -ic "$WARNING_PATTERN" "$LOG_FILE" || echo 0
}

# Find top errors
top_errors() {
    echo "=== Top Errors ==="
    grep -i "$ERROR_PATTERN" "$LOG_FILE" | \
        grep -oE '[A-Z][A-Za-z]+Error|Exception[^ ]*' | \
        sort | uniq -c | sort -rn | head -10
}

# Timeline analysis
timeline_analysis() {
    echo "=== Error Timeline (by hour) ==="
    grep -i "$ERROR_PATTERN" "$LOG_FILE" | \
        grep -oE '[0-9]{2}:[0-9]{2}' | cut -d: -f1 | \
        sort | uniq -c | sort -k2 -n
}

# Recent errors
recent_errors() {
    echo "=== Recent Errors ==="
    grep -i "$ERROR_PATTERN" "$LOG_FILE" | tail -20
}

# Generate report
generate_report() {
    echo "=== Log Analysis Report ==="
    echo "File: $LOG_FILE"
    echo "Generated: $(date)"
    echo
    
    echo "Total Errors: $(count_errors)"
    echo "Total Warnings: $(count_warnings)"
    echo "Total Lines: $(wc -l < "$LOG_FILE")"
    echo
    
    top_errors
    echo
    
    timeline_analysis
    echo
    
    recent_errors
}

# Main
generate_report
```

---

### SECTION 5: ERROR HANDLING AND DEBUGGING

#### 5.1 Error Handling Patterns

**Concept:** Proper error handling makes scripts reliable and maintainable

```bash
#!/bin/bash

# Pattern 1: Check command exit code
command_with_check() {
    if ! some_command; then
        echo "Error: Command failed with exit code $?"
        return 1
    fi
}

# Pattern 2: Use 'set -e' (exit on error)
set -e  # Script exits if any command fails
command1
command2  # Only runs if command1 succeeds

# Pattern 3: Use 'set -u' (error on undefined variable)
set -u  # Script exits if undefined variable used
echo "$UNDEFINED_VAR"  # Causes error

# Pattern 4: Trap errors
trap 'echo "Error on line $LINENO"; exit 1' ERR

# Pattern 5: Trap multiple signals
trap cleanup EXIT INT TERM

cleanup() {
    echo "Cleaning up..."
    rm -f /tmp/myapp_*.tmp
}

# Pattern 6: Comprehensive error handling
#!/bin/bash

set -euo pipefail

# Error handler
error_handler() {
    local line_num=$1
    local error_code=$2
    echo "Error on line $line_num (exit code $error_code)" >&2
    cleanup
    exit "$error_code"
}

trap 'error_handler ${LINENO} $?' ERR
trap cleanup EXIT

cleanup() {
    # Cleanup code
    :
}

# Pattern 7: Custom error function
die() {
    echo "$@" >&2
    exit 1
}

# Usage
[ -f "$config_file" ] || die "Config file not found: $config_file"
```

#### 5.2 Debugging Techniques

```bash
#!/bin/bash

# Enable debug mode with -x flag
# bash -x script.sh

# Or enable within script
set -x  # Enable debug output
set +x  # Disable debug output

# Debug only specific section
debug_on() {
    set -x
    PS4='[DEBUG] ${BASH_SOURCE}:${LINENO} '
}

debug_off() {
    set +x
}

# Verbose output
if [ "${DEBUG:-0}" = "1" ]; then
    set -x
fi

# Custom debug function
debug() {
    if [ "${DEBUG:-0}" = "1" ]; then
        echo "[DEBUG] $*" >&2
    fi
}

# Usage
debug "Starting process"
some_command
debug "Process completed"

# Run with debugging
DEBUG=1 ./script.sh
```

---

## Practical Applications

### Web Server Setup and Management

#### Automated Web Server Deployment Script

```bash
#!/bin/bash

# Web Server Deployment Script
# Deploys and manages Nginx with automatic SSL and monitoring

set -euo pipefail

readonly APP_DIR="/var/www/myapp"
readonly CONFIG_DIR="/etc/nginx/sites-available"
readonly LOG_DIR="/var/log/myapp"
readonly DOMAIN="${1:-example.com}"
readonly EMAIL="${2:-admin@example.com}"

# Logging
log_msg() {
    echo "[$(date +'%Y-%m-%d %H:%M:%S')] $1" | tee -a "${LOG_DIR}/deploy.log"
}

error_exit() {
    log_msg "ERROR: $1"
    exit 1
}

# Step 1: Create directory structure
setup_directories() {
    log_msg "Setting up directories..."
    
    mkdir -p "$APP_DIR"/{public,src,config}
    mkdir -p "$LOG_DIR"
    
    log_msg "Directories created"
}

# Step 2: Install Nginx
install_nginx() {
    log_msg "Installing Nginx..."
    
    apt-get update || error_exit "Failed to update packages"
    apt-get install -y nginx || error_exit "Failed to install Nginx"
    
    log_msg "Nginx installed"
}

# Step 3: Create Nginx configuration
create_nginx_config() {
    log_msg "Creating Nginx configuration..."
    
    local config_file="${CONFIG_DIR}/${DOMAIN}.conf"
    
    cat > "$config_file" << 'EOF'
upstream backend {
    server 127.0.0.1:3000;
}

server {
    listen 80;
    server_name DOMAIN;
    
    # Redirect HTTP to HTTPS
    return 301 https://$server_name$request_uri;
}

server {
    listen 443 ssl http2;
    server_name DOMAIN;
    
    # SSL certificates (via Let's Encrypt)
    ssl_certificate /etc/letsencrypt/live/DOMAIN/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/DOMAIN/privkey.pem;
    
    # Security headers
    add_header Strict-Transport-Security "max-age=31536000" always;
    add_header X-Frame-Options "DENY" always;
    add_header X-Content-Type-Options "nosniff" always;
    add_header X-XSS-Protection "1; mode=block" always;
    
    # Logging
    access_log /var/log/nginx/ACCESS_DOMAIN.log;
    error_log /var/log/nginx/ERROR_DOMAIN.log;
    
    # Root directory
    root /var/www/myapp/public;
    
    # Static files caching
    location ~* \.(jpg|jpeg|png|gif|ico|css|js)$ {
        expires 1y;
        add_header Cache-Control "public, immutable";
    }
    
    # API proxy
    location /api/ {
        proxy_pass http://backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
    
    # Single page application fallback
    location / {
        try_files $uri $uri/ /index.html;
    }
}
EOF

    # Replace placeholders
    sed -i "s/DOMAIN/$DOMAIN/g" "$config_file"
    
    # Enable site
    ln -sf "$config_file" "/etc/nginx/sites-enabled/"
    
    log_msg "Nginx configuration created"
}

# Step 4: Setup SSL with Let's Encrypt
setup_ssl() {
    log_msg "Setting up SSL certificate..."
    
    apt-get install -y certbot python3-certbot-nginx || \
        error_exit "Failed to install Certbot"
    
    certbot certonly --standalone -d "$DOMAIN" -m "$EMAIL" --agree-tos \
        || error_exit "Failed to obtain SSL certificate"
    
    log_msg "SSL certificate obtained"
}

# Step 5: Start and enable services
start_services() {
    log_msg "Starting services..."
    
    systemctl restart nginx || error_exit "Failed to restart Nginx"
    systemctl enable nginx || error_exit "Failed to enable Nginx"
    
    log_msg "Services started and enabled"
}

# Step 6: Health check
health_check() {
    log_msg "Performing health checks..."
    
    # Check Nginx
    if ! nginx -t > /dev/null 2>&1; then
        error_exit "Nginx configuration test failed"
    fi
    
    # Check if listening
    if ! netstat -tuln | grep -q ":443"; then
        error_exit "HTTPS not listening on port 443"
    fi
    
    log_msg "Health checks passed"
}

# Main execution
main() {
    log_msg "Starting deployment for $DOMAIN"
    
    setup_directories
    install_nginx
    create_nginx_config
    setup_ssl
    start_services
    health_check
    
    log_msg "Deployment completed successfully"
}

main
```

---

### System Administration Scripts

#### Automated User Management Script

```bash
#!/bin/bash

# User Management Script
# Creates users, manages permissions, generates reports

set -euo pipefail

readonly USERS_FILE="users.csv"
readonly ADMIN_EMAIL="admin@example.com"

# Log operations
log_operation() {
    echo "[$(date +'%Y-%m-%d %H:%M:%S')] $1" >> /var/log/user_mgmt.log
}

# Create user function
create_user() {
    local username="$1"
    local fullname="$2"
    local department="$3"
    
    # Check if user exists
    if id "$username" &>/dev/null; then
        echo "User already exists: $username"
        return 1
    fi
    
    # Create user
    useradd -m -s /bin/bash -c "$fullname" "$username" || return 1
    
    # Set password expiry
    chage -d 0 "$username"  # Force password change on first login
    
    # Add user to groups based on department
    case "$department" in
        IT)
            usermod -aG wheel,developers "$username"
            ;;
        HR)
            usermod -aG hr-group "$username"
            ;;
        *)
            usermod -aG users "$username"
            ;;
    esac
    
    log_operation "User created: $username ($fullname, $department)"
    echo "User created successfully: $username"
    return 0
}

# Batch create users from CSV
batch_create_users() {
    local file="$1"
    
    [ -f "$file" ] || { echo "File not found: $file"; return 1; }
    
    # CSV format: username,fullname,department
    while IFS=',' read -r username fullname department; do
        [ -z "$username" ] && continue  # Skip empty lines
        create_user "$username" "$fullname" "$department"
    done < "$file"
}

# Disable inactive users
disable_inactive_users() {
    local days="${1:-90}"
    
    echo "Disabling users inactive for more than $days days..."
    
    while IFS=: read -r username _ uid _ _ home shell; do
        ((uid < 1000)) && continue  # Skip system users
        
        last_login=$(stat -c %Y "$home" 2>/dev/null || echo 0)
        current_time=$(date +%s)
        inactive_days=$(( (current_time - last_login) / 86400 ))
        
        if ((inactive_days > days)); then
            usermod -L "$username"  # Lock account
            log_operation "Disabled: $username (inactive for $inactive_days days)"
            echo "Disabled: $username"
        fi
    done < /etc/passwd
}

# Generate user report
generate_user_report() {
    echo "=== User Report ===" > /tmp/user_report.txt
    echo "Generated: $(date)" >> /tmp/user_report.txt
    echo >> /tmp/user_report.txt
    
    echo "Active Users:" >> /tmp/user_report.txt
    awk -F: '$3 >= 1000 {print $1, "(" $5 ")"}' /etc/passwd >> /tmp/user_report.txt
    echo >> /tmp/user_report.txt
    
    echo "Sudo Users:" >> /tmp/user_report.txt
    getent group sudo | cut -d: -f4 | tr ',' '\n' >> /tmp/user_report.txt
    echo >> /tmp/user_report.txt
    
    echo "Failed Login Attempts (last 24h):" >> /tmp/user_report.txt
    grep "Failed password" /var/log/auth.log 2>/dev/null | \
        grep "$(date -d '24 hours ago' +'%b %d')" | \
        awk '{print $11, $13}' | sort | uniq -c >> /tmp/user_report.txt
    
    cat /tmp/user_report.txt
    mail -s "User Report" "$ADMIN_EMAIL" < /tmp/user_report.txt
}

# Main menu
show_menu() {
    echo "=== User Management ==="
    echo "1. Create single user"
    echo "2. Batch create users"
    echo "3. Disable inactive users"
    echo "4. Generate report"
    echo "5. Exit"
}

# Main
main() {
    while true; do
        show_menu
        read -p "Choose option: " choice
        
        case "$choice" in
            1)
                read -p "Username: " username
                read -p "Full name: " fullname
                read -p "Department: " department
                create_user "$username" "$fullname" "$department"
                ;;
            2)
                read -p "CSV file path: " csvfile
                batch_create_users "$csvfile"
                ;;
            3)
                read -p "Days of inactivity (default 90): " days
                disable_inactive_users "${days:-90}"
                ;;
            4)
                generate_user_report
                ;;
            5)
                exit 0
                ;;
            *)
                echo "Invalid option"
                ;;
        esac
    done
}

main
```

---

### Deployment and DevOps Scripts

#### CI/CD Pipeline Script

```bash
#!/bin/bash

# CI/CD Pipeline Script
# Builds, tests, and deploys applications

set -euo pipefail

readonly PROJECT_DIR="${1:-.}"
readonly DEPLOY_DIR="/opt/deploy"
readonly ARTIFACT_DIR="/var/artifacts"
readonly NOTIFICATION_URL="${SLACK_WEBHOOK:-}"

# Logging with colors
log_info() {
    echo -e "\033[36m[INFO]\033[0m $1"
}

log_success() {
    echo -e "\033[32m[SUCCESS]\033[0m $1"
}

log_error() {
    echo -e "\033[31m[ERROR]\033[0m $1"
}

# Notify via Slack
notify() {
    local message="$1"
    local status="$2"
    
    [ -z "$NOTIFICATION_URL" ] && return 0
    
    local color="good"
    [ "$status" = "error" ] && color="danger"
    
    curl -X POST "$NOTIFICATION_URL" \
        -H 'Content-Type: application/json' \
        -d "{
            \"attachments\": [{
                \"color\": \"$color\",
                \"title\": \"Deployment Notification\",
                \"text\": \"$message\"
            }]
        }" 2>/dev/null || true
}

# Step 1: Checkout code
checkout_code() {
    log_info "Checking out code..."
    
    cd "$PROJECT_DIR" || return 1
    
    git pull origin main || return 1
    local commit_hash=$(git rev-parse HEAD | cut -c1-7)
    
    log_success "Code checked out: $commit_hash"
    echo "$commit_hash"
}

# Step 2: Build application
build_application() {
    local commit_hash="$1"
    log_info "Building application..."
    
    cd "$PROJECT_DIR" || return 1
    
    # Install dependencies
    if [ -f "package.json" ]; then
        npm ci || return 1
    fi
    
    # Build
    if [ -f "Makefile" ]; then
        make build || return 1
    fi
    
    # Create artifact
    mkdir -p "$ARTIFACT_DIR"
    local artifact="$ARTIFACT_DIR/app_${commit_hash}.tar.gz"
    tar -czf "$artifact" . \
        --exclude=.git \
        --exclude=node_modules \
        --exclude=.env || return 1
    
    log_success "Build completed: $artifact"
    echo "$artifact"
}

# Step 3: Run tests
run_tests() {
    log_info "Running tests..."
    
    cd "$PROJECT_DIR" || return 1
    
    if [ -f "package.json" ]; then
        npm test || return 1
    fi
    
    log_success "Tests passed"
}

# Step 4: Deploy application
deploy_application() {
    local artifact="$1"
    log_info "Deploying application..."
    
    # Stop current service
    systemctl stop myapp || true
    
    # Extract artifact
    mkdir -p "$DEPLOY_DIR"
    rm -rf "$DEPLOY_DIR"/*
    tar -xzf "$artifact" -C "$DEPLOY_DIR"
    
    # Install dependencies
    cd "$DEPLOY_DIR"
    npm install --production || return 1
    
    # Start service
    systemctl start myapp || return 1
    
    # Verify deployment
    sleep 5
    if ! systemctl is-active --quiet myapp; then
        return 1
    fi
    
    log_success "Application deployed"
}

# Step 5: Health check
health_check() {
    log_info "Performing health checks..."
    
    local max_retries=5
    local retry=0
    
    while ((retry < max_retries)); do
        if curl -sf http://localhost:3000/health > /dev/null; then
            log_success "Health check passed"
            return 0
        fi
        
        ((retry++))
        sleep 2
    done
    
    log_error "Health check failed"
    return 1
}

# Rollback on failure
rollback() {
    log_error "Deployment failed, rolling back..."
    systemctl restart myapp || true
    log_info "Rollback completed"
}

# Main pipeline
main() {
    log_info "Starting CI/CD pipeline"
    
    commit_hash=$(checkout_code) || {
        notify "Checkout failed" "error"
        return 1
    }
    
    artifact=$(build_application "$commit_hash") || {
        notify "Build failed" "error"
        return 1
    }
    
    run_tests || {
        notify "Tests failed" "error"
        return 1
    }
    
    deploy_application "$artifact" || {
        rollback
        notify "Deployment failed" "error"
        return 1
    }
    
    health_check || {
        rollback
        notify "Health check failed" "error"
        return 1
    }
    
    notify "Deployment successful (commit: $commit_hash)" "success"
    log_success "Pipeline completed successfully"
}

trap 'log_error "Pipeline interrupted"; exit 1' INT TERM
main "$@"
```

---

### Data Processing and Analytics Scripts

#### Log Processing Pipeline

```bash
#!/bin/bash

# Log Processing Pipeline
# Analyzes application logs and generates insights

set -euo pipefail

readonly RAW_LOG_DIR="/var/log/app"
readonly PROCESSED_LOG_DIR="/var/log/app/processed"
readonly REPORT_DIR="/var/reports"
readonly DAYS_TO_PROCESS="${1:-1}"

# Initialize directories
init_dirs() {
    mkdir -p "$PROCESSED_LOG_DIR" "$REPORT_DIR"
}

# Extract log metrics
extract_metrics() {
    local log_file="$1"
    local report_file="${REPORT_DIR}/metrics_$(date +%s).json"
    
    {
        echo "{"
        echo "  \"timestamp\": \"$(date -I)\","
        echo "  \"total_requests\": $(wc -l < "$log_file"),"
        echo "  \"unique_ips\": $(awk '{print $1}' "$log_file" | sort -u | wc -l),"
        echo "  \"errors_4xx\": $(grep -c ' 4[0-9][0-9] ' "$log_file" || echo 0),"
        echo "  \"errors_5xx\": $(grep -c ' 5[0-9][0-9] ' "$log_file" || echo 0),"
        echo "  \"average_response_time\": $(awk '{sum+=$NF; count++} END {printf "%.2f", sum/count}' "$log_file" || echo 0)"
        echo "}"
    } > "$report_file"
    
    echo "$report_file"
}

# Detect anomalies
detect_anomalies() {
    local log_file="$1"
    
    # Find IPs with many requests
    echo "=== IPs with High Request Volume ==="
    awk '{print $1}' "$log_file" | sort | uniq -c | sort -rn | head -10
    
    # Find slow endpoints
    echo "=== Slow Endpoints ==="
    awk -F'"' '{gsub(/^ +/, "", $2); print $2}' "$log_file" | \
        sort | uniq -c | sort -rn | head -10
    
    # Find failed requests
    echo "=== Failed Requests ==="
    grep -E ' [45][0-9]{2} ' "$log_file" | tail -20
}

# Generate analytics report
generate_report() {
    local date_range="$1"
    
    {
        echo "# Log Analytics Report"
        echo "Generated: $(date)"
        echo "Period: $date_range"
        echo
        
        echo "## Request Summary"
        for log in "$RAW_LOG_DIR"/*.log; do
            [ -f "$log" ] || continue
            extract_metrics "$log"
        done
        echo
        
        echo "## Anomalies Detected"
        detect_anomalies "$RAW_LOG_DIR"/*.log
    } > "${REPORT_DIR}/report_$(date +%Y%m%d).md"
}

# Archive processed logs
archive_logs() {
    log_date=$(date -d "$DAYS_TO_PROCESS days ago" +%Y-%m-%d)
    
    tar -czf "${PROCESSED_LOG_DIR}/logs_${log_date}.tar.gz" \
        "$RAW_LOG_DIR"/access.log \
        --remove-files || true
}

# Main
main() {
    init_dirs
    generate_report "$DAYS_TO_PROCESS days"
    archive_logs
}

main
```

---

### Security and Compliance Scripts

#### Security Audit Script

```bash
#!/bin/bash

# Security Audit Script
# Performs comprehensive security checks

set -euo pipefail

readonly AUDIT_REPORT="/var/reports/security_audit_$(date +%Y%m%d).txt"

# Initialize report
init_report() {
    {
        echo "=== Security Audit Report ==="
        echo "Generated: $(date)"
        echo "System: $(uname -a)"
        echo
    } > "$AUDIT_REPORT"
}

# Check for world-writable files
check_world_writable() {
    echo "=== World-Writable Files ===" | tee -a "$AUDIT_REPORT"
    find / -xdev -type f -perm -002 2>/dev/null | tee -a "$AUDIT_REPORT"
}

# Check for SUID binaries
check_suid() {
    echo "=== SUID/SGID Binaries ===" | tee -a "$AUDIT_REPORT"
    find / -xdev \( -perm -4000 -o -perm -2000 \) -type f \
        -exec ls -l {} \; 2>/dev/null | tee -a "$AUDIT_REPORT"
}

# Check sudo access
check_sudo_access() {
    echo "=== Sudo Access Configuration ===" | tee -a "$AUDIT_REPORT"
    sudo -l 2>/dev/null | tee -a "$AUDIT_REPORT"
}

# Check failed login attempts
check_failed_logins() {
    echo "=== Failed Login Attempts (Last 24h) ===" | tee -a "$AUDIT_REPORT"
    grep "Failed password" /var/log/auth.log 2>/dev/null | \
        grep "$(date -d '24 hours ago' +'%b %d')" | \
        tail -20 | tee -a "$AUDIT_REPORT"
}

# Check file permissions on critical files
check_critical_files() {
    echo "=== Critical File Permissions ===" | tee -a "$AUDIT_REPORT"
    
    local critical_files=(
        /etc/passwd
        /etc/shadow
        /etc/sudoers
        /etc/ssh/sshd_config
        /root/.ssh/authorized_keys
    )
    
    for file in "${critical_files[@]}"; do
        if [ -e "$file" ]; then
            ls -l "$file" | tee -a "$AUDIT_REPORT"
        fi
    done
}

# Display report
main() {
    init_report
    check_critical_files
    check_suid
    check_world_writable
    check_sudo_access
    check_failed_logins
    
    echo
    echo "Report saved to: $AUDIT_REPORT"
    cat "$AUDIT_REPORT"
}

main
```

---

## Interview Questions and Answers

### Shell Scripting and Automation

**Q1: Explain error handling in shell scripts. How do you use `set -e` and `set -o pipefail`?**

A: Error handling is critical for reliable scripts:

```bash
# set -e: Exit immediately if any command fails
set -e

# set -o pipefail: Pipe fails if any command fails
set -o pipefail

# set -u: Error on undefined variables
set -u

# Combined for robust scripts
set -euo pipefail
```

**Example:**
```bash
#!/bin/bash
set -euo pipefail

# If db_backup fails, script exits immediately
db_backup

# Piped commands: if grep fails, entire pipe fails
cat large_file.txt | grep pattern | awk '{print $1}'
```

**Key Points:**
- `set -e`: Prevents cascading failures
- `set -o pipefail`: Catches errors in middle of pipelines
- `set -u`: Prevents silent failures from typos
- Use `trap` for cleanup on exit

---

**Q2: How do you parse command-line arguments in shell scripts?**

A: Multiple approaches for different scenarios:

```bash
# Positional arguments
#!/bin/bash

script_name="$0"
arg1="$1"
arg2="$2"
all_args="$@"
arg_count="$#"

# Parse with while loop
while (($#)); do
    case "$1" in
        -f|--file)
            file="$2"
            shift 2
            ;;
        -v|--verbose)
            verbose=true
            shift
            ;;
        *)
            echo "Unknown option: $1"
            exit 1
            ;;
    esac
done

# Validate required arguments
[ -z "$file" ] && { echo "Error: --file required"; exit 1; }
```

**Best Practices:**
- Support both short (`-f`) and long (`--file`) options
- Validate required arguments early
- Provide help message: `./script.sh --help`
- Use `shift` to consume arguments

---

**Q3: What's the difference between `$@` and `$*` in shell scripts?**

A: Critical distinction for handling arguments:

```bash
# $@ → splits args into separate words (correct)
function process_args() {
    for arg in "$@"; do
        echo "Arg: $arg"
    done
}

process_args "hello world" "foo bar"
# Output:
# Arg: hello world
# Arg: foo bar

# $* → treats all args as single string (incorrect)
function wrong_process() {
    for arg in $*; do
        echo "Arg: $arg"
    done
}

wrong_process "hello world" "foo bar"
# Output:
# Arg: hello
# Arg: world
# Arg: foo
# Arg: bar

# Always use "$@" (with quotes) for correct behavior
```

**Key Difference:**
- `"$@"` preserves argument boundaries
- `$*` breaks on whitespace
- `"$@"` is almost always correct

---

**Q4: How do you handle temporary files safely in shell scripts?**

A: Use `mktemp` for security:

```bash
#!/bin/bash

# Create temporary file
temp_file=$(mktemp)
temp_dir=$(mktemp -d)

# Automatic cleanup
trap "rm -f $temp_file; rm -rf $temp_dir" EXIT

# Use temporary files
echo "data" > "$temp_file"
process_file "$temp_file"

# Directory for multiple files
mkdir -p "${temp_dir}/subdir"
touch "${temp_dir}/subdir/file.txt"

# Process
for file in "$temp_dir"/*; do
    cat "$file"
done

# Cleanup happens automatically on exit
```

**Key Practices:**
- Always use `mktemp` (not `/tmp/script.$$`)
- Use `trap` for cleanup
- Use quotes around temp file names
- Specify pattern for predictable names: `mktemp /tmp/backup.XXXXXX`

---

**Q5: How would you implement a retry mechanism for unreliable commands?**

A: Essential pattern for production scripts:

```bash
#!/bin/bash

retry_command() {
    local max_attempts=3
    local timeout=5
    local delay=2
    local attempt=1
    
    while ((attempt <= max_attempts)); do
        echo "Attempt $attempt of $max_attempts..."
        
        if timeout $timeout "$@"; then
            echo "Command succeeded"
            return 0
        fi
        
        local exit_code=$?
        
        if ((exit_code == 124)); then
            echo "Command timed out"
        else
            echo "Command failed (exit code: $exit_code)"
        fi
        
        ((attempt++))
        
        if ((attempt <= max_attempts)); then
            echo "Retrying in ${delay}s..."
            sleep $delay
        fi
    done
    
    echo "Command failed after $max_attempts attempts"
    return 1
}

# Usage
retry_command curl -f http://example.com/api
retry_command docker pull myimage:latest
```

**Advanced Pattern with Exponential Backoff:**
```bash
retry_with_backoff() {
    local max_attempts=5
    local attempt=1
    local delay=1
    
    while ((attempt <= max_attempts)); do
        if "$@"; then
            return 0
        fi
        
        if ((attempt < max_attempts)); then
            echo "Retrying in ${delay}s..."
            sleep $delay
            delay=$((delay * 2))  # Exponential backoff
        fi
        
        ((attempt++))
    done
    
    return 1
}
```

---

**Q6: Explain function scoping and how `local` variables work.**

A: Critical for maintaining state in scripts:

```bash
#!/bin/bash

GLOBAL="I'm global"

# Without local - affects global state
bad_function() {
    GLOBAL="Modified"  # Changes global!
    COUNT=$((COUNT + 1))  # Affects outer COUNT
}

# With local - encapsulated
good_function() {
    local TEMP="I'm local"
    local COUNT=0  # Different from outer COUNT
    
    GLOBAL="$GLOBAL modified"  # Can still modify globals intentionally
    echo "$TEMP"  # Only accessible here
}

COUNT=0
good_function
echo "COUNT: $COUNT"  # Still 0
echo "TEMP: $TEMP"    # Empty/undefined

# Return values from functions
get_config() {
    local config="/etc/myapp.conf"
    if [ -f "$config" ]; then
        echo "$config"  # Return via stdout
        return 0
    else
        return 1
    fi
}

config=$(get_config) || { echo "Config not found"; exit 1; }
```

**Best Practices:**
- Use `local` for all function variables
- Return data via `echo` (stdout)
- Use exit codes for success/failure
- Minimize global variable usage

---

**Q7: How do you handle signals (SIGTERM, SIGINT) in shell scripts?**

A: Use `trap` for graceful shutdown:

```bash
#!/bin/bash

# Cleanup function
cleanup() {
    local exit_code=$?
    
    echo "Cleaning up..."
    
    # Kill background processes
    jobs -p | xargs -r kill
    
    # Remove temporary files
    rm -f /tmp/myapp_*.tmp
    
    # Close database connections
    # Flush caches
    
    echo "Cleanup completed"
    exit $exit_code
}

# Setup trap handlers
trap cleanup EXIT      # Cleanup on normal exit
trap cleanup INT       # Cleanup on Ctrl+C
trap cleanup TERM      # Cleanup on SIGTERM
trap cleanup ERR       # Cleanup on error

# Main script
server_pid=""

start_server() {
    server_start_command &
    server_pid=$!
    echo "Server started with PID $server_pid"
}

start_server

# Keep running
while true; do
    if ! kill -0 $server_pid 2>/dev/null; then
        echo "Server died, restarting..."
        start_server
    fi
    sleep 5
done
```

**Handling Multiple Signals:**
```bash
handle_signal() {
    local signal=$1
    
    case $signal in
        INT)
            echo "Interrupted by user"
            ;;
        TERM)
            echo "Terminated"
            ;;
        HUP)
            echo "Reloading configuration"
            reload_config
            return  # Don't exit
            ;;
    esac
    
    cleanup
    exit 128 + $signal
}

trap 'handle_signal INT' INT
trap 'handle_signal TERM' TERM
trap 'handle_signal HUP' HUP
trap cleanup EXIT
```

---

**Q8: How would you implement logging in production shell scripts?**

A: Proper logging for debugging and monitoring:

```bash
#!/bin/bash

readonly LOG_FILE="/var/log/myapp.log"
readonly LOG_LEVEL="${LOG_LEVEL:-INFO}"

# Log levels: DEBUG=0, INFO=1, WARN=2, ERROR=3
declare -A log_levels=(
    [DEBUG]=0
    [INFO]=1
    [WARN]=2
    [ERROR]=3
)

log() {
    local level="$1"
    shift
    local message="$@"
    local timestamp=$(date '+%Y-%m-%d %H:%M:%S')
    
    # Check if should log based on level
    if ((log_levels[$level] < log_levels[$LOG_LEVEL])); then
        return
    fi
    
    # Format: timestamp [LEVEL] message
    local log_entry="[$timestamp] [$level] $message"
    
    # Output to file
    echo "$log_entry" >> "$LOG_FILE"
    
    # Also output to console (or not)
    if [ "${VERBOSE:-0}" = "1" ]; then
        echo "$log_entry" >&2
    fi
}

log_debug() {
    log DEBUG "$@"
}

log_info() {
    log INFO "$@"
}

log_warn() {
    log WARN "$@"
}

log_error() {
    log ERROR "$@" >&2
}

# Usage
log_info "Application starting"
log_debug "Debug mode enabled"
log_warn "High memory usage detected"
log_error "Failed to connect to database"

# Set log level
LOG_LEVEL=DEBUG ./script.sh  # All levels
LOG_LEVEL=ERROR ./script.sh  # Only errors
```

**Rotating Logs:**
```bash
rotate_logs() {
    local log_file="$1"
    local max_size=$((10 * 1024 * 1024))  # 10MB
    
    if [ -f "$log_file" ] && [ $(stat -f%z "$log_file") -gt $max_size ]; then
        mv "$log_file" "${log_file}.$(date +%Y%m%d_%H%M%S)"
        touch "$log_file"
    fi
}
```

---

**Q9: How do you test shell scripts? What's your approach to debugging?**

A: Comprehensive testing and debugging:

```bash
# Test Framework
run_test() {
    local test_name="$1"
    local command="$2"
    local expected="$3"
    
    echo -n "Testing: $test_name... "
    
    result=$(eval "$command" 2>&1)
    
    if [ "$result" = "$expected" ]; then
        echo "✓ PASS"
        return 0
    else
        echo "✗ FAIL"
        echo "  Expected: $expected"
        echo "  Got: $result"
        return 1
    fi
}

# Debugging techniques
debug_on() {
    set -x
    PS4='+ ${BASH_SOURCE}:${LINENO} '
}

debug_off() {
    set +x
}

# Run with debugging
bash -x script.sh
# Or
DEBUG=1 bash -x script.sh

# Unit tests
test_string_operations() {
    local str="hello world"
    
    run_test "uppercase" \
        "echo ${str^^}" \
        "HELLO WORLD"
    
    run_test "lowercase" \
        "echo ${str,,}" \
        "hello world"
    
    run_test "substring" \
        "echo ${str:0:5}" \
        "hello"
}

# Integration tests
test_file_operations() {
    local tmpdir=$(mktemp -d)
    trap "rm -rf $tmpdir" RETURN
    
    run_test "create file" \
        "touch $tmpdir/test.txt && [ -f $tmpdir/test.txt ] && echo 'pass'" \
        "pass"
}

# Run all tests
test_all() {
    local passed=0
    local failed=0
    
    test_string_operations && ((passed++)) || ((failed++))
    test_file_operations && ((passed++)) || ((failed++))
    
    echo
    echo "Tests passed: $passed"
    echo "Tests failed: $failed"
}

test_all
```

---

**Q10: How do you handle sensitive data (passwords, keys) in shell scripts?**

A: Security best practices:

```bash
#!/bin/bash

# Bad: Never hardcode secrets
# password="my_secret_password"

# Good 1: Read from environment variables
db_password="${DB_PASSWORD:?ERROR: DB_PASSWORD not set}"

# Good 2: Read from secure file
if [ -f ~/.db_credentials ]; then
    source ~/.db_credentials
    chmod 600 ~/.db_credentials  # Restrict permissions
fi

# Good 3: Use credential managers
get_secret() {
    local secret_name="$1"
    
    # Example with HashiCorp Vault
    vault kv get -field=password "secret/myapp/$secret_name"
}

db_password=$(get_secret "database")

# Good 4: Prompt for password (masked input)
read -sp "Enter password: " password
echo

# Good 5: Use temporary encrypted storage
store_secret() {
    local secret="$1"
    local file="/tmp/secret.$$"
    
    # Create encrypted file
    echo "$secret" | openssl enc -aes-256-cbc -salt -out "$file"
    
    # Cleanup on exit
    trap "rm -f $file" EXIT
    
    echo "$file"
}

# Good 6: Never echo secrets in logs
wrong_log() {
    echo "Using password: $password"  # BAD!
}

right_log() {
    echo "Connecting to database..."  # OK
}

# Good 7: Secure API calls
call_api() {
    local url="$1"
    local api_key="$API_KEY"
    
    # Suppress output to avoid logging secrets
    curl -s -H "Authorization: Bearer $api_key" "$url"
}

# Good 8: Clear sensitive variables when done
clean_secrets() {
    unset db_password
    unset api_key
    unset auth_token
}

trap clean_secrets EXIT
```

**Environment Variable Best Practices:**
```bash
# Set in .env.local (never commit to git)
# Load carefully
if [ -f .env.local ]; then
    set -a  # Export all variables
    source .env.local
    set +a
fi

# Or use separate secure storage
eval "$(pass show myapp/db_password)"
```

---

## Summary of Shell Scripting Concepts

**Essential Takeaways:**
1. **Always use `set -euo pipefail`** for robustness
2. **Use functions** to organize and reuse code
3. **Implement proper error handling** with `trap`
4. **Log everything** for debugging and monitoring
5. **Use local variables** to prevent state pollution
6. **Quote variables** to handle spaces correctly
7. **Test thoroughly** before production use
8. **Secure sensitive data** - never hardcode secrets
9. **Document complex logic** with comments
10. **Make scripts idempotent** - safe to run multiple times



**Nginx Installation:**
```bash
sudo apt update
sudo apt install nginx
sudo systemctl enable nginx
sudo systemctl start nginx
sudo systemctl status nginx

# Configuration
/etc/nginx/nginx.conf               # Main config
/etc/nginx/sites-available/default  # Default site
/etc/nginx/sites-enabled/           # Enabled sites

# Test configuration
sudo nginx -t

# Restart after changes
sudo systemctl reload nginx
```

### Database Server

**PostgreSQL Setup:**
```bash
sudo apt install postgresql postgresql-contrib
sudo systemctl start postgresql
sudo -u postgres psql              # Connect as postgres

# Create database and user
CREATE DATABASE myapp;
CREATE USER appuser WITH PASSWORD 'password';
ALTER ROLE appuser SET client_encoding TO 'utf8';
GRANT ALL PRIVILEGES ON DATABASE myapp TO appuser;
\q                                 # Quit

# Backup database
pg_dump myapp > backup.sql

# Restore database
psql myapp < backup.sql
```

### Application Deployment

**systemd Service File:**
```bash
sudo tee /etc/systemd/system/myapp.service <<EOF
[Unit]
Description=My Application
After=network.target postgresql.service

[Service]
Type=simple
User=appuser
WorkingDirectory=/opt/myapp
ExecStart=/usr/bin/python3 /opt/myapp/app.py
Restart=on-failure
RestartSec=10
StandardOutput=journal
StandardError=journal

[Install]
WantedBy=multi-user.target
EOF

sudo systemctl daemon-reload
sudo systemctl enable myapp
sudo systemctl start myapp
sudo systemctl status myapp
journalctl -u myapp -f              # View logs
```

---

## Interview Questions

### Q1. Explain the Linux boot process.

**Answer:**
```
1. BIOS/UEFI
   - Initializes hardware
   - Runs POST (Power-On Self Test)
   - Loads bootloader from MBR/GPT

2. Bootloader (GRUB)
   - Displays boot menu
   - Loads kernel into memory
   - Passes control to kernel

3. Kernel
   - Detects hardware
   - Mounts root filesystem
   - Starts init process (PID 1)

4. Init System (systemd)
   - Reads /etc/systemd/system/default.target
   - Starts required services
   - Brings system to desired state

5. Login
   - Display login prompt
   - User authentication
   - Shell assignment
```

### Q2. What are inode and hard links?

**Answer:**
- **Inode**: Data structure containing file metadata (permissions, size, timestamps, pointers to data blocks)
- **Hard Link**: Multiple filenames pointing to same inode
- Deleting filename removes link; file deleted when all hard links gone
- Cannot create hard links to directories
- Hard links cannot cross filesystem boundaries
- Hard links share same inode number

### Q3. Explain file permissions and umask.

**Answer:**
```
Permission bits:
- 4: Read (r)
- 2: Write (w)
- 1: Execute (x)

umask: Subtracts permissions from default
Default file: 666 (rw-rw-rw-)
Default dir:  777 (rwxrwxrwx)

umask 022:
File: 666 - 022 = 644 (rw-r--r--)
Dir:  777 - 022 = 755 (rwxr-xr-x)

umask 077:
File: 666 - 077 = 600 (rw-------)
Dir:  777 - 077 = 700 (rwx------)
```

### Q4. What's the difference between daemon and service?

**Answer:**
- **Daemon**: Background process without controlling terminal
- **Service**: Managed by init system (systemd)
- Services start daemons
- Daemons can exist without service file
- Services provide standard lifecycle (start/stop/restart)

### Q5. Explain the difference between /dev/null and /dev/zero.

**Answer:**
```
/dev/null:
- Reads: Always return EOF
- Writes: Discard all data
- Use: command > /dev/null (suppress output)

/dev/zero:
- Reads: Infinite stream of NULL bytes
- Writes: Discard all data
- Use: dd if=/dev/zero of=file bs=1M count=100 (create file)
```

### Q6. How would you check network connectivity?

**Answer:**
```bash
ping host                          # Basic connectivity
traceroute host                    # Route to destination
mtr host                           # Continuous trace
telnet host port                   # TCP connectivity
nc -zv host port                   # Netcat check
ss -tuln | grep port               # Check listening port
netstat -tupn | grep port          # Process listening
```

### Q7. Explain the Linux kernel.

**Answer:**
- Core of OS managing hardware
- Process scheduling
- Memory management
- File system
- Device drivers
- Interprocess communication
- Can update applications without reboot
- Can add/remove modules without reboot

### Q8. What's the difference between bash and sh?

**Answer:**
```
sh:
- POSIX shell
- Minimal features
- Standard across systems
- Faster startup

bash:
- Bourne Again Shell
- Extended features
- Functions, arrays, regex
- More user-friendly
- Commonly used in scripts
```

### Q9. How do you find and kill a process?

**Answer:**
```bash
ps aux | grep processname           # Find process
pgrep processname                   # Get PID
kill -9 PID                        # Force kill
killall processname                # Kill by name
pkill -f pattern                   # Kill by pattern

# Check if killed
ps -p PID                          # Still running?
```

### Q10. Explain SELinux vs AppArmor.

**Answer:**
```
SELinux:
- Mandatory Access Control (MAC)
- More complex configuration
- Finer-grained control
- RedHat/CentOS systems
- Learning curve steep

AppArmor:
- MAC framework
- Simpler than SELinux
- Path-based profiles
- Debian/Ubuntu systems
- Easier to configure
```

---

## Summary

Linux is a powerful, flexible operating system used in servers, desktops, embedded systems, and beyond. Key competencies include:

- Understanding file system and permissions
- Command-line proficiency
- User and group management
- Process and service management
- Package management
- Networking fundamentals
- Shell scripting
- System administration
- Security best practices
- Performance monitoring

The Linux ecosystem continues to grow with containerization (Docker), orchestration (Kubernetes), and cloud integration.

---

## Learning Path

1. **Basics**: File system, commands, permissions
2. **Intermediate**: Shell scripting, user management, services
3. **Advanced**: System administration, security, performance tuning
4. **Specialist**: Containers, cloud integration, DevOps
5. **Expertise**: Kernel development, security hardening, large-scale deployment

---

## Useful Resources

**Documentation:**
- man command (Manual pages)
- info command
- /usr/share/doc/

**Online Resources:**
- Linux man pages online
- Linux Foundation documentation
- Stack Overflow for specific issues

**Practice:**
- Linux Academy
- TryHackMe
- HackTheBox
- OverTheWire

**Certifications:**
- CompTIA Linux+
- Linux Professional Institute (LPI) LPIC-1
- Red Hat Certified System Administrator (RHCSA)
