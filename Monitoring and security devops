# Monitoring & Security for DevOps - Complete Guide

## Table of Contents
1. [Monitoring Fundamentals](#monitoring-fundamentals)
2. [Security Fundamentals](#security-fundamentals)
3. [Network Security](#network-security)
4. [Identity & Access Management](#identity--access-management)
5. [Data Protection & Encryption](#data-protection--encryption)
6. [Security Monitoring & Logging](#security-monitoring--logging)
7. [Securing Terraform](#securing-terraform)
8. [Monitoring Best Practices](#monitoring-best-practices)
9. [Compliance & Governance](#compliance--governance)

---

## Monitoring Fundamentals

### What is Monitoring?

**Monitoring** is the continuous observation of system metrics, logs, and traces to understand infrastructure health, performance, and user experience. It's the foundation of operational excellence and enables rapid incident detection and response.

**Core Definition:**
- Real-time or near-real-time collection of data
- Aggregation and analysis of collected data
- Alert generation based on defined thresholds
- Historical data retention for trends and optimization

### Key Pillars of Observability

**The "Three Pillars of Observability":**

1. **Metrics**: Quantitative measurements (time-series data)
   ```
   Definition: Numerical measurements aggregated over time
   Collection: Active/Passive from systems
   Storage: Time-series database (Prometheus, CloudWatch)
   Granularity: Seconds to minutes intervals
   
   Examples:
   - CPU utilization (0-100%)
   - Memory usage (bytes)
   - Request latency (milliseconds)
   - Throughput (requests/second)
   - Error rates (percentage)
   - Queue depths (count)
   - Connection pooling metrics
   - Garbage collection pauses
   ```
   
   **Types of Metrics:**
   - **RED Method** (for services): Rate, Errors, Duration
   - **USE Method** (for resources): Utilization, Saturation, Errors
   - **Business Metrics**: Revenue, conversions, user engagement
   - **Technical Metrics**: Response time, availability, throughput

2. **Logs**: Event records with context (unstructured/structured text)
   ```
   Definition: Timestamped records of events and state changes
   Format: Unstructured text or JSON structured logs
   Retention: Days to years (depends on compliance)
   Indexing: Full-text search capabilities (ELK, Splunk)
   
   Examples:
   - Application errors and stack traces
   - HTTP request logs (method, path, status, duration)
   - System logs (kernel, services, authentication)
   - Security logs (failed logins, permission changes)
   - Audit logs (who did what, when, why)
   - Debug logs (detailed execution flow)
   ```
   
   **Log Levels (in order of severity):**
   - **DEBUG**: Detailed info for diagnostic purposes
   - **INFO**: General informational messages
   - **WARN**: Warning conditions that should be reviewed
   - **ERROR**: Error conditions that need attention
   - **FATAL/CRITICAL**: System shutdown conditions

3. **Traces**: End-to-end request journey (distributed tracing)
   ```
   Definition: Complete path of request through microservices
   Components: Spans (units of work) and traces (collection of spans)
   Tools: Jaeger, X-Ray, Datadog APM, New Relic
   
   Captured Information:
   - Request path through services
   - Latency breakdown by service
   - Database query time
   - Cache hit/miss
   - External API calls
   - Error context and stack traces
   - Service dependencies
   ```
   
   **Trace Structure:**
   ```
   Trace ID: abc123 (unique request identifier)
   â”œâ”€ Span 1: API Gateway (0-50ms)
   â”‚  â””â”€ Span 2: Auth Service (5-15ms)
   â”‚  â””â”€ Span 3: Business Logic (15-30ms)
   â”‚     â””â”€ Span 4: Database Query (10-25ms)
   â”‚  â””â”€ Span 5: Cache Lookup (1-2ms)
   â””â”€ Span 6: Response Serialization (3-5ms)
   ```

4. **Events**: Significant state changes (signals)
   ```
   Definition: Discrete occurrences of importance
   Examples:
   - Deployments and releases
   - Auto-scaling events (scale up/down)
   - Errors and exceptions
   - Configuration changes
   - Security incidents
   - Performance anomalies
   - Resource exhaustion
   ```

### Why Monitoring Matters

**Business Impact:**
- **MTTD (Mean Time to Detect)**: Faster detection = reduced user impact
- **MTTR (Mean Time to Resolve)**: Better data = faster resolution
- **Reliability**: 99.9% uptime requires monitoring
- **Cost**: Right-sized resources reduce cloud spend by 20-40%
- **User Experience**: Real-user monitoring detects UX issues before support calls

**Operational Benefits:**
- ğŸš¨ **Alerting**: Detect issues before users experience them (proactive monitoring)
- ğŸ“Š **Optimization**: Identify performance bottlenecks and wasteful resource usage
- ğŸ’° **Cost Management**: Spot over-provisioned resources, schedule off-peak cleanup
- ğŸ“ˆ **Capacity Planning**: Forecast growth trends, plan expansions proactively
- ğŸ” **Debugging**: Complete visibility into request flow for rapid root cause analysis
- ğŸ“‹ **Compliance**: Audit trails for regulatory requirements (HIPAA, PCI-DSS, SOC2)
- ğŸ›¡ï¸ **Security**: Detect anomalies, unauthorized access, suspicious patterns

**Real-World Example:**
```
Without Monitoring:
- Production outage at 3 AM
- On-call engineer wakes up
- No context available
- Guesses what might be wrong
- 45 minutes to identify root cause
- 90 minutes total resolution time
- Customer SLA breach, reputation damage
- Post-mortem: "We didn't know it was happening"

With Monitoring:
- Alert fires within 2 seconds of threshold
- Dashboard shows exact issue (CPU spike, memory leak)
- Stack trace available in logs
- Related spans show which service failed
- On-call engineer has full context
- 5 minutes to identify root cause
- 15 minutes total resolution time
- SLA met, customer unaffected
- Post-mortem: "We have detailed data to prevent recurrence"
```

### Monitoring Types (Detailed)

**1. Infrastructure Monitoring (Resource-level)**
```
Purpose: Track compute resources health and utilization
Focus: Servers, containers, VMs, storage capacity

Key Metrics:
â”œâ”€ CPU
â”‚  â”œâ”€ Utilization (percentage)
â”‚  â”œâ”€ Saturation (wait time)
â”‚  â”œâ”€ Context switches per second
â”‚  â””â”€ Load average (1, 5, 15 min)
â”‚
â”œâ”€ Memory
â”‚  â”œâ”€ Used/Free/Cached (bytes)
â”‚  â”œâ”€ Swap usage
â”‚  â”œâ”€ Page faults
â”‚  â””â”€ Out-of-memory killer events
â”‚
â”œâ”€ Disk
â”‚  â”œâ”€ Space utilization (percentage)
â”‚  â”œâ”€ Inode usage
â”‚  â”œâ”€ I/O operations per second
â”‚  â””â”€ Read/write latency
â”‚
â”œâ”€ Network
â”‚  â”œâ”€ Bandwidth in/out
â”‚  â”œâ”€ Packet loss
â”‚  â”œâ”€ Connection count
â”‚  â””â”€ Network errors
â”‚
â””â”€ Reliability
   â”œâ”€ Uptime/downtime
   â”œâ”€ Disk failures
   â”œâ”€ Hardware issues
   â””â”€ Service restarts

Alert Examples:
- CPU > 85% for 5 minutes
- Memory free < 10% remaining
- Disk full in < 24 hours (trending)
- Network packet loss > 1%
```

**2. Application Monitoring (Service-level)**
```
Purpose: Track application health and performance
Focus: API endpoints, business logic, user transactions

Key Metrics (RED Method):
â”œâ”€ Rate (Throughput)
â”‚  â”œâ”€ Requests per second
â”‚  â”œâ”€ Transactions per minute
â”‚  â””â”€ Concurrent users
â”‚
â”œâ”€ Errors
â”‚  â”œâ”€ 4xx errors (client errors)
â”‚  â”œâ”€ 5xx errors (server errors)
â”‚  â”œâ”€ Error rate (percentage)
â”‚  â””â”€ Specific error types (timeout, connection refused)
â”‚
â””â”€ Duration (Latency)
   â”œâ”€ Response time (p50, p90, p99)
   â”œâ”€ Request size
   â”œâ”€ Processing time breakdown
   â””â”€ Queue wait time

Additional Metrics:
â”œâ”€ Database Performance
â”‚  â”œâ”€ Query execution time
â”‚  â”œâ”€ Query throughput
â”‚  â”œâ”€ Connection pool utilization
â”‚  â”œâ”€ Slow query count
â”‚  â””â”€ Lock contention
â”‚
â”œâ”€ Cache Performance
â”‚  â”œâ”€ Hit rate (percentage)
â”‚  â”œâ”€ Miss rate
â”‚  â”œâ”€ Eviction rate
â”‚  â””â”€ Cache size
â”‚
â”œâ”€ Dependency Health
â”‚  â”œâ”€ Third-party API latency
â”‚  â”œâ”€ Third-party API error rate
â”‚  â”œâ”€ Circuit breaker state
â”‚  â””â”€ Timeout frequency
â”‚
â””â”€ Business Metrics
   â”œâ”€ Transaction success rate
   â”œâ”€ Conversion rate
   â”œâ”€ Revenue per minute
   â””â”€ User engagement metrics

Alert Examples:
- Error rate > 1% (compared to baseline)
- p99 latency > 1000ms
- Database query time > 5s
- API timeout rate > 0.5%
```

**3. Log Monitoring (Event-level)**
```
Purpose: Understand what's happening in detail
Focus: Patterns, errors, security events, audit trails

Log Categories:
â”œâ”€ Application Logs
â”‚  â”œâ”€ Error logs with stack traces
â”‚  â”œâ”€ Request logs (method, path, status, duration)
â”‚  â”œâ”€ Feature logs (feature flags, decisions)
â”‚  â””â”€ Performance logs (slow queries, expensive operations)
â”‚
â”œâ”€ System Logs
â”‚  â”œâ”€ Kernel logs (OOM killer, panic)
â”‚  â”œâ”€ Service logs (start, stop, restart)
â”‚  â”œâ”€ Package manager logs (install, update)
â”‚  â””â”€ Cron job logs
â”‚
â”œâ”€ Security Logs
â”‚  â”œâ”€ Failed login attempts
â”‚  â”œâ”€ Permission denied events
â”‚  â”œâ”€ SSH connection attempts
â”‚  â”œâ”€ Sudo usage
â”‚  â””â”€ File access changes
â”‚
â”œâ”€ Access Logs
â”‚  â”œâ”€ HTTP access logs
â”‚  â”œâ”€ Database connection logs
â”‚  â”œâ”€ API call logs
â”‚  â””â”€ Load balancer logs
â”‚
â””â”€ Audit Logs
   â”œâ”€ Configuration changes
   â”œâ”€ Deployment events
   â”œâ”€ User actions
   â””â”€ Compliance-related events

Log Analysis Techniques:
- Pattern matching (grep, regex)
- Aggregation (error counts, types)
- Correlation (request ID tracking)
- Anomaly detection (sudden spike in errors)
- Root cause analysis (trace related logs)

Alert Examples:
- Database connection refused errors > 10 in 5 min
- Error rate spike > 2x baseline
- Specific exception appearing (e.g., OutOfMemoryError)
- Failed authentication attempts > 5 from same IP
```

**4. Synthetic Monitoring (Proactive)**
```
Purpose: Monitor from outside, like end users experience
Focus: Uptime, availability, functionality, performance

Types:
â”œâ”€ Endpoint Monitoring
â”‚  â”œâ”€ HTTP/HTTPS availability checks
â”‚  â”œâ”€ DNS resolution time
â”‚  â”œâ”€ SSL certificate expiration
â”‚  â”œâ”€ Response time from multiple regions
â”‚  â””â”€ Frequency: Every 1-5 minutes
â”‚
â”œâ”€ Transaction Monitoring (Scripted)
â”‚  â”œâ”€ Simulate user workflows (login, purchase, logout)
â”‚  â”œâ”€ Verify critical user paths
â”‚  â”œâ”€ Validate business functions
â”‚  â””â”€ Frequency: Every 15-30 minutes
â”‚
â”œâ”€ Performance Baselines
â”‚  â”œâ”€ Page load time
â”‚  â”œâ”€ Time to first byte (TTFB)
â”‚  â”œâ”€ Core Web Vitals (LCP, FID, CLS)
â”‚  â””â”€ Asset load times
â”‚
â””â”€ Regional Testing
   â”œâ”€ Monitor from different geographic regions
   â”œâ”€ Detect regional outages
   â”œâ”€ Verify CDN performance
   â””â”€ Test from various networks (3G, 4G, WiFi)

Benefits:
- Early detection (before customers notice)
- Objective performance data
- User experience perspective
- Regression testing in production

Alert Examples:
- Endpoint not responding within 5 seconds
- API returns 500 error (instant alert)
- Transaction flow fails at checkout
```

**5. Real User Monitoring (RUM)**
```
Purpose: Track actual user experience
Focus: Real browsers, real networks, real behavior

Collected Data:
â”œâ”€ Page Load Performance
â”‚  â”œâ”€ DNS lookup time
â”‚  â”œâ”€ TCP connect time
â”‚  â”œâ”€ TLS handshake time
â”‚  â”œâ”€ Time to first byte (TTFB)
â”‚  â”œâ”€ Time to interactive (TTI)
â”‚  â””â”€ Fully loaded time
â”‚
â”œâ”€ User Interactions
â”‚  â”œâ”€ Click response time
â”‚  â”œâ”€ Form submission time
â”‚  â”œâ”€ Navigation timing
â”‚  â””â”€ Resource timing
â”‚
â”œâ”€ Browser Context
â”‚  â”œâ”€ Device type (mobile, desktop, tablet)
â”‚  â”œâ”€ Browser type and version
â”‚  â”œâ”€ Network type (WiFi, 3G, 4G)
â”‚  â”œâ”€ Geography (country, region)
â”‚  â””â”€ OS version
â”‚
â”œâ”€ Error Tracking
â”‚  â”œâ”€ JavaScript errors
â”‚  â”œâ”€ Network errors
â”‚  â”œâ”€ HTTP error responses
â”‚  â””â”€ Long task identification
â”‚
â””â”€ Session Recording (optional)
   â”œâ”€ User actions and flow
   â”œâ”€ DOM changes
   â”œâ”€ Console errors
   â””â”€ Network activity (be careful with PII!)

Advantages Over Synthetic:
- Real user behavior (not scripted)
- Natural network conditions
- Device and browser diversity
- Session context available
- Can correlate with user actions

Privacy Considerations:
- Do NOT capture sensitive data
- Anonymize PII (user IDs, emails)
- Get user consent
- Comply with GDPR, CCPA
```

### AWS Monitoring Tools

**CloudWatch (Native AWS):**

```hcl
# EC2 Instance Monitoring
resource "aws_cloudwatch_metric_alarm" "cpu_high" {
  alarm_name          = "ec2-cpu-high"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = "2"
  metric_name         = "CPUUtilization"
  namespace           = "AWS/EC2"
  period              = "300"          # 5 minutes
  statistic           = "Average"
  threshold           = "80"
  
  dimensions = {
    InstanceId = aws_instance.web.id
  }
  
  alarm_actions = [aws_sns_topic.alerts.arn]
}

# Memory monitoring (requires CloudWatch agent)
resource "aws_cloudwatch_metric_alarm" "memory_high" {
  alarm_name          = "ec2-memory-high"
  comparison_operator = "GreaterThanThreshold"
  metric_name         = "MemoryUtilization"
  namespace           = "CWAgent"
  period              = "300"
  statistic           = "Average"
  threshold           = "85"
  alarm_actions       = [aws_sns_topic.alerts.arn]
}

# Application Insights (APM)
resource "aws_applicationinsights_app" "main" {
  resource_group_name = aws_resourcegroups_group.app.name
  
  tags = { Environment = "production" }
}

# CloudWatch Logs
resource "aws_cloudwatch_log_group" "app" {
  name              = "/aws/app/production"
  retention_in_days = 30
  kms_key_id        = aws_kms_key.logs.arn
}
```

**Third-Party Tools:**
- **Prometheus**: Metrics collection and time-series database
- **Grafana**: Visualization and dashboard creation
- **ELK Stack**: Elasticsearch, Logstash, Kibana for logs
- **Splunk**: Enterprise-grade log analytics
- **Datadog**: Full-stack monitoring platform
- **New Relic**: Application performance monitoring
- **Sumo Logic**: Cloud-native monitoring
- **Dynatrace**: AI-powered observability

---

## Security Fundamentals

### Core Security Concepts & Theory

**What is Security?**
Security in cloud infrastructure is about:
1. **Confidentiality**: Only authorized users can access data
2. **Integrity**: Data cannot be modified without detection
3. **Availability**: Services are accessible when needed (vs. denial-of-service)
4. **Authenticity**: Verify users/systems are who they claim to be
5. **Non-repudiation**: Users cannot deny their actions (audit trail)

**Security Mindset: Assume Breach**
```
Traditional Mindset:        Modern Mindset:
âœ— "Keep threats out"        âœ“ "Threats are inside, control spread"
âœ— "Trust inside network"    âœ“ "Never trust, always verify"
âœ— "Perimeter is secure"     âœ“ "No perimeter, verify every access"
âœ— "Fixed defenses"          âœ“ "Continuous monitoring & adaptation"
```

### Defense in Depth - 7 Layers (Detailed Theory)

**Layer 1: Perimeter Security (Network Boundary)**
```
Purpose: First line of defense, block obvious threats
Components:
â”œâ”€ DDoS Protection
â”‚  â”œâ”€ AWS Shield (Standard - free, Basic - auto)
â”‚  â”œâ”€ AWS Shield Advanced (paid - advanced protection)
â”‚  â””â”€ CloudFlare, Akamai (3rd party)
â”‚
â”œâ”€ Web Application Firewall (WAF)
â”‚  â”œâ”€ Rate limiting (prevent brute force, DDoS)
â”‚  â”œâ”€ SQL injection protection
â”‚  â”œâ”€ XSS prevention
â”‚  â”œâ”€ Geo-blocking
â”‚  â””â”€ IP reputation filtering
â”‚
â”œâ”€ Network Segmentation
â”‚  â”œâ”€ VPC (Virtual Private Cloud)
â”‚  â”œâ”€ Subnets (Public, Private, Database)
â”‚  â”œâ”€ Route tables (control traffic flow)
â”‚  â””â”€ Network ACLs (stateless rules)
â”‚
â””â”€ Firewalls
   â”œâ”€ Security groups (stateful - ALB, EC2, RDS)
   â”œâ”€ Network ACLs (stateless - subnet-level)
   â””â”€ Host-based firewalls (OS-level - ufw, iptables)

Key Metrics:
- DDoS attack mitigation time
- WAF rule effectiveness
- False positive rate
```

**Layer 2: Identity & Access (Authentication & Authorization)**
```
Purpose: Verify who you are and what you can do
Components:
â”œâ”€ Authentication (Who are you?)
â”‚  â”œâ”€ Username/password (basic, vulnerable)
â”‚  â”œâ”€ Multi-Factor Authentication (MFA)
â”‚  â”‚  â”œâ”€ Something you know (password)
â”‚  â”‚  â”œâ”€ Something you have (phone, hardware token)
â”‚  â”‚  â””â”€ Something you are (biometric)
â”‚  â”œâ”€ Federated identity (SSO, SAML, OAuth)
â”‚  â””â”€ Temporary credentials (time-limited tokens)
â”‚
â”œâ”€ Authorization (What can you do?)
â”‚  â”œâ”€ Role-based Access Control (RBAC)
â”‚  â”œâ”€ Attribute-based Access Control (ABAC)
â”‚  â”œâ”€ Policy-based access (JSON policies)
â”‚  â””â”€ Resource-based permissions (bucket policies)
â”‚
â”œâ”€ IAM Implementation
â”‚  â”œâ”€ Principle of Least Privilege (PoLP)
â”‚  â”œâ”€ Regular access reviews & audits
â”‚  â”œâ”€ Separate prod/dev credentials
â”‚  â””â”€ Automatic credential rotation
â”‚
â””â”€ Session Management
   â”œâ”€ Session timeout (force logout after X minutes)
   â”œâ”€ Concurrent session limits
   â””â”€ Session token invalidation

Key Metrics:
- Failed login attempts per user
- Unused credentials (age > 90 days)
- Overprivileged accounts (admin when they don't need it)
- MFA adoption rate
```

**Layer 3: Data Protection (Encryption)**
```
Purpose: Protect data from unauthorized access
Components:
â”œâ”€ Encryption in Transit (TLS/SSL)
â”‚  â”œâ”€ All communications over HTTPS
â”‚  â”œâ”€ TLS 1.2 minimum (TLS 1.3 preferred)
â”‚  â”œâ”€ Certificate validation
â”‚  â””â”€ Forward secrecy (ephemeral keys)
â”‚
â”œâ”€ Encryption at Rest
â”‚  â”œâ”€ Database encryption (RDS, DynamoDB)
â”‚  â”œâ”€ Storage encryption (S3, EBS)
â”‚  â”œâ”€ Backup encryption
â”‚  â””â”€ Log file encryption
â”‚
â”œâ”€ Key Management
â”‚  â”œâ”€ AWS KMS (Key Management Service)
â”‚  â”œâ”€ Customer-managed vs AWS-managed keys
â”‚  â”œâ”€ Key rotation policies (annual or more)
â”‚  â””â”€ Key access audit trail
â”‚
â”œâ”€ Secrets Management
â”‚  â”œâ”€ AWS Secrets Manager (automatic rotation)
â”‚  â”œâ”€ AWS Systems Manager Parameter Store
â”‚  â”œâ”€ Vault, Consul (3rd party)
â”‚  â””â”€ Never hardcode in code/config
â”‚
â””â”€ Data Masking & Tokenization
   â”œâ”€ Redact sensitive data in logs
   â”œâ”€ Anonymize in non-prod environments
   â””â”€ Token replacement for PII

Key Metrics:
- Encryption coverage (% of data encrypted)
- Key rotation compliance
- Unencrypted data discovery
- Secret exposure detection (scanning)
```

**Layer 4: Application Security**
```
Purpose: Prevent vulnerable code from causing harm
Components:
â”œâ”€ Secure Coding Practices
â”‚  â”œâ”€ Input validation (prevent injection attacks)
â”‚  â”œâ”€ Output encoding (prevent XSS)
â”‚  â”œâ”€ Error handling (don't expose stack traces)
â”‚  â””â”€ Dependency management (patch vulnerabilities)
â”‚
â”œâ”€ OWASP Top 10 Mitigation
â”‚  â”œâ”€ A1: Broken Access Control
â”‚  â”œâ”€ A2: Cryptographic Failures
â”‚  â”œâ”€ A3: Injection (SQL, NoSQL, OS)
â”‚  â”œâ”€ A4: Insecure Design
â”‚  â”œâ”€ A5: Security Misconfiguration
â”‚  â”œâ”€ A6: Vulnerable Components
â”‚  â”œâ”€ A7: Authentication Failures
â”‚  â”œâ”€ A8: Software & Data Integrity
â”‚  â”œâ”€ A9: Logging & Monitoring Failures
â”‚  â””â”€ A10: SSRF
â”‚
â”œâ”€ Code Security
â”‚  â”œâ”€ SAST (Static Application Security Testing)
â”‚  â”œâ”€ DAST (Dynamic Application Security Testing)
â”‚  â”œâ”€ Dependency scanning (npm audit, Snyk)
â”‚  â””â”€ Container scanning (Trivy, Grype)
â”‚
â””â”€ API Security
   â”œâ”€ Rate limiting per API key
   â”œâ”€ Request validation
   â”œâ”€ Response redaction
   â””â”€ API versioning

Key Metrics:
- Vulnerability count by severity
- Time to patch vulnerabilities
- SAST findings trend
- Dependency audit findings
```

**Layer 5: Infrastructure Security**
```
Purpose: Harden OS, containers, and platform
Components:
â”œâ”€ OS Hardening
â”‚  â”œâ”€ Remove unnecessary services & packages
â”‚  â”œâ”€ Disable default accounts
â”‚  â”œâ”€ Restrict user permissions (sudo rules)
â”‚  â”œâ”€ Firewall rules (iptables, ufw)
â”‚  â””â”€ SELinux or AppArmor (MAC)
â”‚
â”œâ”€ Patching & Updates
â”‚  â”œâ”€ OS security patches (monthly)
â”‚  â”œâ”€ Application security updates (as available)
â”‚  â”œâ”€ Dependency updates (regular audits)
â”‚  â””â”€ Kernel security patches (critical priority)
â”‚
â”œâ”€ Container Security
â”‚  â”œâ”€ Non-root user in containers
â”‚  â”œâ”€ Read-only root filesystem
â”‚  â”œâ”€ Resource limits (CPU, memory)
â”‚  â”œâ”€ Network policies
â”‚  â””â”€ Pod security policies (K8s)
â”‚
â”œâ”€ Configuration Management
â”‚  â”œâ”€ Immutable infrastructure (build & replace)
â”‚  â”œâ”€ Infrastructure as Code (git-tracked)
â”‚  â”œâ”€ Configuration drift detection
â”‚  â””â”€ Automated remediation
â”‚
â””â”€ Compliance as Code
   â”œâ”€ CIS Benchmarks
   â”œâ”€ AWS Config Rules
   â”œâ”€ CloudFormation Guard
   â””â”€ Automated scanning

Key Metrics:
- Patch compliance (% systems patched)
- Configuration drift instances
- Unpatched vulnerabilities count
- Container image scan failures
```

**Layer 6: Monitoring & Incident Response**
```
Purpose: Detect and respond to security events
Components:
â”œâ”€ Security Monitoring
â”‚  â”œâ”€ CloudTrail (API audit logs)
â”‚  â”œâ”€ VPC Flow Logs (network traffic)
â”‚  â”œâ”€ CloudWatch Logs (application logs)
â”‚  â”œâ”€ GuardDuty (threat detection - AI/ML)
â”‚  â””â”€ Security Hub (centralized findings)
â”‚
â”œâ”€ Threat Detection
â”‚  â”œâ”€ Anomaly detection (unusual API calls)
â”‚  â”œâ”€ Failed login patterns
â”‚  â”œâ”€ Privilege escalation attempts
â”‚  â”œâ”€ Data exfiltration patterns
â”‚  â””â”€ Backdoor/malware indicators
â”‚
â”œâ”€ Alerting & Response
â”‚  â”œâ”€ Security alerts (SNS, email)
â”‚  â”œâ”€ Incident response runbooks
â”‚  â”œâ”€ Automated response (block IP, disable user)
â”‚  â””â”€ Escalation procedures (SIEM, SOC)
â”‚
â””â”€ Forensics & Investigation
   â”œâ”€ Log retention (1-7 years depending on compliance)
   â”œâ”€ Chain of custody procedures
   â”œâ”€ Forensic tools (Volatility, Ghidra)
   â””â”€ Timeline reconstruction

Key Metrics:
- MTTD (Mean Time to Detect) - target < 5 minutes
- MTTR (Mean Time to Respond) - target < 15 minutes
- False positive rate
- Detection coverage (% of threats detected)
- Log retention compliance
```

**Layer 7: Disaster Recovery & Resilience**
```
Purpose: Survive attacks and recover quickly
Components:
â”œâ”€ Backups & Recovery
â”‚  â”œâ”€ Regular automated backups (daily)
â”‚  â”œâ”€ Off-site backup storage (different region)
â”‚  â”œâ”€ Backup encryption
â”‚  â”œâ”€ Recovery Point Objective (RPO) - data loss tolerance
â”‚  â”œâ”€ Recovery Time Objective (RTO) - downtime tolerance
â”‚  â””â”€ Backup testing (restore drills)
â”‚
â”œâ”€ High Availability
â”‚  â”œâ”€ Multi-AZ deployment
â”‚  â”œâ”€ Load balancing & failover
â”‚  â”œâ”€ Database replication
â”‚  â”œâ”€ Asynchronous replication (RPO > 0)
â”‚  â””â”€ Synchronous replication (RPO = 0, slower)
â”‚
â”œâ”€ Disaster Recovery
â”‚  â”œâ”€ Warm standby (secondary in different region)
â”‚  â”œâ”€ Hot standby (active-active replication)
â”‚  â”œâ”€ DR plan and runbook
â”‚  â”œâ”€ Regular DR drills (quarterly)
â”‚  â””â”€ Terraform recovery (infrastructure as code)
â”‚
â”œâ”€ Business Continuity
â”‚  â”œâ”€ Critical service identification
â”‚  â”œâ”€ Dependency mapping
â”‚  â”œâ”€ Escalation procedures
â”‚  â””â”€ Communication plan
â”‚
â””â”€ Resilience Architecture
   â”œâ”€ Circuit breakers (fail fast)
   â”œâ”€ Retry logic with exponential backoff
   â”œâ”€ Graceful degradation
   â”œâ”€ Rate limiting & throttling
   â””â”€ Health checks & auto-healing

Key Metrics:
- RPO and RTO compliance
- Backup success rate
- Restore time verification
- Failover time
- DR drill frequency & success
- Uptime percentage (99.9%, 99.99%)
```

### Security Principles & Frameworks

**Principle of Least Privilege (PoLP)**
```
Definition: Grant minimum permissions necessary for task completion

Application:
â”œâ”€ IAM: Users get specific permissions, not admin access
â”œâ”€ Database: App user can SELECT, not DROP tables
â”œâ”€ Filesystem: Files have restrictive permissions (750)
â”œâ”€ Network: Only allow required ports, deny all else
â””â”€ API: Token scopes limited to required endpoints

Implementation:
1. Start with NO permissions (deny by default)
2. Grant ONLY what's needed (whitelist approach)
3. Use time-limited credentials
4. Review periodically (quarterly audits)
5. Revoke when no longer needed

Example:
âœ— Developer has AWS Admin access (overprivileged)
âœ“ Developer has read-only EC2 + S3 bucket access (least privilege)
```

**Zero Trust Architecture (Never Trust, Always Verify)**
```
Principles:
â”œâ”€ Assume Breach: Threats exist inside and outside
â”œâ”€ Verify Explicitly: All access requires authentication/authorization
â”œâ”€ Secure by Default: Deny by default, allow specific
â”œâ”€ Monitor Continuously: Track all access and behavior
â”œâ”€ Protect Data: Encrypt, classify, control
â””â”€ Focus on Identity: Identity is the new perimeter

Implementation:
1. Authenticate every request (no implicit trust)
2. Authorize based on context (device, location, time)
3. Encrypt all communication (TLS end-to-end)
4. Monitor all access (comprehensive logging)
5. Validate device health (antivirus, patches updated)

Traditional vs Zero Trust:
Traditional (Perimeter-based):
  Internet â†’ DMZ â†’ Internal Network â†’ Servers
  âœ— Trust inside network
  âœ— Single perimeter breach = full access
  âœ— Lateral movement easy

Zero Trust (Identity-based):
  Every access point requires:
  1. Authentication (who are you?)
  2. Authorization (what can you do?)
  3. Device health check (is your machine secure?)
  4. Monitoring (logging every access)
```

**Defense in Depth**
```
Concept: Multiple layers of security controls
Rationale: If one layer fails, others still protect

Example Stack:
1. DDoS Protection (CloudFlare/Shield)
2. WAF (rate limiting, SQL injection)
3. ALB + Security Groups
4. VPC segmentation + NACLs
5. IAM + MFA authentication
6. Encryption in transit (TLS)
7. Encryption at rest (KMS)
8. Application-level validation
9. Logging + anomaly detection
10. Incident response + DR

Benefit: Attacker must break through multiple layers
Cost: Complexity, but worth it for critical systems
```

**Shared Responsibility Model (AWS)**
```
AWS Responsible For:
â”œâ”€ Physical security (data centers)
â”œâ”€ Network security (DDoS, firewalls)
â”œâ”€ Infrastructure (hypervisor, virtualization)
â”œâ”€ Managed services (RDS, DynamoDB, Lambda)
â””â”€ Compliance infrastructure (monitoring, logging)

Customer Responsible For:
â”œâ”€ IAM & access control
â”œâ”€ Application security (code)
â”œâ”€ Data classification & encryption
â”œâ”€ Network configuration
â”œâ”€ OS patching (EC2, containers)
â”œâ”€ Firewall rules & NACLs
â”œâ”€ Secrets management
â”œâ”€ Backup & disaster recovery
â””â”€ Compliance verification

Not a Shared Responsibility:
â”œâ”€ Customer data (you own it)
â”œâ”€ Your applications (you secure them)
â”œâ”€ Your business logic (you verify)
â””â”€ Your compliance (you prove it)
```

---

## Network Security (Comprehensive Theory)

### Network Segmentation Theory

**Why Segment Networks?**
```
Without Segmentation (Flat Network):
  Attacker compromises 1 server â†’ Access to ALL servers
  Problem: Lateral movement unrestricted
  
With Segmentation (Layered Network):
  Attacker compromises 1 server â†’ Trapped in DMZ
  Cannot access backend database/cache
  Lateral movement blocked by security groups
  Detected faster when unusual access attempted
```

**OSI Model Approach to Network Security**
```
Layer 7 (Application):    WAF - block malicious requests
Layer 6 (Presentation):   TLS - encrypt data
Layer 5 (Session):        Session management, timeouts
Layer 4 (Transport):      NACLs, security groups (port-level)
Layer 3 (Network):        Routing, VPC CIDR blocks, VPN
Layer 2 (Data Link):      MAC filtering (advanced)
Layer 1 (Physical):       Data center security (AWS responsibility)
```

**Network Architecture: Three-Tier Model**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  INTERNET (Public World)                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TIER 1: DMZ / Public Tier                            â”‚
â”‚  â”œâ”€ Load Balancers (ALB, NLB)                        â”‚
â”‚  â”œâ”€ NAT Gateways (for outbound)                      â”‚
â”‚  â”œâ”€ CloudFront / CDN                                â”‚
â”‚  â””â”€ Public EC2 (Bastion hosts)                      â”‚
â”‚  CIDR: 10.0.0.0/24 - 10.0.1.0/24                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        SG: Allow 80/443 from internet
                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TIER 2: Application / Private Tier                  â”‚
â”‚  â”œâ”€ Web servers (Node, Python, Java)                â”‚
â”‚  â”œâ”€ App servers (microservices)                     â”‚
â”‚  â”œâ”€ Cache layer (Redis, Memcached)                 â”‚
â”‚  â””â”€ Message queues (RabbitMQ, SQS)                 â”‚
â”‚  CIDR: 10.0.10.0/24 - 10.0.11.0/24                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        SG: Allow 8080-8090 from ALB only
                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TIER 3: Data / Database Tier                        â”‚
â”‚  â”œâ”€ RDS (PostgreSQL, MySQL)                         â”‚
â”‚  â”œâ”€ DynamoDB (NoSQL)                                â”‚
â”‚  â”œâ”€ Elasticsearch                                   â”‚
â”‚  â””â”€ Backups & Snapshots                             â”‚
â”‚  CIDR: 10.0.20.0/24 - 10.0.21.0/24                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        SG: Allow 5432/3306 from App tier only
        NACL: Deny all outbound (database shouldn't initiate)
```

**Subnet Design Principles**
```
Public Subnets:
â”œâ”€ Have route to Internet Gateway (IGW)
â”œâ”€ Instances get public IPs
â”œâ”€ Accessible from internet
â”œâ”€ Contains: Load Balancers, NAT Gateways, Bastion Hosts
â””â”€ Should have MINIMAL instances

Private Subnets:
â”œâ”€ No direct internet access
â”œâ”€ No public IPs
â”œâ”€ Access internet through NAT Gateway (in public subnet)
â”œâ”€ Contains: Web servers, app servers, databases
â””â”€ Should have MOST instances

Database/Isolated Subnets:
â”œâ”€ No internet access (not even through NAT)
â”œâ”€ Can only be reached from app tier
â”œâ”€ Contains: Databases, sensitive data
â””â”€ Most restricted tier

Multi-AZ Deployment:
  â”œâ”€ Public Subnet 1 (us-east-1a) + Public Subnet 2 (us-east-1b)
  â”œâ”€ Private Subnet 1 (us-east-1a) + Private Subnet 2 (us-east-1b)
  â”œâ”€ Database Subnet 1 (us-east-1a) + Database Subnet 2 (us-east-1b)
  â””â”€ High availability: AZ failure doesn't cause outage

CIDR Planning:
  VPC: 10.0.0.0/16 (65,536 IP addresses)
  â”œâ”€ Public: 10.0.0.0/24 (256 IPs), 10.0.1.0/24
  â”œâ”€ Private: 10.0.10.0/24 (256 IPs), 10.0.11.0/24
  â””â”€ Database: 10.0.20.0/24 (256 IPs), 10.0.21.0/24
  
  Reserve 10.0.128.0/17 for future expansion
```

```hcl
resource "aws_vpc" "main" {
  cidr_block           = "10.0.0.0/16"
  enable_dns_hostnames = true
  enable_dns_support   = true
}

# DMZ/Public subnets (web tier)
resource "aws_subnet" "public" {
  count                   = 2
  vpc_id                  = aws_vpc.main.id
  cidr_block              = "10.0.${count.index + 1}.0/24"
  availability_zone       = data.aws_availability_zones.available.names[count.index]
  map_public_ip_on_launch = true
  
  tags = { Name = "public-subnet-${count.index + 1}" }
}

# Private subnets (application tier)
resource "aws_subnet" "private" {
  count             = 2
  vpc_id            = aws_vpc.main.id
  cidr_block        = "10.0.${count.index + 10}.0/24"
  availability_zone = data.aws_availability_zones.available.names[count.index]
  
  tags = { Name = "private-subnet-${count.index + 1}" }
}

# Database subnets (isolated data tier)
resource "aws_subnet" "database" {
  count             = 2
  vpc_id            = aws_vpc.main.id
  cidr_block        = "10.0.${count.index + 20}.0/24"
  availability_zone = data.aws_availability_zones.available.names[count.index]
  
  tags = { Name = "database-subnet-${count.index + 1}" }
}

# Internet Gateway (for public subnets)
resource "aws_internet_gateway" "main" {
  vpc_id = aws_vpc.main.id
  tags   = { Name = "main-igw" }
}

# NAT Gateway (for private subnets outbound)
resource "aws_eip" "nat" {
  count  = 2
  domain = "vpc"
  tags   = { Name = "nat-eip-${count.index + 1}" }
  
  depends_on = [aws_internet_gateway.main]
}

resource "aws_nat_gateway" "main" {
  count         = 2
  allocation_id = aws_eip.nat[count.index].id
  subnet_id     = aws_subnet.public[count.index].id
  
  tags = { Name = "nat-gw-${count.index + 1}" }
}
```

### Security Group and NACL Implementation Details

**Security Groups (Stateful Firewall) - Complete Implementation**

```hcl
# ALB Security Group
resource "aws_security_group" "alb" {
  name_prefix = "alb-"
  vpc_id      = aws_vpc.main.id
  
  # Allow HTTPS from internet
  ingress {
    from_port   = 443
    to_port     = 443
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
    description = "HTTPS from internet"
  }
  
  # Allow HTTP redirect
  ingress {
    from_port   = 80
    to_port     = 80
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
    description = "HTTP redirect"
  }
  
  # Allow all outbound
  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }
  
  tags = { Name = "alb-sg" }
}

# Application Security Group
resource "aws_security_group" "app" {
  name_prefix = "app-"
  vpc_id      = aws_vpc.main.id
  
  # Allow from ALB only
  ingress {
    from_port       = 8080
    to_port         = 8080
    protocol        = "tcp"
    security_groups = [aws_security_group.alb.id]
    description     = "App traffic from ALB"
  }
  
  # Allow outbound to database
  egress {
    from_port       = 5432
    to_port         = 5432
    protocol        = "tcp"
    security_groups = [aws_security_group.database.id]
    description     = "Database access"
  }
}

# Database Security Group
resource "aws_security_group" "database" {
  name_prefix = "database-"
  vpc_id      = aws_vpc.main.id
  
  # Allow from application tier only
  ingress {
    from_port       = 5432
    to_port         = 5432
    protocol        = "tcp"
    security_groups = [aws_security_group.app.id]
    description     = "PostgreSQL from app tier"
  }
  
  # Deny all outbound (database doesn't initiate connections)
  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = []
    description = "Deny all outbound"
  }
  
  tags = { Name = "database-sg" }
}
```

**Security Groups vs NACLs: Comprehensive Comparison**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Feature             â”‚ Security Groups      â”‚ NACLs              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Layer               â”‚ Instance level       â”‚ Subnet level       â”‚
â”‚ State               â”‚ STATEFUL             â”‚ STATELESS          â”‚
â”‚ Rules               â”‚ Allow + Implicit     â”‚ Allow + Explicit   â”‚
â”‚                     â”‚ deny all             â”‚ deny all           â”‚
â”‚ Evaluation          â”‚ Unordered (all eval) â”‚ Ordered (first     â”‚
â”‚                     â”‚                      â”‚ match wins)        â”‚
â”‚ Scope               â”‚ Attached to ENI      â”‚ Attached to subnet â”‚
â”‚ Replication         â”‚ Auto replies         â”‚ Manual replies     â”‚
â”‚ Performance         â”‚ Slightly slower      â”‚ Very fast          â”‚
â”‚ IPv6                â”‚ Yes                  â”‚ Yes                â”‚
â”‚ Default Rules       â”‚ Implicit deny ingressâ”‚ Explicit deny 32768â”‚
â”‚                     â”‚ Allow all egress     â”‚ for ephemeral      â”‚
â”‚ Rule Limit          â”‚ 120 rules            â”‚ 20 rules (soft)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

STATEFUL vs STATELESS:

Security Groups (STATEFUL):
  Inbound Rule:  Allow TCP 443 from 0.0.0.0/0
  â†“
  Client connects to server:
  Server receives packet â†’ Matches rule â†’ ALLOW âœ“
  â†“
  Client receives response from server:
  Server sends response â†’ No explicit inbound rule needed
  BUT stateful tracking remembers the outbound connection
  Response allowed automatically âœ“

NACLs (STATELESS):
  Inbound Rule 100:  Allow TCP 443 from 0.0.0.0/0
  Outbound Rule 100: Allow TCP 1024-65535 to 0.0.0.0/0 (ephemeral)
  â†“
  Client connects to server:
  Server receives packet â†’ Matches inbound rule 100 â†’ ALLOW âœ“
  â†“
  Client receives response from server:
  Server sends response â†’ Must match outbound rule (ephemeral range)
  Response matches 1024-65535 â†’ ALLOW âœ“
  
  Without ephemeral range in NACL:
  Response sent â†’ No matching outbound rule â†’ DENY âœ—
  Connection fails silently (worst debugging nightmare!)

When to Use Each:
â”œâ”€ Security Groups: PRIMARY - Use for 95% of filtering
â”‚  â”œâ”€ Fine-grained control (port ranges, protocols)
â”‚  â”œâ”€ Easier to understand and troubleshoot
â”‚  â”œâ”€ Stateful = less rules needed
â”‚  â””â”€ Performance is adequate
â”‚
â””â”€ NACLs: SECONDARY - Use for additional protection
   â”œâ”€ Subnet-level blocking (protect multiple instances)
   â”œâ”€ Deny specific traffic (override security groups)
   â”œâ”€ Additional compliance requirement
   â””â”€ High-traffic filtering (performance advantage)
```

**Security Group Best Practices**

```
1. Principle of Least Privilege
   âœ— Bad:   Allow 0.0.0.0/0 (entire internet)
   âœ“ Good:  Allow 10.0.10.0/24 (app tier only)
   âœ“ Better: Allow sg-xxxxx (reference security group)

2. Layered Security Groups
   âœ— One massive SG with hundreds of rules
   âœ“ Separate SGs: ALB, App, Database, Cache
   âœ“ Each SG handles one tier with focused rules

3. Document with Descriptions
   âœ— ingress {
        from_port = 8080
        to_port = 8080
      }
   âœ“ ingress {
        from_port = 8080
        to_port = 8080
        description = "App traffic from ALB for health checks"
      }

4. Reference Security Groups (Not CIDR)
   âœ— ingress {
        cidr_blocks = ["10.0.10.0/24"]  # Breaks if app tier expands
      }
   âœ“ ingress {
        security_groups = [aws_security_group.app.id]  # Dynamic
      }

5. Separate Inbound and Egress Rules
   - Inbound: Be restrictive (allow specific sources only)
   - Egress: Consider what services NEED to reach (not allow-all)
   - Example: Database shouldn't need outbound internet access

6. Avoid Circular Dependencies
   âœ— ALB SG references App SG, App SG references ALB SG
     Creates Terraform circular dependency
   âœ“ Create separate rules after initial SG creation

7. Regular Audits
   - Quarterly: Review all security groups
   - Remove unused rules (rules that never match)
   - Check for overly permissive rules (0.0.0.0/0)
   - Monitor with AWS Config rules
```

**NACL Best Practices**

```
1. Always Configure Both Inbound and Outbound
   âœ— Configure inbound only
     Outbound defaults to ALLOW â†’ Potential data exfiltration
   âœ“ Configure both with explicit deny rules

2. Remember Ephemeral Ports (1024-65535)
   âœ— Forget to allow return traffic
   âœ“ Always allow 1024-65535 for responses

3. Use Rule Numbers Strategically
   Rule 100: Allow critical traffic
   Rule 200: Allow secondary traffic
   Rule 32767: Explicit deny all (AWS default)
   
   Leaves room (101-199) for future rules

4. Keep NACL Rules Minimal
   - NACLs should have < 20 rules (soft limit 20)
   - Use Security Groups for detailed filtering
   - NACLs for subnet-level, broad policies

5. Test NACL Changes
   - Changes take effect immediately
   - Test from instance in subnet
   - Use traceroute/netstat to debug
   - Have rollback plan ready

6. Document Network Diagram
   - Visual of inbound/outbound rules
   - Clear dependencies between layers
   - Help new team members understand
```

```hcl
# Database subnet NACL - strict access control
resource "aws_network_acl" "database" {
  vpc_id     = aws_vpc.main.id
  subnet_ids = aws_subnet.database[*].id
  
  # Allow inbound from application tier
  ingress {
    protocol   = "tcp"
    rule_no    = 100
    action     = "allow"
    cidr_block = "10.0.10.0/23"  # App tier CIDR
    from_port  = 5432
    to_port    = 5432
  }
  
  # Allow ephemeral ports for responses
  ingress {
    protocol   = "tcp"
    rule_no    = 110
    action     = "allow"
    cidr_block = "10.0.10.0/23"
    from_port  = 1024
    to_port    = 65535
  }
  
  # Deny all other inbound traffic
  ingress {
    protocol   = "-1"
    rule_no    = 200
    action     = "deny"
    cidr_block = "0.0.0.0/0"
    from_port  = 0
    to_port    = 0
  }
  
  # Allow all outbound (implicit for stateless)
  egress {
    protocol   = "-1"
    rule_no    = 100
    action     = "allow"
    cidr_block = "0.0.0.0/0"
    from_port  = 0
    to_port    = 0
  }
  
  tags = { Name = "database-nacl" }
}
```

### Web Application Firewall (WAF)

```hcl
resource "aws_wafv2_web_acl" "main" {
  name  = "application-waf"
  scope = "CLOUDFRONT"
  
  default_action {
    allow {}
  }
  
  # Rule 1: Rate limiting
  rule {
    name     = "rate-limit-rule"
    priority = 1
    action {
      block {
        custom_response {
          response_code = 429
        }
      }
    }
    
    statement {
      rate_based_statement {
        limit              = 2000
        aggregate_key_type = "IP"
        
        # Rate limit per custom key (e.g., user ID)
        scope_down_statement {
          byte_match_statement {
            field_to_match {
              uri_path {}
            }
            text_transformation {
              priority = 0
              type     = "URL_DECODE"
            }
            positional_constraint = "STARTS_WITH"
            search_string         = "/api/"
            operator              = "EQ"
          }
        }
      }
    }
    
    visibility_config {
      cloudwatch_metrics_enabled = true
      metric_name                = "rate-limit-metric"
      sampled_requests_enabled   = true
    }
  }
  
  # Rule 2: SQL Injection protection
  rule {
    name     = "sql-injection-rule"
    priority = 2
    action {
      block {}
    }
    
    statement {
      managed_rule_group_statement {
        name        = "AWSManagedRulesSQLiRuleSet"
        vendor_name = "AWS"
      }
    }
    
    visibility_config {
      cloudwatch_metrics_enabled = true
      metric_name                = "sql-injection-metric"
      sampled_requests_enabled   = true
    }
  }
  
  # Rule 3: XSS protection
  rule {
    name     = "xss-protection-rule"
    priority = 3
    action {
      block {}
    }
    
    statement {
      managed_rule_group_statement {
        name        = "AWSManagedRulesKnownBadInputsRuleSet"
        vendor_name = "AWS"
      }
    }
    
    visibility_config {
      cloudwatch_metrics_enabled = true
      metric_name                = "xss-metric"
      sampled_requests_enabled   = true
    }
  }
  
  # Rule 4: Geo-blocking (optional)
  rule {
    name     = "geo-blocking-rule"
    priority = 4
    action {
      block {}
    }
    
    statement {
      geo_match_statement {
        country_codes = ["KP", "IR"]  # North Korea, Iran
      }
    }
    
    visibility_config {
      cloudwatch_metrics_enabled = true
      metric_name                = "geo-block-metric"
      sampled_requests_enabled   = true
    }
  }
  
  visibility_config {
    cloudwatch_metrics_enabled = true
    metric_name                = "application-waf-metrics"
    sampled_requests_enabled   = true
  }
  
  tags = { Name = "application-waf" }
}
```

---

### IAM Best Practices Checklist

**Authentication Security**
```
â˜ Enable MFA on all human users (especially admin/privileged)
  - Email MFA (least secure)
  - SMS MFA (vulnerable to sim-swap)
  - Virtual MFA app (Authy, Google Authenticator - better)
  - Hardware token (most secure)

â˜ Rotate credentials regularly
  - Access keys: Every 90 days
  - Passwords: Every 90 days
  - Temporary credentials: Auto-rotated (no action needed)

â˜ Use temporary credentials wherever possible
  - EC2 instances: Use IAM roles (temporary)
  - Lambda: Use IAM roles (temporary)
  - Mobile apps: Use Cognito/temporary tokens
  - Cross-account: Use STS AssumeRole (temporary)

â˜ Implement password policies
  - Minimum 14 characters
  - Require uppercase, lowercase, numbers, symbols
  - Prevent reuse of last 24 passwords
  - Require MFA for console access
```

**Authorization & Permissions**
```
â˜ Start with DENY by default
  - Don't attach AdministratorAccess
  - Explicitly list allowed actions
  - Use condition keys for additional restrictions

â˜ Use roles instead of users for applications
  - âœ— Create IAM user for EC2 instance
  - âœ“ Attach IAM role to EC2 instance
  - Credentials auto-rotated, no key rotation needed

â˜ Implement permission boundaries
  - Set maximum permissions for user/role
  - Limits what admins can grant
  - Safety net: "Never grant more than X permissions"

â˜ Use resource-based policies for cross-account access
  - More secure than long-term cross-account keys
  - Grants access to assume role in other account
  - Can include external ID for additional safety
```

**Governance & Compliance**
```
â˜ Regular access reviews
  - Quarterly: Review all user permissions
  - Remove unused permissions
  - Remove unused users
  - Verify MFA enabled on all accounts

â˜ Enable AWS IAM Access Analyzer
  - Identifies overprivileged users
  - Detects unused permissions
  - Recommends permission reduction

â˜ Implement SCPs (Service Control Policies)
  - Organization-wide maximum permissions
  - Prevent services in non-approved regions
  - Block termination of critical resources
  - Enforce tag requirements

â˜ Logging & Monitoring
  - CloudTrail: Track all IAM changes
  - CloudWatch: Alert on privilege escalation attempts
  - Suppress logs for low-risk actions (DescribeInstances)
  - Focus logs on high-risk (DeleteUser, ModifyPolicy)
```

**Common IAM Mistakes & How to Avoid**

```
Mistake #1: Hardcoding AWS Credentials
âŒ Wrong:
  AWS_ACCESS_KEY_ID=AKIAIOSFODNN7EXAMPLE
  AWS_SECRET_ACCESS_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY

âœ… Right:
  Use IAM roles (EC2, Lambda, ECS)
  Use environment variables (managed by platform)
  Use credential profiles (~/.aws/credentials with MFA)
  Use temporary credentials (STS)

Mistake #2: Creating IAM User for Application
âŒ Wrong:
  resource "aws_iam_user" "app_service" {
    name = "my-app"
  }
  # Access key gets compromised
  # App has long-term credentials
  # Manual rotation required

âœ… Right:
  resource "aws_iam_role" "app_service" {
    name = "my-app-role"
    assume_role_policy = jsonencode({
      Principal = { Service = "ec2.amazonaws.com" }
    })
  }
  # Automatic credential rotation (hourly)
  # Short-lived temporary credentials
  # No manual key management

Mistake #3: Using Root Account for Daily Work
âŒ Wrong:
  All operations with root account
  # Root cannot be restricted
  # Cannot use MFA with certain services
  # If compromised: Complete account takeover

âœ… Right:
  Root account: Only for account setup, recovery, billing
  Daily work: Use IAM users/roles with minimal permissions
  Privileged operations: Use switch role (assume role) with MFA

Mistake #4: Overly Permissive S3 Bucket Policy
âŒ Wrong:
  resource "aws_s3_bucket_policy" "allow_all" {
    bucket = aws_s3_bucket.data.id
    policy = jsonencode({
      Version = "2012-10-17"
      Statement = [{
        Effect = "Allow"
        Principal = "*"          # Anyone!
        Action = "s3:GetObject"
        Resource = "${aws_s3_bucket.data.arn}/*"
      }]
    })
  }
  # Anyone can read your data
  # GDPR/HIPAA violation if sensitive data

âœ… Right:
  resource "aws_s3_bucket_policy" "allow_specific" {
    bucket = aws_s3_bucket.data.id
    policy = jsonencode({
      Version = "2012-10-17"
      Statement = [{
        Effect = "Allow"
        Principal = {
          AWS = aws_iam_role.app_role.arn
        }
        Action = "s3:GetObject"
        Resource = "${aws_s3_bucket.data.arn}/public/*"  # Only specific prefix
        Condition = {
          IpAddress = {
            "aws:SourceIp" = ["10.0.0.0/8"]  # Only from VPC
          }
        }
      }]
    })
  }

Mistake #5: Granting Full Service Permissions
âŒ Wrong:
  "Action": "s3:*"      # All S3 permissions
  "Action": "ec2:*"     # All EC2 permissions

âœ… Right:
  "Action": [
    "s3:GetObject",         # Only what's needed
    "s3:ListBucket"
  ]
  "Action": [
    "ec2:DescribeInstances",
    "ec2:GetConsoleOutput"
  ]
```

```hcl
# âŒ Bad: Admin access for everyone
resource "aws_iam_role" "developer" {
  name = "developer-role"
  
  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [{
      Effect    = "Allow"
      Principal = { AWS = "arn:aws:iam::ACCOUNT:user/john" }
      Action    = "sts:AssumeRole"
    }]
  })
}

resource "aws_iam_role_policy_attachment" "admin" {
  role       = aws_iam_role.developer.name
  policy_arn = "arn:aws:iam::aws:policy/AdministratorAccess"
}

# âœ… Good: Specific permissions only
resource "aws_iam_policy" "developer" {
  name = "developer-policy"
  
  policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Sid    = "EC2ReadOnly"
        Effect = "Allow"
        Action = [
          "ec2:DescribeInstances",
          "ec2:DescribeSecurityGroups",
          "ec2:DescribeNetworkInterfaces"
        ]
        Resource = "*"
      },
      {
        Sid    = "S3DevBucket"
        Effect = "Allow"
        Action = [
          "s3:GetObject",
          "s3:PutObject",
          "s3:DeleteObject"
        ]
        Resource = "arn:aws:s3:::dev-bucket/developers/*"
      },
      {
        Sid    = "CloudWatchLogs"
        Effect = "Allow"
        Action = [
          "logs:GetLogEvents",
          "logs:FilterLogEvents"
        ]
        Resource = "arn:aws:logs:*:*:log-group:/app/*"
      },
      {
        Sid    = "DenyDangerousActions"
        Effect = "Deny"
        Action = [
          "iam:*",
          "organizations:*",
          "account:*"
        ]
        Resource = "*"
      }
    ]
  })
}

resource "aws_iam_role_policy_attachment" "developer" {
  role       = aws_iam_role.developer.name
  policy_arn = aws_iam_policy.developer.arn
}
```

### Use Roles for Applications (No Long-Lived Keys)

```hcl
# Application role for EC2
resource "aws_iam_role" "app_role" {
  name = "app-ec2-role"
  
  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [{
      Effect    = "Allow"
      Principal = { Service = "ec2.amazonaws.com" }
      Action    = "sts:AssumeRole"
    }]
  })
}

resource "aws_iam_role_policy" "app_policy" {
  name = "app-policy"
  role = aws_iam_role.app_role.id
  
  policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Effect = "Allow"
        Action = [
          "s3:GetObject",
          "s3:PutObject"
        ]
        Resource = "arn:aws:s3:::app-bucket/*"
      },
      {
        Effect = "Allow"
        Action = [
          "secretsmanager:GetSecretValue"
        ]
        Resource = "arn:aws:secretsmanager:*:*:secret:app/*"
      },
      {
        Effect = "Allow"
        Action = [
          "kms:Decrypt"
        ]
        Resource = aws_kms_key.app.arn
      }
    ]
  })
}

# Instance profile to attach role
resource "aws_iam_instance_profile" "app_profile" {
  name = "app-instance-profile"
  role = aws_iam_role.app_role.name
}

resource "aws_instance" "app" {
  ami                  = data.aws_ami.ubuntu.id
  instance_type        = "t3.medium"
  iam_instance_profile = aws_iam_instance_profile.app_profile.name
  
  tags = { Name = "app-server" }
}
```

### Cross-Account Access

```hcl
# Trust role in secondary account
resource "aws_iam_role" "cross_account" {
  name = "cross-account-access"
  
  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [{
      Effect    = "Allow"
      Principal = { AWS = "arn:aws:iam::PRIMARY_ACCOUNT:root" }
      Action    = "sts:AssumeRole"
      Condition = {
        StringEquals = {
          "sts:ExternalId" = "unique-external-id-12345"
        }
      }
    }]
  })
}

resource "aws_iam_role_policy" "cross_account_policy" {
  name = "cross-account-policy"
  role = aws_iam_role.cross_account.id
  
  policy = jsonencode({
    Version = "2012-10-17"
    Statement = [{
      Effect = "Allow"
      Action = [
        "ec2:*",
        "s3:*"
      ]
      Resource = "*"
    }]
  })
}

# Primary account user assumes role
resource "aws_iam_user" "primary_user" {
  name = "cross-account-user"
}

resource "aws_iam_user_policy" "assume_cross_account" {
  name = "assume-cross-account-policy"
  user = aws_iam_user.primary_user.name
  
  policy = jsonencode({
    Version = "2012-10-17"
    Statement = [{
      Effect = "Allow"
      Action = "sts:AssumeRole"
      Resource = "arn:aws:iam::SECONDARY_ACCOUNT:role/cross-account-access"
      Condition = {
        StringEquals = {
          "sts:ExternalId" = "unique-external-id-12345"
        }
      }
    }]
  })
}
```

### IAM Best Practices

```hcl
# 1. Enable MFA for console access
resource "aws_iam_user" "admin" {
  name = "admin-user"
}

# MFA requirement enforced via policy

# 2. Regular audit of permissions
resource "aws_iam_access_analyzer" "main" {
  analyzer_name = "organization-analyzer"
  type          = "ACCOUNT"
  
  tags = { Environment = "production" }
}

# 3. Use service control policies
resource "aws_organizations_policy" "restrict_regions" {
  content = jsonencode({
    Version = "2012-10-17"
    Statement = [{
      Effect    = "Deny"
      Action    = "*"
      Resource  = "*"
      Condition = {
        StringNotEquals = {
          "aws:RequestedRegion" = [
            "us-east-1",
            "us-west-2",
            "eu-west-1"
          ]
        }
      }
    }]
  })
  
  name = "restrict-regions-policy"
  type = "SERVICE_CONTROL_POLICY"
}

# 4. Rotate access keys regularly
resource "aws_iam_access_key" "user" {
  user = aws_iam_user.developer.name
}

# 5. Use conditions for additional security
resource "aws_iam_policy" "conditional_access" {
  policy = jsonencode({
    Version = "2012-10-17"
    Statement = [{
      Effect   = "Allow"
      Action   = "s3:GetObject"
      Resource = "arn:aws:s3:::secure-bucket/*"
      Condition = {
        IpAddress = {
          "aws:SourceIp" = ["10.0.0.0/8"]
        }
        StringEquals = {
          "aws:username" = "admin"
        }
      }
    }]
  })
}
```

---

## Data Protection & Encryption (Comprehensive Theory)

### Encryption Fundamentals

**What is Encryption?**
```
Definition: Converting readable data (plaintext) into unreadable format (ciphertext)
using a key, so only authorized parties can decrypt.

Simple Example:
  Plaintext:      "Hello"
  + Encryption Key: "SecureKey123"
  + Encryption Algorithm: AES-256
  = Ciphertext: "7x9@#$%K2m"
  
  Only someone with "SecureKey123" can decrypt back to "Hello"
```

**Symmetric vs Asymmetric Encryption**

```
SYMMETRIC ENCRYPTION (Same Key for Encrypt & Decrypt):
â”œâ”€ Algorithms: AES-256, DES (outdated), 3DES
â”œâ”€ How it works:
â”‚  Alice: "Secret message" + Key1 â†’ Encrypted
â”‚  Network: Encrypted data travels
â”‚  Bob: Encrypted + Key1 â†’ "Secret message"
â”‚
â”œâ”€ Advantages:
â”‚  âœ“ Fast (good for large data)
â”‚  âœ“ Strong encryption with short keys
â”‚  âœ“ Standard for at-rest encryption
â”‚
â”œâ”€ Disadvantages:
â”‚  âœ— Key distribution problem (how does Bob get Key1 securely?)
â”‚  âœ— No non-repudiation (both parties have same key)
â”‚
â””â”€ Use Cases:
   - Database encryption
   - Disk/EBS encryption
   - S3 object encryption
   - Backup encryption

ASYMMETRIC ENCRYPTION (Different Keys for Encrypt & Decrypt):
â”œâ”€ Algorithms: RSA, ECC, ECDSA
â”œâ”€ How it works:
â”‚  Alice: Has Bob's PUBLIC key
â”‚  Alice: "Secret message" + Bob's Public Key â†’ Encrypted
â”‚  Network: Encrypted data travels
â”‚  Bob: Encrypted + Bob's PRIVATE key â†’ "Secret message"
â”‚  Bob cannot decrypt (he doesn't have private key for encryption)
â”‚
â”œâ”€ Advantages:
â”‚  âœ“ No key distribution problem (public key is public!)
â”‚  âœ“ Non-repudiation (only sender could have encrypted)
â”‚  âœ“ Enables digital signatures
â”‚
â”œâ”€ Disadvantages:
â”‚  âœ— Slower than symmetric (not good for large data)
â”‚  âœ— Larger key sizes needed
â”‚
â””â”€ Use Cases:
   - TLS/HTTPS certificates (RSA)
   - API signing
   - Digital signatures
   - Email encryption

HYBRID ENCRYPTION (Best of Both):
  Alice â†’ Generates random symmetric key (Data Key)
  Alice â†’ Encrypts message with Data Key (symmetric, fast)
  Alice â†’ Encrypts Data Key with Bob's public key (asymmetric)
  Alice â†’ Sends encrypted message + encrypted data key
  Bob â†’ Decrypts data key with private key
  Bob â†’ Uses data key to decrypt message
  
  AWS KMS uses this approach!
```

**Encryption in Transit (TLS/HTTPS)**
```
Purpose: Protect data while moving over network
Threat: Man-in-the-middle (MITM) attacks, eavesdropping

TLS/HTTPS Process (Simplified):
1. Client initiates connection
2. Server sends certificate (containing public key)
3. Client verifies certificate validity
4. Client & server negotiate symmetric key (encrypted)
5. All further communication uses symmetric key
6. Attacker in middle cannot decrypt (doesn't have private key)

TLS Versions:
  âœ— SSL 3.0, TLS 1.0, 1.1 (deprecated - insecure)
  âœ“ TLS 1.2 (minimum for production)
  âœ“ TLS 1.3 (latest, fastest)

Certificate Validation:
  âœ“ Certificate matches domain (example.com certificate for example.com)
  âœ— Using self-signed certificate (no CA verification)
  âœ“ Certificate signed by trusted CA
  âœ“ Certificate not expired
  âœ“ Certificate not revoked (CRL/OCSP check)

AWS Best Practices:
  â”œâ”€ Use AWS Certificate Manager (free certificates)
  â”œâ”€ Enforce HTTPS everywhere (redirect HTTPâ†’HTTPS)
  â”œâ”€ Minimum TLS 1.2 (policy: ELBSecurityPolicy-TLS-1-2-2017-01)
  â”œâ”€ Use strong cipher suites (AES-128 GCM minimum)
  â””â”€ Enable HSTS (HTTP Strict Transport Security)
     - Tells browser: Only use HTTPS for this domain
     - Prevents downgrade attacks
```

**Encryption at Rest (KMS - Key Management Service)**
```
Purpose: Protect data stored in databases, filesystems, backups
Threat: Someone steals hard drive or snapshot

AWS KMS Architecture:
  Application â† Encrypt/Decrypt Request
    â†“
  AWS KMS (Managed Service)
    â”œâ”€ Customer Master Key (CMK)
    â”‚  â”œâ”€ AWS-managed key (simple, shared with others)
    â”‚  â””â”€ Customer-managed key (more control, separate keys)
    â”‚
    â”œâ”€ Data Key (generated from CMK)
    â”‚  â”œâ”€ Used to encrypt/decrypt actual data
    â”‚  â”œâ”€ Never leaves KMS in plaintext
    â”‚  â””â”€ Different key for each data object
    â”‚
    â””â”€ Key Rotation
       â”œâ”€ Automatic: New key generated yearly
       â”œâ”€ Old keys retained for decryption
       â””â”€ No action required (automatic)

When to Use AWS-Managed vs Customer-Managed Keys:
  AWS-Managed (aws/s3, aws/rds):
    â”œâ”€ Automatic rotation
    â”œâ”€ Low cost (free)
    â”œâ”€ Shared across accounts (multiple customers)
    â”œâ”€ No direct control
    â””â”€ Good for: Standard encryption at rest

  Customer-Managed:
    â”œâ”€ Manual rotation control
    â”œâ”€ Cost ($1/month per key)
    â”œâ”€ Individual keys per customer
    â”œâ”€ Full control (disable, schedule deletion)
    â”œâ”€ Compliance requirements (HIPAA, PCI-DSS)
    â””â”€ Good for: Sensitive data, compliance, audit requirements

Encryption at Rest: Where to Apply
  â”œâ”€ RDS / Aurora database
  â”‚  â””â”€ Enable "Storage encryption" during creation
  â”‚     (Cannot enable on existing database - must restore)
  â”‚
  â”œâ”€ EBS volumes
  â”‚  â””â”€ Enable "Encrypt this volume" during creation
  â”‚     (Can be enabled on existing volumes)
  â”‚
  â”œâ”€ S3 buckets
  â”‚  â””â”€ Default encryption: All objects encrypted with KMS
  â”‚     Block unencrypted uploads with bucket policy
  â”‚
  â”œâ”€ DynamoDB tables
  â”‚  â””â”€ Enable "Encryption at rest"
  â”‚
  â”œâ”€ CloudWatch Logs
  â”‚  â””â”€ Encrypt log group with KMS key
  â”‚
  â”œâ”€ Snapshots & Backups
  â”‚  â””â”€ Encrypted snapshots (inherited from volume/DB)
  â”‚
  â””â”€ Secrets Manager
     â””â”€ Secrets encrypted with KMS
```

**Key Rotation Strategy**
```
Why Rotate Keys?
  â”œâ”€ Limit impact of key compromise
  â”œâ”€ Comply with security policies (annually)
  â”œâ”€ Reduce exposure window if key leaked
  â””â”€ Best practice: Annual rotation minimum

Automatic Key Rotation (AWS KMS Default):
  Current year:  Use Key Version 1
  Next year:     New Key Version 2 automatically created
  Encryption:    Always uses latest version
  Decryption:    KMS tries all versions (transparent)
  
  Pro: Automatic, no operational burden
  Con: Cannot audit exactly when rotation occurred

Manual Key Rotation:
  1. Create new CMK (different key, different ID)
  2. Update application to use new key for encryption
  3. Keep old key for decryption (of historical data)
  4. Schedule old key deletion (30 days waiting period)
  
  Pro: Full control and audit trail
  Con: Manual process, more operational burden

Rotation Best Practices:
  â”œâ”€ Annual minimum (monthly if sensitive data)
  â”œâ”€ After employee departure (they might have key access)
  â”œâ”€ After security audit/incident
  â”œâ”€ Document rotation in change log
  â”œâ”€ Test rotation procedure quarterly
  â””â”€ Disable key after rotation (waiting period before deletion)
```

**Data Classification & Handling**

```
Classify Data by Sensitivity:
â”œâ”€ PUBLIC (No encryption needed)
â”‚  â””â”€ Publicly available information
â”‚     Example: Blog posts, marketing materials
â”‚
â”œâ”€ INTERNAL (Encryption recommended)
â”‚  â””â”€ Company-specific but not sensitive
â”‚     Example: Internal documentation, policies
â”‚
â”œâ”€ CONFIDENTIAL (Encryption required)
â”‚  â””â”€ Sensitive business data
â”‚     Example: Financial data, customer lists
â”‚     KMS: Customer-managed key minimum
â”‚
â””â”€ RESTRICTED (Encryption + access control required)
   â””â”€ Highly sensitive, regulated data
      Example: HIPAA (medical), PCI-DSS (payment), PII
      KMS: Customer-managed key, separate per data type
      Access: MFA, cross-account roles, audit logging

Encryption Requirements by Data Type:
  Credit Cards (PCI-DSS):
    âœ“ Encrypt in transit (TLS 1.2+)
    âœ“ Encrypt at rest (AES-256 minimum)
    âœ“ Strong access control (MFA)
    âœ“ Audit logging (CloudTrail)
    âœ“ Regular security testing
    âœ— Store in plaintext (never)
    âœ— Log sensitive data (never)

  Medical Records (HIPAA):
    âœ“ Encrypt in transit (TLS 1.2+)
    âœ“ Encrypt at rest (AES-256 minimum)
    âœ“ Strong access control (MFA)
    âœ“ Audit logging (CloudTrail, VPC Flow Logs)
    âœ“ Automatic logout (15 min idle)
    âœ“ Incident response plan
    âœ— Store unencrypted (never)

  Personally Identifiable Info (GDPR):
    âœ“ Encrypt in transit
    âœ“ Encrypt at rest
    âœ“ Right to be forgotten (data deletion)
    âœ“ Data portability
    âœ“ Breach notification (72 hours)
    âœ“ Data processing agreements (DPA)
    âœ— Retain longer than necessary
```

```hcl
# ALB with HTTPS
resource "aws_lb" "main" {
  name               = "application-alb"
  load_balancer_type = "application"
  security_groups    = [aws_security_group.alb.id]
  subnets            = aws_subnet.public[*].id
  
  tags = { Name = "application-alb" }
}

# HTTPS listener
resource "aws_lb_listener" "https" {
  load_balancer_arn = aws_lb.main.arn
  port              = 443
  protocol          = "HTTPS"
  ssl_policy        = "ELBSecurityPolicy-TLS-1-2-Ext-2018-06"
  certificate_arn   = aws_acm_certificate.main.arn
  
  default_action {
    type             = "forward"
    target_group_arn = aws_lb_target_group.app.arn
  }
}

# HTTP redirect to HTTPS
resource "aws_lb_listener" "http" {
  load_balancer_arn = aws_lb.main.arn
  port              = 80
  protocol          = "HTTP"
  
  default_action {
    type = "redirect"
    
    redirect {
      port        = "443"
      protocol    = "HTTPS"
      status_code = "HTTP_301"
    }
  }
}

# SSL certificate
resource "aws_acm_certificate" "main" {
  domain_name       = "example.com"
  validation_method = "DNS"
  
  lifecycle {
    create_before_destroy = true
  }
  
  tags = { Name = "example-cert" }
}

# Database force SSL
resource "aws_db_parameter_group" "postgres" {
  family = "postgres14"
  
  parameter {
    name         = "rds.force_ssl"
    value        = "1"
    apply_method = "immediate"
  }
}

resource "aws_db_instance" "postgres" {
  db_parameter_group_name = aws_db_parameter_group.postgres.name
  # ... other configuration
}
```

### Encryption at Rest (KMS)

```hcl
# KMS Master Key
resource "aws_kms_key" "main" {
  description             = "Master key for application encryption"
  deletion_window_in_days = 30
  enable_key_rotation     = true
  
  tags = { Name = "app-master-key" }
}

resource "aws_kms_alias" "main" {
  name          = "alias/app-master-key"
  target_key_id = aws_kms_key.main.key_id
}

# RDS encryption
resource "aws_db_instance" "postgres" {
  identifier            = "production-db"
  engine                = "postgres"
  engine_version        = "14.7"
  instance_class        = "db.r6i.large"
  allocated_storage     = 100
  
  storage_encrypted = true
  kms_key_id        = aws_kms_key.main.arn
  
  # ... other configuration
}

# EBS encryption
resource "aws_ebs_volume" "data" {
  availability_zone = "us-east-1a"
  size              = 500
  
  encrypted   = true
  kms_key_id  = aws_kms_key.main.arn
  
  tags = { Name = "data-volume" }
}

# EBS encryption by default
resource "aws_ebs_encryption_by_default" "main" {
  enabled = true
}

resource "aws_ebs_default_kms_key" "main" {
  kms_key_id = aws_kms_key.main.arn
}

# S3 encryption
resource "aws_s3_bucket_server_side_encryption_configuration" "data" {
  bucket = aws_s3_bucket.data.id
  
  rule {
    apply_server_side_encryption_by_default {
      sse_algorithm     = "aws:kms"
      kms_master_key_id = aws_kms_key.main.arn
    }
    bucket_key_enabled = true
  }
}

# Block unencrypted uploads
resource "aws_s3_bucket_policy" "force_encryption" {
  bucket = aws_s3_bucket.data.id
  
  policy = jsonencode({
    Version = "2012-10-17"
    Statement = [{
      Sid    = "DenyUnencryptedObjectUploads"
      Effect = "Deny"
      Principal = "*"
      Action = "s3:PutObject"
      Resource = "${aws_s3_bucket.data.arn}/*"
      Condition = {
        StringNotEquals = {
          "s3:x-amz-server-side-encryption" = "aws:kms"
        }
      }
    }]
  })
}

# CloudWatch encryption
resource "aws_cloudwatch_log_group" "app" {
  name              = "/aws/app/production"
  retention_in_days = 30
  kms_key_id        = aws_kms_key.main.arn
}

# DynamoDB encryption
resource "aws_dynamodb_table" "sessions" {
  name           = "application-sessions"
  billing_mode   = "PAY_PER_REQUEST"
  hash_key       = "SessionID"
  
  attribute {
    name = "SessionID"
    type = "S"
  }
  
  server_side_encryption {
    enabled     = true
    kms_key_arn = aws_kms_key.main.arn
  }
}
```

### Secrets Management

```hcl
# AWS Secrets Manager
resource "aws_secretsmanager_secret" "db_credentials" {
  name                    = "prod/rds/credentials"
  description             = "RDS database credentials"
  recovery_window_in_days = 7
  
  tags = { Environment = "production" }
}

resource "aws_secretsmanager_secret_version" "db_credentials" {
  secret_id = aws_secretsmanager_secret.db_credentials.id
  secret_string = jsonencode({
    username = aws_db_instance.postgres.username
    password = random_password.db.result
    engine   = "postgres"
    host     = aws_db_instance.postgres.address
    port     = aws_db_instance.postgres.port
    dbname   = aws_db_instance.postgres.db_name
  })
}

# Use in application
resource "aws_iam_policy" "access_secrets" {
  policy = jsonencode({
    Version = "2012-10-17"
    Statement = [{
      Effect = "Allow"
      Action = [
        "secretsmanager:GetSecretValue"
      ]
      Resource = [
        aws_secretsmanager_secret.db_credentials.arn
      ]
    }]
  })
}

# Systems Manager Parameter Store
resource "aws_ssm_parameter" "api_endpoint" {
  name  = "/prod/api/endpoint"
  type  = "String"
  value = aws_lb.main.dns_name
  
  tags = { Environment = "production" }
}

resource "aws_ssm_parameter" "api_key" {
  name  = "/prod/api/key"
  type  = "SecureString"
  value = random_string.api_key.result
  key_id = aws_kms_key.main.id
  
  tags = { Environment = "production" }
}

# Automatic secret rotation
resource "aws_secretsmanager_secret_rotation" "db" {
  secret_id           = aws_secretsmanager_secret.db_credentials.id
  rotation_enabled    = true
  rotation_lambda_arn = aws_lambda_function.rotate_db_password.arn
  
  rotation_rules {
    automatically_after_days = 30
  }
}
```

---

## Security Monitoring & Logging

### CloudTrail (API Audit Logging)

```hcl
# S3 bucket for CloudTrail logs
resource "aws_s3_bucket" "cloudtrail_logs" {
  bucket = "org-cloudtrail-logs-${data.aws_caller_identity.current.account_id}"
  
  tags = { Name = "cloudtrail-logs" }
}

resource "aws_s3_bucket_versioning" "cloudtrail" {
  bucket = aws_s3_bucket.cloudtrail_logs.id
  
  versioning_configuration {
    status = "Enabled"
  }
}

resource "aws_s3_bucket_server_side_encryption_configuration" "cloudtrail" {
  bucket = aws_s3_bucket.cloudtrail_logs.id
  
  rule {
    apply_server_side_encryption_by_default {
      sse_algorithm = "AES256"
    }
  }
}

resource "aws_s3_bucket_public_access_block" "cloudtrail" {
  bucket = aws_s3_bucket.cloudtrail_logs.id
  
  block_public_acls       = true
  block_public_policy     = true
  ignore_public_acls      = true
  restrict_public_buckets = true
}

# CloudTrail
resource "aws_cloudtrail" "main" {
  name                          = "organization-trail"
  s3_bucket_name                = aws_s3_bucket.cloudtrail_logs.id
  include_global_service_events = true
  is_multi_region_trail         = true
  enable_log_file_validation    = true
  depends_on                    = [aws_s3_bucket_policy.cloudtrail]
  
  tags = { Name = "organization-trail" }
}

resource "aws_s3_bucket_policy" "cloudtrail" {
  bucket = aws_s3_bucket.cloudtrail_logs.id
  
  policy = jsonencode({
    Version = "2012-10-17"
    Statement = [{
      Sid    = "AWSCloudTrailAclCheck"
      Effect = "Allow"
      Principal = { Service = "cloudtrail.amazonaws.com" }
      Action   = "s3:GetBucketAcl"
      Resource = aws_s3_bucket.cloudtrail_logs.arn
    },
    {
      Sid    = "AWSCloudTrailWrite"
      Effect = "Allow"
      Principal = { Service = "cloudtrail.amazonaws.com" }
      Action   = "s3:PutObject"
      Resource = "${aws_s3_bucket.cloudtrail_logs.arn}/*"
      Condition = {
        StringEquals = { "s3:x-amz-acl" = "bucket-owner-full-control" }
      }
    }]
  })
}
```

### VPC Flow Logs

```hcl
# IAM role for VPC Flow Logs
resource "aws_iam_role" "vpc_flow_logs" {
  name = "vpc-flow-logs-role"
  
  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [{
      Effect    = "Allow"
      Principal = { Service = "vpc-flow-logs.amazonaws.com" }
      Action    = "sts:AssumeRole"
    }]
  })
}

resource "aws_iam_role_policy" "vpc_flow_logs" {
  name = "vpc-flow-logs-policy"
  role = aws_iam_role.vpc_flow_logs.id
  
  policy = jsonencode({
    Version = "2012-10-17"
    Statement = [{
      Action = [
        "logs:CreateLogGroup",
        "logs:CreateLogStream",
        "logs:PutLogEvents",
        "logs:DescribeLogGroups",
        "logs:DescribeLogStreams"
      ]
      Effect   = "Allow"
      Resource = "*"
    }]
  })
}

# CloudWatch Log Group
resource "aws_cloudwatch_log_group" "vpc_flow_logs" {
  name              = "/aws/vpc/flowlogs"
  retention_in_days = 90
  kms_key_id        = aws_kms_key.main.arn
}

# VPC Flow Logs
resource "aws_flow_log" "vpc" {
  iam_role_arn    = aws_iam_role.vpc_flow_logs.arn
  log_destination = "${aws_cloudwatch_log_group.vpc_flow_logs.arn}:*"
  traffic_type    = "ALL"
  vpc_id          = aws_vpc.main.id
  
  tags = { Name = "vpc-flow-logs" }
}

# Alert on suspicious activity
resource "aws_cloudwatch_metric_alarm" "rejected_connections" {
  alarm_name          = "vpc-rejected-connections"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = "1"
  metric_name         = "RejectedConnectionCount"
  namespace           = "AWS/VPC"
  period              = "300"
  statistic           = "Sum"
  threshold           = "100"
  
  alarm_actions = [aws_sns_topic.security_alerts.arn]
}
```

### GuardDuty (Threat Detection)

```hcl
# Enable GuardDuty
resource "aws_guardduty_detector" "main" {
  enable = true
  
  datasources {
    s3_logs {
      enable = true
    }
    kubernetes {
      audit_logs {
        enable = true
      }
    }
  }
  
  tags = { Name = "main-detector" }
}

# CloudWatch Event Rule for GuardDuty Findings
resource "aws_cloudwatch_event_rule" "guardduty_findings" {
  name        = "guardduty-findings"
  description = "Capture GuardDuty findings"
  
  event_pattern = jsonencode({
    source      = ["aws.guardduty"]
    detail-type = ["GuardDuty Finding"]
    detail = {
      severity = [4, 7, 8]  # Medium and above
    }
  })
}

resource "aws_cloudwatch_event_target" "sns" {
  rule      = aws_cloudwatch_event_rule.guardduty_findings.name
  target_id = "GuardDutyFindings"
  arn       = aws_sns_topic.security_alerts.arn
}

# SNS topic for alerts
resource "aws_sns_topic" "security_alerts" {
  name = "security-alerts"
  
  tags = { Name = "security-alerts" }
}

resource "aws_sns_topic_subscription" "security_email" {
  topic_arn = aws_sns_topic.security_alerts.arn
  protocol  = "email"
  endpoint  = "security-team@example.com"
}
```

---

## Securing Terraform

### 1. Secure State Management

```hcl
# Remote state in S3 with encryption and locking
terraform {
  backend "s3" {
    bucket         = "organization-terraform-state"
    key            = "prod/terraform.tfstate"
    region         = "us-east-1"
    encrypt        = true
    dynamodb_table = "terraform-locks"
  }
}

# S3 bucket for state
resource "aws_s3_bucket" "terraform_state" {
  bucket = "organization-terraform-state"
  
  tags = { Name = "terraform-state" }
}

# Block public access
resource "aws_s3_bucket_public_access_block" "terraform_state" {
  bucket = aws_s3_bucket.terraform_state.id
  
  block_public_acls       = true
  block_public_policy     = true
  ignore_public_acls      = true
  restrict_public_buckets = true
}

# Enable versioning
resource "aws_s3_bucket_versioning" "terraform_state" {
  bucket = aws_s3_bucket.terraform_state.id
  
  versioning_configuration {
    status = "Enabled"
  }
}

# Server-side encryption
resource "aws_s3_bucket_server_side_encryption_configuration" "terraform_state" {
  bucket = aws_s3_bucket.terraform_state.id
  
  rule {
    apply_server_side_encryption_by_default {
      sse_algorithm     = "aws:kms"
      kms_master_key_id = aws_kms_key.terraform_state.arn
    }
  }
}

# DynamoDB table for state locking
resource "aws_dynamodb_table" "terraform_locks" {
  name           = "terraform-locks"
  billing_mode   = "PAY_PER_REQUEST"
  hash_key       = "LockID"
  
  attribute {
    name = "LockID"
    type = "S"
  }
  
  server_side_encryption {
    enabled = true
  }
  
  point_in_time_recovery {
    enabled = true
  }
  
  tags = { Name = "terraform-locks" }
}
```

### 2. Avoid Hardcoding Secrets

```hcl
# âŒ Bad: Hardcoded secrets
resource "aws_db_instance" "main" {
  password = "MySecurePassword123!"
}

# âœ… Good: Use variables with sensitive flag
variable "db_password" {
  type      = string
  sensitive = true
}

resource "aws_db_instance" "main" {
  password = var.db_password
}

# âœ… Better: Use Secrets Manager
data "aws_secretsmanager_secret_version" "db_password" {
  secret_id = "prod/rds/password"
}

resource "aws_db_instance" "main" {
  password = jsondecode(
    data.aws_secretsmanager_secret_version.db_password.secret_string
  )["password"]
}

# âœ… Best: Use Terraform Cloud variables
resource "aws_db_instance" "main" {
  password = var.db_password  # Set in Terraform Cloud UI
}
```

### 3. Regular Security Scanning

```bash
# Terraform linting and security
terraform fmt -recursive
terraform validate

# TFSec - Terraform security scanner
tfsec .

# Checkov - IaC compliance checker
checkov -d .

# Trivy - Configuration scanning
trivy config .

# Terrascan - Terraform scanning
terrascan scan -t aws
```

### 4. Code Review & CI/CD Integration

```yaml
# GitHub Actions workflow
name: Terraform Security

on: [pull_request, push]

jobs:
  security:
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v3
      
      # Format check
      - name: Terraform Format Check
        run: terraform fmt -check -recursive
      
      # Validation
      - name: Terraform Validate
        run: terraform validate
      
      # TFSec scanning
      - name: TFSec
        uses: aquasecurity/tfsec-action@v1.0.0
      
      # Checkov scanning
      - name: Checkov
        uses: bridgecrewio/checkov-action@master
      
      # Plan
      - name: Terraform Plan
        run: terraform plan -out=tfplan
      
      # Block PR if security issues found
      - name: Block on Failures
        if: failure()
        run: exit 1
```

---

## Monitoring Best Practices

### 1. Establish Baselines

```hcl
# Create comprehensive dashboards
resource "aws_cloudwatch_dashboard" "application" {
  dashboard_name = "application-health"
  
  dashboard_body = jsonencode({
    widgets = [
      {
        type = "metric"
        properties = {
          metrics = [
            ["AWS/ApplicationELB", "RequestCount", { stat = "Sum" }],
            ["AWS/ApplicationELB", "TargetResponseTime", { stat = "Average" }],
            ["AWS/ApplicationELB", "HTTPCode_Target_5XX_Count", { stat = "Sum" }],
            ["AWS/ApplicationELB", "HealthyHostCount", { stat = "Average" }],
            ["AWS/ApplicationELB", "UnHealthyHostCount", { stat = "Average" }]
          ]
          period = 60
          stat   = "Average"
          region = "us-east-1"
          title  = "Application Load Balancer"
        }
      },
      {
        type = "metric"
        properties = {
          metrics = [
            ["AWS/RDS", "CPUUtilization"],
            ["AWS/RDS", "DatabaseConnections"],
            ["AWS/RDS", "ReadLatency"],
            ["AWS/RDS", "WriteLatency"]
          ]
          title = "Database Performance"
        }
      }
    ]
  })
}
```

### 2. Anomaly Detection

```hcl
# Detect anomalies in API latency
resource "aws_cloudwatch_metric_alarm" "latency_anomaly" {
  alarm_name          = "api-latency-anomaly"
  comparison_operator = "LessThanLowerOrGreaterThanUpperThreshold"
  evaluation_periods  = "2"
  threshold_metric_id = "e1"
  
  metric_query {
    id          = "e1"
    expression  = "ANOMALY_DETECTION_BAND(m1, 2)"
    label       = "API Latency (Expected)"
    return_data = true
  }
  
  metric_query {
    id          = "m1"
    return_data = true
    metric {
      metric_name = "Latency"
      namespace   = "AWS/ApplicationELB"
      period      = "60"
      stat        = "Average"
    }
  }
  
  alarm_actions = [aws_sns_topic.alerts.arn]
}
```

### 3. Distributed Tracing

```hcl
# X-Ray sampling configuration
resource "aws_xray_sampling_rule" "main" {
  rule_name      = "default"
  priority       = 1000
  version        = 1
  reservoir_size = 1
  fixed_rate     = 0.05  # 5% of requests
  url_path       = "*"
  host           = "*"
  http_method    = "*"
  service_type   = "*"
  service_name   = "*"
  resource_arn   = "*"
}

# Application instrumentation
# Use AWS X-Ray SDK in application code
# Enable X-Ray write access in IAM role
resource "aws_iam_policy" "xray_write" {
  policy = jsonencode({
    Version = "2012-10-17"
    Statement = [{
      Effect = "Allow"
      Action = [
        "xray:PutTraceSegments",
        "xray:PutTelemetryRecords"
      ]
      Resource = "*"
    }]
  })
}
```

---

## Compliance & Governance

### AWS Config for Compliance

```hcl
# Enable AWS Config
resource "aws_config_configuration_recorder" "main" {
  name       = "main-recorder"
  role_arn   = aws_iam_role.config.arn
  depends_on = [aws_iam_role_policy_attachment.config]
  
  recording_group {
    all_supported = true
    include_global = true
  }
}

resource "aws_config_configuration_recorder_status" "main" {
  name              = aws_config_configuration_recorder.main.name
  is_enabled        = true
  depends_on        = [aws_config_delivery_channel.main]
  start_recording   = true
}

# Delivery channel
resource "aws_config_delivery_channel" "main" {
  name                        = "main-delivery-channel"
  s3_bucket_name              = aws_s3_bucket.config_logs.id
  depends_on                  = [aws_config_configuration_recorder.main]
}

# Organization-wide aggregator
resource "aws_config_configuration_aggregator" "organization" {
  name = "organization-aggregator"
  
  account_aggregation_sources {
    all_regions = true
    account_ids = var.member_account_ids
  }
}

# CIS Benchmark compliance
resource "aws_config_conformance_pack" "cis_benchmark" {
  name = "cis-aws-foundations-benchmark"
  
  conformance_pack_input_parameters = {
    AccessKeysRotatedParameterMaxAccessKeyAge = "90"
    PasswordRequirementPasswordMinimumLength   = "14"
  }
}
```

---

**Key Takeaways:**

âœ… **Monitoring**: Metrics, logs, traces, events for complete observability
âœ… **Security**: Defense in depth with 7 layers of protection
âœ… **Encryption**: TLS for transit, KMS for at-rest data
âœ… **IAM**: Least privilege, roles over long-lived keys
âœ… **Logging**: CloudTrail, VPC Flow Logs, GuardDuty
âœ… **Terraform**: Secure state, no hardcoded secrets, automated scanning
âœ… **Compliance**: AWS Config, conformance packs, CIS benchmarks

Monitoring and security are continuous, ongoing activities that require automation, regular reviews, and team commitment to maintain production-grade infrastructure!
# Interview-Based Scenarios & Real-World Questions

## Q13: Production Incident - You're on-call at 3 AM, monitoring system goes down. How do you respond?

**Scenario Setup:**
```
Your monitoring system (Grafana, Prometheus) is down
â”œâ”€ Can't see any metrics
â”œâ”€ Can't verify if application is up or down
â”œâ”€ On-call alerts can't be sent
â”œâ”€ You're woken up at 3 AM
â””â”€ Business Impact: CRITICAL (blind to production problems)
```

**Immediate Actions (First 60 Seconds):**
```
1. Wake up, assess situation
   â”œâ”€ Check phone notifications: What triggered the alert?
   â”œâ”€ Slack: Check #incidents channel for context
   â””â”€ First thought: "What's the blast radius?"

2. Determine: Is application down or just monitoring?
   â”œâ”€ Try direct application access (curl, browser)
   â”œâ”€ Check AWS console status page
   â”œâ”€ Ask team: "Can you access the app?"
   
   If app is UP but monitoring is DOWN:
   âœ“ Good news: Application is serving customers
   âœ“ Priority: Restore monitoring (understand situation)
   âœ— Don't panic about false alarm
   
   If app is DOWN:
   âœ— Critical: Application not accessible
   âœ— Priority: Restore application (customer impact)
   âœ— Monitoring is secondary
```

**Debugging Steps (Next 10 Minutes):**
```
1. Check obvious issues
   â”œâ”€ Disk full? (df -h) â†’ Most common cause
   â”œâ”€ Memory exhausted? (free -h)
   â”œâ”€ Service running? (systemctl status prometheus)
   â”œâ”€ Network connectivity? (ping 8.8.8.8)
   â””â”€ Logs for errors? (tail -f /var/log/prometheus/error.log)

2. Recovery options
   Option A: Quick restart (30 seconds)
   â”œâ”€ systemctl restart prometheus grafana
   â”œâ”€ Risk: Low (monitoring is non-critical to app)
   
   Option B: Degraded mode (2 minutes)
   â”œâ”€ Start with reduced retention to free disk
   â”œâ”€ Clear old metrics, restart services
   
   Option C: Restore from backup (5-10 minutes)
   â”œâ”€ For database corruption scenarios
   â”œâ”€ Restore Prometheus from S3 snapshot

3. Communication
   T=3:15 AM: Alert to team on Slack
   "@channel Monitoring down since 3:05 AM
    Application: âœ… UP (verified)
    Status: Investigating Prometheus crash
    ETA: 3:25 AM for fix"

4. Root Cause Analysis (Next Morning)
   â””â”€ Why did disk fill up?
   â””â”€ Why wasn't this caught by monitoring?
   â””â”€ Solution: Monitor the monitor (dogfooding)
```

**Takeaway:** Always verify if application is up before investigating monitoring. Communicate frequently. Have degraded mode.

---

## Q14: Security Incident - You find suspicious IAM activity. What do you do?

**Scenario:**
```
Alert triggers: "Unusual IAM activity detected"
â”œâ”€ 10 new admin users created in 30 minutes
â”œâ”€ Created from internal IP but outside working hours
â”œâ”€ Created by Jenkins service account
â””â”€ Question: Legitimate automation or compromise?
```

**Immediate Response (First Minute):**
```
1. DON'T DELETE ANYTHING YET
   â”œâ”€ Need evidence for forensics
   â””â”€ Don't break the incident investigation

2. Alert team immediately
   Slack: "@security-team ğŸš¨ CRITICAL: 10 admin users created
           Investigate if legitimate or breach"

3. Start war room with security, infrastructure, and DevOps
```

**Investigation (Next 5 Minutes):**
```
Check CloudTrail for:
â”œâ”€ Principal that created users (who/what?)
â”œâ”€ Timestamp and source IP
â”œâ”€ Were they created by Jenkins automation?
â”œâ”€ Check Jenkins logs: Was a job scheduled?
â”œâ”€ Check Jenkins credentials: Are they compromised?

Determination:
â”œâ”€ Scenario A: Legitimate (Jenkins job deployed 10 services)
â”‚  â””â”€ Result: FALSE ALARM, close incident, improve alerts
â”‚
â””â”€ Scenario B: Compromise (no scheduled job, unknown principal)
   â””â”€ Proceed to containment
```

**Containment (If Compromise):**
```
Within 2 minutes:
1. Disable compromised access key
2. Disable the 10 new admin users
3. Revoke all sessions
4. Enable MFA enforcement
5. Forensic investigation starts
```

**Timeline of Communication:**
```
T=0:00  Alert team about suspicious activity
T=0:05  Initial findings: Likely compromise
T=0:10  Containment: Access key disabled
T=0:20  Forensics underway
T=1:00  Root cause: Access key leaked in GitHub
T=2:00  Full investigation complete, prevention actions identified
```

**Prevention Actions:**
- Never commit credentials to git
- Pre-commit hooks to block credentials
- Rotate Jenkins keys daily (not weekly)
- Enable MFA on all IAM users
- Alert on unknown access keys being created

**Takeaway:** Speed of detection matters. Forensics matter. Prevention is key.

---

## Q15: Multi-Service Monitoring Design - How do you monitor 20+ microservices?

**The Challenge:**
```
20+ services Ã— 10 metrics = 200 metrics (seems fine)
But: 2 regions Ã— 3 instances = 600 metrics (getting bigger)
With all tags and dimensions = 10,000+ metrics (explosion!)
Problems: Which dashboard? Which alert? Too much noise.
```

**Solution: Organized Monitoring Architecture:**

```
TIER 1: Golden Signals (Executives)
â”œâ”€ Overall availability
â”œâ”€ Active users
â”œâ”€ Global error rate
â””â”€ Alert ONLY on critical items

TIER 2: Service Level (Engineers)
â”œâ”€ Per-service RED metrics
â”œâ”€ Dependencies health
â”œâ”€ Error breakdown
â””â”€ Alert on service-level issues

TIER 3: Instance Level (Deep debugging)
â”œâ”€ CPU, memory, disk, network
â”œâ”€ Connection pools
â”œâ”€ GC pauses
â””â”€ No alerts (informational only)
```

**Alert Strategy - 3 Tiers:**
```
CRITICAL: Page on-call (service down, error > 5%)
WARNING: Slack notification (error > 1%, latency spike)
INFO: Logs only (CPU > 50%, normal load)
```

**Distributed Tracing for Root Cause:**
```
Without tracing: "User Service is slow. Why?"
With tracing: Shows exact breakdown:
  â”œâ”€ User Service (100ms)
  â”œâ”€ Auth Service (50ms)
  â”œâ”€ Payment Service (800ms) â† BOTTLENECK!
  â”‚  â””â”€ Database query (750ms) â† SLOW QUERY!
  â””â”€ Solution: Add index, back to 500ms
```

**Takeaway:** Organize by role (executives, engineers, on-call). Use tracing for root cause. Tier your alerts.

---

## Q16: Cost Optimization - Reduce monitoring costs 80% while maintaining visibility

**Scenario:**
```
Monitoring bill: $16,000/month
â”œâ”€ CloudWatch metrics: $5,000
â”œâ”€ CloudWatch Logs: $3,000
â”œâ”€ Datadog: $8,000
â””â”€ Business asks: "Can we cut this 50%?"
```

**Cost Optimization Strategy:**
```
1. Metrics Reduction (50,000 â†’ 10,000 metrics)
   â”œâ”€ Remove unused metrics (not queried in 90 days)
   â”œâ”€ Aggregate instance to service level
   â”œâ”€ Remove redundant metrics
   â””â”€ Cost: $5,000 â†’ $1,000 âœ“ $4,000 savings

2. Log Sampling
   â”œâ”€ DEBUG logs: Sample 10% (keep 10%)
   â”œâ”€ INFO logs: Sample 50% (keep 50%)
   â”œâ”€ ERROR logs: 100% (keep all, important)
   â””â”€ Cost: $3,000 â†’ $60 âœ“ $2,940 savings

3. Log Tiering
   â”œâ”€ 1 week in CloudWatch (hot, expensive)
   â”œâ”€ 90 days in S3/Athena (warm, cheaper)
   â”œâ”€ 2 years in Glacier (cold, compliance only)
   â””â”€ Cost: $3,000 â†’ $170

4. Dashboard & Alert Consolidation
   â”œâ”€ Delete unused dashboards (50 of 150)
   â”œâ”€ Merge overlapping dashboards
   â”œâ”€ Reduce false positive alerts (only actionable)
   â””â”€ Reduced metric queries = lower cost

TOTAL BEFORE: $8,000/month
TOTAL AFTER: $1,060/month (87% reduction!)
Still monitoring: All errors (100%), critical metrics, visibility
```

**Takeaway:** Smart sampling preserves what matters. Tiering saves more than reducing collection.

---

## Q17: SaaS Monitoring - Multi-tenant platform with 1,000+ customers

**SaaS Challenges:**
```
Each customer needs isolation:
â”œâ”€ Customer A: 100 req/sec, 0% error
â”œâ”€ Customer B: 500 req/sec, 2% error
â””â”€ (Cannot combine, must separate metrics)

Different SLOs per tier:
â”œâ”€ Free: 99% uptime (43 min/month ok)
â”œâ”€ Pro: 99.9% uptime (4.3 min/month)
â”œâ”€ Enterprise: 99.95% uptime (22 sec/month)

Monitoring must respect:
â”œâ”€ Data isolation (Customer A can't see B's metrics)
â”œâ”€ Compliance (HIPAA, PCI-DSS for sensitive data)
â”œâ”€ Customer-facing status page
â””â”€ Support SLA tracking per customer
```

**Implementation:**
```
Metric tagging with customer_id:
â”œâ”€ {customer_id="acme-corp", service="api", metric="latency"}
â”œâ”€ Prometheus labels or CloudWatch dimensions
â””â”€ Customer-specific dashboard (dropdown to select)

Per-customer SLO tracking:
â”œâ”€ Calculate: Has customer breached their SLO?
â”œâ”€ Alert if: Trending towards breach (predict)
â”œâ”€ Customer self-service status page
â””â”€ Different alert thresholds per tier (not one-size-fits-all)

Security & compliance:
â”œâ”€ Never log customer data (no PII in logs)
â”œâ”€ Encrypt monitoring data (sensitive)
â”œâ”€ Audit trail (who accessed which customer?)
â”œâ”€ RBAC (support sees customer X only)
```

---

## Q18: Chaos Engineering - Test monitoring by breaking things deliberately

**Challenge:**
```
You have comprehensive monitoring, but question:
"Will we actually catch a failure when it happens?"
â””â”€ Answer: Run chaos experiments to find out
```

**Common Chaos Experiments:**

```
1. Network Latency (What if database gets slow?)
   â”œâ”€ Gradually add 1000ms latency
   â”œâ”€ Watch: Does alert fire?
   â”œâ”€ Measure: How long until detection?
   â””â”€ Result: Alert fires after 5 minutes (should be < 2 min)

2. Service Down (What if auth service crashes?)
   â”œâ”€ Kill auth service pods
   â”œâ”€ Should trigger errors in dependent services
   â”œâ”€ Alert: "Auth service down"
   â””â”€ Runbook: "Restart auth service"

3. Memory Leak (Gradual degradation)
   â”œâ”€ Memory increases 10% per minute
   â”œâ”€ Can you identify the leak from metrics?
   â”œâ”€ Does auto-scaling kick in before crash?
   â””â”€ Alerts: Memory trending, OOM risk

4. Cache Failure (What if Redis goes down?)
   â”œâ”€ Baseline: 2,000 req/sec, 50ms latency, 80% cache hit
   â”œâ”€ Turn off Redis
   â”œâ”€ Watch: Latency â†‘ (now hitting database)
   â”œâ”€ Database CPU â†‘ to 90%, connections maxed
   â”œâ”€ Error rate â†‘ to 20%
   â””â”€ Measure: Time until critical alert: 30 seconds
```

**Automation:**
```
Run experiments every Friday afternoon:
â”œâ”€ Measure: Does alert fire? (yes/no)
â”œâ”€ Track: MTTD (mean time to detect)
â”œâ”€ Track: MTTR (mean time to resolve)
â”œâ”€ Iterate: Fix issues found
â””â”€ Goal: Continuous monitoring validation

Tools:
â”œâ”€ Kubernetes: Chaos Mesh, Kube-monkey
â”œâ”€ Network: Toxiproxy, Linux TC
â”œâ”€ Commercial: Gremlin, BigCommerce chaos
â””â”€ Custom: Application-level fault injection
```

**Example Experiment Run:**
```
Experiment: Redis failure

Pre: 2,000 req/sec, 50ms latency, 0% error
Kill Redis...
T=10s: Cache errors appear, latency â†‘ to 500ms âœ“ Alert 1
T=20s: DB connections maxed, error rate â†‘ to 5% âœ“ Alert 2
T=30s: Error rate â†‘ to 20% âœ“ Critical alert
T=45s: Load balancer removes unhealthy instances âœ“ Auto-healing

Results:
âœ“ Alerts fired correctly
âœ“ Dashboard showed root cause (Redis down)
âœ— Problem: No alert for "Redis connection errors" (add it)
âœ— Problem: Auto-scaling too slow (tune threshold)

Action items:
â”œâ”€ Add alert for Redis connection errors
â”œâ”€ Tune auto-scaling (faster response)
â”œâ”€ Update runbook for this scenario
â””â”€ Re-test next Friday
```

---

**Key Takeaways:**

âœ… **Production Incidents**: Verify app status first, communicate early, have degraded mode
âœ… **Security Response**: Don't delete evidence, isolate quickly, improve alerts
âœ… **Multi-Service Monitoring**: Organize by role, use distributed tracing for root causes
âœ… **Cost Optimization**: Smart sampling, metric aggregation, log tiering
âœ… **SaaS Complexity**: Data isolation, per-customer SLOs, compliance requirements
âœ… **Chaos Engineering**: Validate alerts, measure MTTD/MTTR, continuous improvement

Real-world DevOps expertise requires not just knowing the theory, but understanding how to respond under pressure, design for complexity, and continuously improve systems!
