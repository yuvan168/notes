# Terraform Complete Notes: Theory & Practical Application

## Table of Contents
1. [Introduction](#introduction)
2. [Core Concepts](#core-concepts)
3. [Installation & Setup](#installation--setup)
4. [Terraform Basics](#terraform-basics)
5. [Configuration Language](#configuration-language)
6. [State Management](#state-management)
7. [Modules & Reusability](#modules--reusability)
8. [Practical Examples](#practical-examples)
9. [Best Practices](#best-practices)
10. [Troubleshooting](#troubleshooting)
11. [Advanced Concepts](#advanced-concepts)
12. [Interview Questions & Scenarios](#interview-questions--scenarios)

---

## Introduction

**Terraform** is an open-source Infrastructure as Code (IaC) tool created by HashiCorp. It allows you to define, preview, and deploy infrastructure using declarative configuration files.

### Why Terraform?
- **Declarative**: Define desired state, not steps to reach it
- **Multi-cloud**: Support for AWS, Azure, GCP, and 50+ providers
- **State Management**: Tracks infrastructure state
- **Version Control**: Infrastructure code can be versioned
- **Modular**: Reusable, composable modules
- **Plan & Apply**: Preview changes before applying

### Key Terminology
- **Provider**: Plugin that allows Terraform to interact with cloud services
- **Resource**: Infrastructure components (VMs, databases, networks)
- **Data Source**: Read-only information from providers
- **Module**: Reusable collection of resources
- **State**: Current configuration stored locally or remotely
- **Plan**: Preview of changes before applying

---

## Core Concepts

### Infrastructure as Code (IaC)
Infrastructure defined in code instead of manual UI clicks. Benefits:
- Reproducibility across environments
- Version control and audit trails
- Easier collaboration
- Faster deployments
- Automated testing

### Declarative vs Imperative
- **Declarative** (Terraform): "Create this state"
- **Imperative** (Scripts): "Do step 1, then step 2, then step 3"

### State Management
Terraform maintains a **state file** that tracks:
- Current resources
- Resource attributes
- Dependencies
- Metadata

State file is critical - it's the source of truth for what exists.

### Plan & Apply Workflow

```
1. Write configuration files (.tf files)
   ↓
2. terraform init (initialize working directory)
   ↓
3. terraform plan (preview changes)
   ↓
4. terraform apply (apply changes)
   ↓
5. Infrastructure created/updated
```

---

## Installation & Setup

### Install Terraform

**Windows (using Chocolatey):**
```powershell
choco install terraform
```

**Windows (manual):**
1. Download from [terraform.io](https://www.terraform.io/downloads.html)
2. Extract to a directory (e.g., `C:\terraform`)
3. Add to PATH environment variable

**Verify Installation:**
```bash
terraform version
```

### Configure AWS Credentials

**Method 1: Environment Variables**
```powershell
$env:AWS_ACCESS_KEY_ID = "your_access_key"
$env:AWS_SECRET_ACCESS_KEY = "your_secret_key"
$env:AWS_DEFAULT_REGION = "us-east-1"
```

**Method 2: AWS Credentials File**
Create `~/.aws/credentials`:
```
[default]
aws_access_key_id = YOUR_ACCESS_KEY
aws_secret_access_key = YOUR_SECRET_KEY
```

Create `~/.aws/config`:
```
[default]
region = us-east-1
```

---

## Terraform Basics

### HCL Syntax

Terraform uses **HCL (HashiCorp Configuration Language)**:

```hcl
# Comments start with #

# Blocks define infrastructure components
resource "aws_instance" "web" {
  # Arguments
  ami           = "ami-0c55b159cbfafe1f0"
  instance_type = "t2.micro"
  
  tags = {
    Name = "MyInstance"
  }
}

# Data source
data "aws_ami" "ubuntu" {
  most_recent = true

  filter {
    name   = "name"
    values = ["ubuntu/images/hvm-ssd/ubuntu-focal-20.04-amd64-server-*"]
  }

  owners = ["099720109477"] # Canonical
}

# Variables
variable "instance_type" {
  type    = string
  default = "t2.micro"
}

# Outputs
output "instance_id" {
  value = aws_instance.web.id
}
```

### File Organization

**Standard Structure:**
```
project/
├── main.tf           # Main resource definitions
├── variables.tf      # Variable declarations
├── outputs.tf        # Output definitions
├── terraform.tfvars  # Variable values
├── provider.tf       # Provider configuration
├── .terraform/       # Terraform directory (auto-created)
└── terraform.tfstate # State file (auto-created)
```

---

## Configuration Language

### Providers

Providers are plugins that define resources:

```hcl
# AWS Provider
terraform {
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 4.0"
    }
  }
}

provider "aws" {
  region = "us-east-1"

  default_tags {
    tags = {
      Environment = "dev"
      Project     = "MyProject"
    }
  }
}
```

### Resources

Resources create and manage infrastructure:

```hcl
# EC2 Instance
resource "aws_instance" "app_server" {
  ami             = "ami-0c55b159cbfafe1f0"
  instance_type   = "t2.micro"
  security_groups = [aws_security_group.web.name]

  user_data = <<-EOF
              #!/bin/bash
              sudo yum update -y
              sudo yum install -y httpd
              sudo systemctl start httpd
              EOF

  tags = {
    Name = "AppServer"
  }
}

# Security Group
resource "aws_security_group" "web" {
  name = "web-sg"

  ingress {
    from_port   = 80
    to_port     = 80
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }
}

# RDS Database
resource "aws_db_instance" "postgres" {
  identifier     = "my-database"
  engine         = "postgres"
  engine_version = "13.7"
  instance_class = "db.t2.micro"
  allocated_storage = 20
  
  db_name  = "mydb"
  username = "admin"
  password = var.db_password
  
  skip_final_snapshot = true
}
```

### Variables

Variables make configurations reusable:

```hcl
# variables.tf
variable "instance_type" {
  description = "EC2 instance type"
  type        = string
  default     = "t2.micro"
}

variable "instance_count" {
  description = "Number of instances"
  type        = number
  default     = 1
}

variable "tags" {
  description = "Common tags"
  type        = map(string)
  default = {
    Environment = "dev"
    Team        = "platform"
  }
}

variable "availability_zones" {
  description = "List of AZs"
  type        = list(string)
  default     = ["us-east-1a", "us-east-1b"]
}

variable "instance_config" {
  description = "Instance configuration"
  type = object({
    type   = string
    volume = number
  })
  default = {
    type   = "t2.micro"
    volume = 20
  }
}
```

**Using Variables:**
```hcl
resource "aws_instance" "web" {
  ami           = data.aws_ami.ubuntu.id
  instance_type = var.instance_type

  tags = merge(
    var.tags,
    { Name = "WebServer" }
  )
}
```

**Providing Values:**
```bash
# Command line
terraform apply -var="instance_type=t2.small"

# From file
terraform apply -var-file="prod.tfvars"
```

### Outputs

Outputs expose values after apply:

```hcl
# outputs.tf
output "instance_id" {
  description = "ID of the EC2 instance"
  value       = aws_instance.web.id
  sensitive   = false
}

output "instance_public_ip" {
  description = "Public IP of instance"
  value       = aws_instance.web.public_ip
}

output "database_endpoint" {
  description = "Database endpoint"
  value       = aws_db_instance.postgres.endpoint
  sensitive   = true
}
```

### Data Sources

Read existing infrastructure:

```hcl
# Get latest Ubuntu AMI
data "aws_ami" "ubuntu" {
  most_recent = true

  filter {
    name   = "name"
    values = ["ubuntu/images/hvm-ssd/ubuntu-focal-*"]
  }

  filter {
    name   = "virtualization-type"
    values = ["hvm"]
  }

  owners = ["099720109477"]
}

# Get existing VPC
data "aws_vpc" "default" {
  default = true
}

# Get existing security group
data "aws_security_group" "default" {
  vpc_id = data.aws_vpc.default.id
  name   = "default"
}
```

### Interpolation & Functions

```hcl
# String interpolation
resource "aws_instance" "web" {
  tags = {
    Name = "instance-${var.environment}-${count.index + 1}"
  }
}

# Built-in functions
locals {
  # String functions
  app_name = lower(var.project_name)
  
  # List functions
  azs = slice(var.availability_zones, 0, 2)
  
  # Map functions
  merged_tags = merge(var.default_tags, var.additional_tags)
  
  # Math functions
  cpu_cores = max(2, var.cpu_count)
  
  # Type conversion
  port = tonumber(var.port_string)
}
```

---

## State Management

### Local State

Default state storage:
```hcl
# .gitignore
terraform.tfstate
terraform.tfstate.*
.terraform/
```

⚠️ Never commit state files to version control!

### Remote State

Store state in centralized location (recommended for teams):

```hcl
# main.tf
terraform {
  backend "s3" {
    bucket         = "my-terraform-state"
    key            = "prod/terraform.tfstate"
    region         = "us-east-1"
    encrypt        = true
    dynamodb_table = "terraform-locks"
  }
}
```

### State Locking

Prevent concurrent modifications:

```hcl
# Using DynamoDB for state locking
terraform {
  backend "s3" {
    bucket         = "my-terraform-state"
    key            = "prod/terraform.tfstate"
    region         = "us-east-1"
    encrypt        = true
    dynamodb_table = "terraform-locks"
  }
}
```

### State Commands

```bash
# Show state
terraform state list
terraform state show aws_instance.web

# Advanced state manipulation (use carefully)
terraform state mv aws_instance.old aws_instance.new
terraform state rm aws_instance.temporary
terraform import aws_instance.existing i-1234567890abcdef0
```

---

## Modules & Reusability

### Module Structure

```
modules/
├── vpc/
│   ├── main.tf
│   ├── variables.tf
│   ├── outputs.tf
│   └── README.md
├── security_group/
│   ├── main.tf
│   ├── variables.tf
│   └── outputs.tf
└── ec2/
    ├── main.tf
    ├── variables.tf
    └── outputs.tf
```

### Using Modules

```hcl
# Root module (main configuration)
module "vpc" {
  source = "./modules/vpc"

  cidr_block = "10.0.0.0/16"
  name       = "prod-vpc"
  
  tags = var.common_tags
}

module "web_sg" {
  source = "./modules/security_group"

  name   = "web-sg"
  vpc_id = module.vpc.vpc_id

  ingress_rules = [
    {
      from_port   = 80
      to_port     = 80
      protocol    = "tcp"
      cidr_blocks = ["0.0.0.0/0"]
    }
  ]
}

module "web_server" {
  source = "./modules/ec2"
  count  = var.web_server_count

  instance_type   = var.instance_type
  ami             = data.aws_ami.ubuntu.id
  security_groups = [module.web_sg.security_group_id]
  
  tags = merge(
    var.common_tags,
    { Name = "WebServer-${count.index + 1}" }
  )
}
```

### Module Outputs

```hcl
# modules/vpc/outputs.tf
output "vpc_id" {
  value = aws_vpc.main.id
}

output "private_subnets" {
  value = aws_subnet.private[*].id
}
```

### Local Modules

```hcl
# Local module
module "storage" {
  source = "./modules/storage"
}

# Remote module (from registry)
module "security" {
  source = "terraform-aws-modules/security-group/aws"
  version = "~> 4.0"

  name = "security-group"
  # ... configuration
}

# Git module
module "database" {
  source = "git::https://github.com/company/terraform-database-module.git"
  version = "v1.0.0"
}
```

---

## Practical Examples

### Example 1: Simple Web Server

**Directory Structure:**
```
web-server/
├── main.tf
├── variables.tf
├── outputs.tf
└── terraform.tfvars
```

**variables.tf:**
```hcl
variable "instance_type" {
  type    = string
  default = "t2.micro"
}

variable "environment" {
  type = string
}

variable "enable_monitoring" {
  type    = bool
  default = false
}
```

**main.tf:**
```hcl
terraform {
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 4.0"
    }
  }
}

provider "aws" {
  region = "us-east-1"
}

# Security group
resource "aws_security_group" "web" {
  name_prefix = "web-"

  ingress {
    from_port   = 80
    to_port     = 80
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  ingress {
    from_port   = 443
    to_port     = 443
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  ingress {
    from_port   = 22
    to_port     = 22
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }

  tags = {
    Name        = "web-sg"
    Environment = var.environment
  }
}

# EC2 instance
resource "aws_instance" "web" {
  ami             = data.aws_ami.ubuntu.id
  instance_type   = var.instance_type
  security_groups = [aws_security_group.web.name]

  user_data = base64encode(<<-EOF
              #!/bin/bash
              apt-get update
              apt-get install -y nginx
              systemctl start nginx
              systemctl enable nginx
              echo "Hello from $(hostname -f)" > /var/www/html/index.html
              EOF
  )

  monitoring = var.enable_monitoring

  tags = {
    Name        = "web-server"
    Environment = var.environment
  }
}

# Data source for latest Ubuntu AMI
data "aws_ami" "ubuntu" {
  most_recent = true

  filter {
    name   = "name"
    values = ["ubuntu/images/hvm-ssd/ubuntu-focal-20.04-amd64-server-*"]
  }

  owners = ["099720109477"]
}
```

**outputs.tf:**
```hcl
output "instance_id" {
  description = "Instance ID"
  value       = aws_instance.web.id
}

output "public_ip" {
  description = "Public IP address"
  value       = aws_instance.web.public_ip
}

output "public_dns" {
  description = "Public DNS name"
  value       = aws_instance.web.public_dns
}
```

**terraform.tfvars:**
```hcl
environment       = "development"
instance_type     = "t2.micro"
enable_monitoring = false
```

**Commands:**
```bash
# Initialize
terraform init

# Plan
terraform plan

# Apply
terraform apply

# Destroy
terraform destroy
```

### Example 2: Multi-Tier Application

**main.tf:**
```hcl
terraform {
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 4.0"
    }
  }

  backend "s3" {
    bucket = "company-terraform-state"
    key    = "multi-tier/terraform.tfstate"
    region = "us-east-1"
  }
}

provider "aws" {
  region = var.aws_region

  default_tags {
    tags = {
      Project     = "MultiTier"
      Environment = var.environment
      ManagedBy   = "Terraform"
    }
  }
}

# VPC
resource "aws_vpc" "main" {
  cidr_block           = var.vpc_cidr
  enable_dns_hostnames = true
  enable_dns_support   = true

  tags = { Name = "${var.app_name}-vpc" }
}

# Public Subnets
resource "aws_subnet" "public" {
  count             = length(var.availability_zones)
  vpc_id            = aws_vpc.main.id
  cidr_block        = var.public_subnet_cidrs[count.index]
  availability_zone = var.availability_zones[count.index]

  map_public_ip_on_launch = true

  tags = { Name = "${var.app_name}-public-subnet-${count.index + 1}" }
}

# Private Subnets
resource "aws_subnet" "private" {
  count             = length(var.availability_zones)
  vpc_id            = aws_vpc.main.id
  cidr_block        = var.private_subnet_cidrs[count.index]
  availability_zone = var.availability_zones[count.index]

  tags = { Name = "${var.app_name}-private-subnet-${count.index + 1}" }
}

# Internet Gateway
resource "aws_internet_gateway" "main" {
  vpc_id = aws_vpc.main.id

  tags = { Name = "${var.app_name}-igw" }
}

# Elastic IPs for NAT Gateways
resource "aws_eip" "nat" {
  count    = length(var.availability_zones)
  domain   = "vpc"
  depends_on = [aws_internet_gateway.main]

  tags = { Name = "${var.app_name}-eip-${count.index + 1}" }
}

# NAT Gateways
resource "aws_nat_gateway" "main" {
  count         = length(var.availability_zones)
  allocation_id = aws_eip.nat[count.index].id
  subnet_id     = aws_subnet.public[count.index].id

  depends_on = [aws_internet_gateway.main]

  tags = { Name = "${var.app_name}-nat-${count.index + 1}" }
}

# Route table for public subnets
resource "aws_route_table" "public" {
  vpc_id = aws_vpc.main.id

  route {
    cidr_block = "0.0.0.0/0"
    gateway_id = aws_internet_gateway.main.id
  }

  tags = { Name = "${var.app_name}-public-rt" }
}

# Associate public subnets with public route table
resource "aws_route_table_association" "public" {
  count          = length(aws_subnet.public)
  subnet_id      = aws_subnet.public[count.index].id
  route_table_id = aws_route_table.public.id
}

# Route tables for private subnets
resource "aws_route_table" "private" {
  count  = length(var.availability_zones)
  vpc_id = aws_vpc.main.id

  route {
    cidr_block     = "0.0.0.0/0"
    nat_gateway_id = aws_nat_gateway.main[count.index].id
  }

  tags = { Name = "${var.app_name}-private-rt-${count.index + 1}" }
}

# Associate private subnets with private route tables
resource "aws_route_table_association" "private" {
  count          = length(aws_subnet.private)
  subnet_id      = aws_subnet.private[count.index].id
  route_table_id = aws_route_table.private[count.index].id
}

# Security Groups
resource "aws_security_group" "alb" {
  name_prefix = "alb-"
  vpc_id      = aws_vpc.main.id

  ingress {
    from_port   = 80
    to_port     = 80
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  ingress {
    from_port   = 443
    to_port     = 443
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }

  tags = { Name = "${var.app_name}-alb-sg" }
}

resource "aws_security_group" "app" {
  name_prefix = "app-"
  vpc_id      = aws_vpc.main.id

  ingress {
    from_port       = 8080
    to_port         = 8080
    protocol        = "tcp"
    security_groups = [aws_security_group.alb.id]
  }

  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }

  tags = { Name = "${var.app_name}-app-sg" }
}

resource "aws_security_group" "database" {
  name_prefix = "db-"
  vpc_id      = aws_vpc.main.id

  ingress {
    from_port       = 5432
    to_port         = 5432
    protocol        = "tcp"
    security_groups = [aws_security_group.app.id]
  }

  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }

  tags = { Name = "${var.app_name}-db-sg" }
}

# Application Load Balancer
resource "aws_lb" "main" {
  name_prefix        = "app"
  internal           = false
  load_balancer_type = "application"
  security_groups    = [aws_security_group.alb.id]
  subnets            = aws_subnet.public[*].id

  tags = { Name = "${var.app_name}-alb" }
}

# Target Group
resource "aws_lb_target_group" "app" {
  name_prefix = "app"
  port        = 8080
  protocol    = "HTTP"
  vpc_id      = aws_vpc.main.id

  health_check {
    healthy_threshold   = 2
    unhealthy_threshold = 2
    timeout             = 3
    interval            = 30
    path                = "/"
    matcher             = "200-299"
  }

  tags = { Name = "${var.app_name}-tg" }
}

# ALB Listener
resource "aws_lb_listener" "app" {
  load_balancer_arn = aws_lb.main.arn
  port              = 80
  protocol          = "HTTP"

  default_action {
    type             = "forward"
    target_group_arn = aws_lb_target_group.app.arn
  }
}

# Auto Scaling Group
resource "aws_launch_template" "app" {
  name_prefix   = "app-"
  image_id      = data.aws_ami.ubuntu.id
  instance_type = var.app_instance_type

  user_data = base64encode(<<-EOF
              #!/bin/bash
              apt-get update
              apt-get install -y python3-pip
              pip3 install flask
              cat > /app/server.py << 'INNEREOF'
              from flask import Flask
              app = Flask(__name__)
              @app.route('/')
              def hello():
                  return 'Hello from Flask App'
              if __name__ == '__main__':
                  app.run(host='0.0.0.0', port=8080)
              INNEREOF
              python3 /app/server.py &
              EOF
  )

  vpc_security_group_ids = [aws_security_group.app.id]

  tag_specifications {
    resource_type = "instance"
    tags = {
      Name = "${var.app_name}-instance"
    }
  }
}

resource "aws_autoscaling_group" "app" {
  name                = "${var.app_name}-asg"
  vpc_zone_identifier = aws_subnet.private[*].id
  target_group_arns   = [aws_lb_target_group.app.arn]
  health_check_type   = "ELB"
  health_check_grace_period = 300

  min_size         = var.app_min_size
  max_size         = var.app_max_size
  desired_capacity = var.app_desired_size

  launch_template {
    id      = aws_launch_template.app.id
    version = "$Latest"
  }

  tag {
    key                 = "Name"
    value               = "${var.app_name}-asg-instance"
    propagate_at_launch = true
  }
}

# RDS Database
resource "aws_db_subnet_group" "main" {
  name       = "${var.app_name}-db-subnet-group"
  subnet_ids = aws_subnet.private[*].id

  tags = { Name = "${var.app_name}-db-subnet-group" }
}

resource "aws_db_instance" "postgres" {
  identifier            = "${var.app_name}-db"
  engine               = "postgres"
  engine_version       = "14.7"
  instance_class       = var.db_instance_class
  allocated_storage    = var.db_allocated_storage
  db_subnet_group_name = aws_db_subnet_group.main.name
  vpc_security_group_ids = [aws_security_group.database.id]

  db_name  = var.db_name
  username = var.db_username
  password = var.db_password

  skip_final_snapshot       = !var.db_backup_enabled
  final_snapshot_identifier = "${var.app_name}-db-final-snapshot"
  backup_retention_period   = var.db_backup_retention

  tags = { Name = "${var.app_name}-db" }
}

# Data source for AMI
data "aws_ami" "ubuntu" {
  most_recent = true

  filter {
    name   = "name"
    values = ["ubuntu/images/hvm-ssd/ubuntu-focal-20.04-amd64-server-*"]
  }

  owners = ["099720109477"]
}
```

**variables.tf:**
```hcl
variable "aws_region" {
  type    = string
  default = "us-east-1"
}

variable "environment" {
  type = string
}

variable "app_name" {
  type = string
}

variable "vpc_cidr" {
  type    = string
  default = "10.0.0.0/16"
}

variable "availability_zones" {
  type    = list(string)
  default = ["us-east-1a", "us-east-1b"]
}

variable "public_subnet_cidrs" {
  type    = list(string)
  default = ["10.0.1.0/24", "10.0.2.0/24"]
}

variable "private_subnet_cidrs" {
  type    = list(string)
  default = ["10.0.10.0/24", "10.0.11.0/24"]
}

variable "app_instance_type" {
  type    = string
  default = "t2.small"
}

variable "app_min_size" {
  type    = number
  default = 2
}

variable "app_max_size" {
  type    = number
  default = 6
}

variable "app_desired_size" {
  type    = number
  default = 3
}

variable "db_instance_class" {
  type    = string
  default = "db.t2.micro"
}

variable "db_allocated_storage" {
  type    = number
  default = 20
}

variable "db_name" {
  type = string
}

variable "db_username" {
  type      = string
  sensitive = true
}

variable "db_password" {
  type      = string
  sensitive = true
}

variable "db_backup_enabled" {
  type    = bool
  default = true
}

variable "db_backup_retention" {
  type    = number
  default = 7
}
```

**outputs.tf:**
```hcl
output "load_balancer_dns" {
  description = "DNS name of load balancer"
  value       = aws_lb.main.dns_name
}

output "database_endpoint" {
  description = "RDS endpoint"
  value       = aws_db_instance.postgres.endpoint
}

output "vpc_id" {
  value = aws_vpc.main.id
}
```

### Example 3: Using Modules

**Directory structure:**
```
project/
├── main.tf
├── variables.tf
├── outputs.tf
├── terraform.tfvars
└── modules/
    ├── vpc/
    │   ├── main.tf
    │   ├── variables.tf
    │   └── outputs.tf
    └── rds/
        ├── main.tf
        ├── variables.tf
        └── outputs.tf
```

**modules/vpc/main.tf:**
```hcl
resource "aws_vpc" "main" {
  cidr_block           = var.cidr_block
  enable_dns_hostnames = true
  enable_dns_support   = true

  tags = merge(
    var.tags,
    { Name = var.name }
  )
}

resource "aws_subnet" "public" {
  count             = length(var.public_subnets)
  vpc_id            = aws_vpc.main.id
  cidr_block        = var.public_subnets[count.index]
  availability_zone = var.availability_zones[count.index % length(var.availability_zones)]

  map_public_ip_on_launch = true

  tags = merge(
    var.tags,
    { Name = "${var.name}-public-${count.index + 1}" }
  )
}

resource "aws_internet_gateway" "main" {
  vpc_id = aws_vpc.main.id

  tags = merge(
    var.tags,
    { Name = "${var.name}-igw" }
  )
}

resource "aws_route_table" "public" {
  vpc_id = aws_vpc.main.id

  route {
    cidr_block = "0.0.0.0/0"
    gateway_id = aws_internet_gateway.main.id
  }

  tags = merge(
    var.tags,
    { Name = "${var.name}-public-rt" }
  )
}

resource "aws_route_table_association" "public" {
  count          = length(aws_subnet.public)
  subnet_id      = aws_subnet.public[count.index].id
  route_table_id = aws_route_table.public.id
}
```

**modules/vpc/variables.tf:**
```hcl
variable "name" {
  type = string
}

variable "cidr_block" {
  type = string
}

variable "public_subnets" {
  type = list(string)
}

variable "availability_zones" {
  type = list(string)
}

variable "tags" {
  type = map(string)
  default = {}
}
```

**modules/vpc/outputs.tf:**
```hcl
output "vpc_id" {
  value = aws_vpc.main.id
}

output "public_subnet_ids" {
  value = aws_subnet.public[*].id
}

output "internet_gateway_id" {
  value = aws_internet_gateway.main.id
}
```

**main.tf:**
```hcl
terraform {
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 4.0"
    }
  }
}

provider "aws" {
  region = var.aws_region
}

module "vpc" {
  source = "./modules/vpc"

  name                = "production"
  cidr_block          = "10.0.0.0/16"
  public_subnets     = ["10.0.1.0/24", "10.0.2.0/24"]
  availability_zones = ["us-east-1a", "us-east-1b"]

  tags = {
    Environment = "production"
    Project     = "MyApp"
  }
}

module "rds" {
  source = "./modules/rds"

  identifier            = "production-db"
  db_name              = var.db_name
  username             = var.db_username
  password             = var.db_password
  allocated_storage    = 20
  instance_class       = "db.t2.micro"
  subnet_ids           = [] # Pass appropriate subnets
  vpc_security_group_ids = [] # Pass appropriate SGs
}
```

---

## Best Practices

### 1. State Management
```hcl
# ✅ Good: Use remote state
terraform {
  backend "s3" {
    bucket         = "my-state"
    key            = "prod/terraform.tfstate"
    region         = "us-east-1"
    encrypt        = true
    dynamodb_table = "terraform-locks"
  }
}

# ❌ Bad: Storing state locally in production
```

### 2. Sensitive Data
```hcl
# ✅ Good: Mark sensitive outputs
output "db_password" {
  value     = aws_db_instance.main.password
  sensitive = true
}

# ✅ Good: Use variable files (add to .gitignore)
# terraform.tfvars
db_password = "secure-password"

# ✅ Good: Use environment variables
# export TF_VAR_db_password="secure-password"
```

### 3. Naming Conventions
```hcl
# ✅ Good: Consistent, descriptive names
resource "aws_instance" "web_server_prod" {
  tags = { Name = "web-server-prod-01" }
}

# ❌ Bad: Unclear names
resource "aws_instance" "test1" {
  tags = { Name = "instance1" }
}
```

### 4. Code Organization
```
project/
├── environments/
│   ├── dev/
│   │   ├── main.tf
│   │   ├── terraform.tfvars
│   │   └── backend.tf
│   ├── staging/
│   └── prod/
├── modules/
│   ├── vpc/
│   ├── rds/
│   └── security/
├── shared.tf
└── README.md
```

### 5. Input Validation
```hcl
variable "instance_count" {
  type    = number
  default = 1

  validation {
    condition     = var.instance_count > 0 && var.instance_count <= 10
    error_message = "Instance count must be between 1 and 10."
  }
}

variable "environment" {
  type = string

  validation {
    condition     = contains(["dev", "staging", "prod"], var.environment)
    error_message = "Environment must be dev, staging, or prod."
  }
}
```

### 6. Resource Dependencies
```hcl
# ✅ Good: Explicit dependencies
resource "aws_instance" "app" {
  # ...
  depends_on = [aws_nat_gateway.main]
}

# Implicit dependencies (preferred when possible)
resource "aws_instance" "app" {
  security_groups = [aws_security_group.app.name]
  # Terraform automatically manages dependency
}
```

### 7. DRY (Don't Repeat Yourself)
```hcl
# ✅ Good: Use locals
locals {
  common_tags = {
    Project     = "MyApp"
    Environment = var.environment
    ManagedBy   = "Terraform"
  }
}

resource "aws_instance" "web" {
  tags = merge(local.common_tags, { Name = "web-server" })
}

# ✅ Good: Use count or for_each
resource "aws_subnet" "main" {
  for_each = var.subnets

  vpc_id            = aws_vpc.main.id
  cidr_block        = each.value.cidr
  availability_zone = each.value.az
}
```

### 8. Provider Versioning
```hcl
# ✅ Good: Specify versions
terraform {
  required_version = ">= 1.0"
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 4.0, < 5.0"
    }
  }
}

# ❌ Bad: No version constraints
terraform {
  required_providers {
    aws = {
      source = "hashicorp/aws"
    }
  }
}
```

### 9. Testing Infrastructure
```bash
# Format code
terraform fmt -recursive

# Validate syntax
terraform validate

# Check for security issues
tfsec .

# Test with terraform plan before apply
terraform plan -out=tfplan

# Generate documentation
terraform-docs .
```

### 10. Destruction Safeguards
```hcl
# ✅ Good: Prevent accidental destruction
resource "aws_db_instance" "production" {
  # ... configuration ...
  
  lifecycle {
    prevent_destroy = true
  }
}

# ❌ Bad: No protection
resource "aws_db_instance" "production" {
  # ... configuration ...
}
```

---

## Troubleshooting

### Common Issues & Solutions

**1. State Lock Timeout**
```bash
# Problem: Another process is modifying state
# Solution: Force unlock (use with caution)
terraform force-unlock <LOCK_ID>
```

**2. Resource Already Exists**
```bash
# Problem: Resource created outside Terraform
# Solution: Import it
terraform import aws_instance.web i-1234567890abcdef0
```

**3. Dirty State**
```bash
# Problem: Plan shows changes but nothing changed
# Solution: Refresh state
terraform refresh

# Or use -refresh-only
terraform apply -refresh-only
```

**4. Provider Authentication Errors**
```bash
# Check AWS credentials
aws sts get-caller-identity

# Or use named profiles
export AWS_PROFILE=my-profile
terraform apply
```

**5. Module Source Errors**
```bash
# Re-initialize modules
terraform init -upgrade

# Clear module cache
rm -rf .terraform/modules/
terraform init
```

### Debug Commands

```bash
# Verbose logging
export TF_LOG=DEBUG
terraform apply

# Show resource details
terraform state show aws_instance.web

# List all resources
terraform state list

# Graph resources
terraform graph | dot -Tsvg > graph.svg

# Validate configuration
terraform validate

# Format check
terraform fmt -check
```

---

## Advanced Concepts

### 1. Workspaces (Environment Management)

**What are Workspaces?**
Workspaces allow you to maintain multiple distinct sets of infrastructure in the same configuration directory using separate state files.

```hcl
# Create and switch workspaces
terraform workspace new staging
terraform workspace new production
terraform workspace select staging
terraform workspace list
```

**Workspace Example:**

```hcl
# main.tf
locals {
  workspace_config = {
    dev = {
      instance_type = "t2.micro"
      instance_count = 1
      environment = "dev"
    }
    staging = {
      instance_type = "t2.small"
      instance_count = 2
      environment = "staging"
    }
    production = {
      instance_type = "t2.medium"
      instance_count = 3
      environment = "production"
    }
  }

  config = local.workspace_config[terraform.workspace]
}

resource "aws_instance" "app" {
  count         = local.config.instance_count
  ami           = data.aws_ami.ubuntu.id
  instance_type = local.config.instance_type

  tags = {
    Name        = "${local.config.environment}-instance-${count.index + 1}"
    Environment = local.config.environment
  }
}

output "current_workspace" {
  value = terraform.workspace
}
```

**⚠️ Key Points:**
- Each workspace has its own state file
- Ideal for non-critical environments
- Not suitable for production (use separate directories/backends instead)
- Workspaces are local by default

**Best Practice:** For production, use separate directories with different backends rather than workspaces.

---

### 2. Count vs For_Each

**Count:**
- Uses numeric indexing (0, 1, 2...)
- Simpler but less stable
- Changing count values shifts resource addresses

```hcl
resource "aws_instance" "web" {
  count         = var.instance_count
  ami           = data.aws_ami.ubuntu.id
  instance_type = "t2.micro"

  tags = {
    Name = "web-server-${count.index + 1}"
  }
}

# Access: aws_instance.web[0], aws_instance.web[1], etc.
# Reference in outputs
output "instance_ips" {
  value = aws_instance.web[*].public_ip
}
```

**For_Each:**
- Uses key-based addressing (strings)
- More stable when items are added/removed
- Better for maps and sets

```hcl
resource "aws_instance" "web" {
  for_each      = var.instances
  ami           = data.aws_ami.ubuntu.id
  instance_type = each.value.type
  
  tags = {
    Name = each.key
  }
}

# variables.tf
variable "instances" {
  type = map(object({
    type = string
  }))
  default = {
    "web-1" = { type = "t2.micro" }
    "web-2" = { type = "t2.small" }
  }
}

# Access: aws_instance.web["web-1"], aws_instance.web["web-2"]
# Reference in outputs
output "instance_details" {
  value = { for k, v in aws_instance.web : k => v.public_ip }
}
```

**Comparison:**
| Feature | Count | For_Each |
|---------|-------|----------|
| Indexing | Numeric (0-based) | Key-based (strings) |
| Stability | Less stable when changing count | More stable with map operations |
| Refactoring | Shifting indices breaks references | Keys remain stable |
| Use Case | Simple lists | Complex configurations |
| Performance | Slightly faster | Slightly slower |

---

### 3. Dynamic Blocks

**Dynamic Blocks** allow you to generate nested blocks dynamically.

```hcl
# Without dynamic block
resource "aws_security_group" "web" {
  name = "web-sg"

  ingress {
    from_port   = 80
    to_port     = 80
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  ingress {
    from_port   = 443
    to_port     = 443
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  ingress {
    from_port   = 22
    to_port     = 22
    protocol    = "tcp"
    cidr_blocks = ["10.0.0.0/8"]
  }
}

# With dynamic block (DRY)
resource "aws_security_group" "web" {
  name = "web-sg"

  dynamic "ingress" {
    for_each = var.ingress_rules
    content {
      from_port   = ingress.value.from_port
      to_port     = ingress.value.to_port
      protocol    = ingress.value.protocol
      cidr_blocks = ingress.value.cidr_blocks
    }
  }
}

# variables.tf
variable "ingress_rules" {
  type = list(object({
    from_port   = number
    to_port     = number
    protocol    = string
    cidr_blocks = list(string)
  }))
  default = [
    {
      from_port   = 80
      to_port     = 80
      protocol    = "tcp"
      cidr_blocks = ["0.0.0.0/0"]
    },
    {
      from_port   = 443
      to_port     = 443
      protocol    = "tcp"
      cidr_blocks = ["0.0.0.0/0"]
    }
  ]
}
```

---

### 4. Conditional Logic

**Using Terraform Conditionals:**

```hcl
# Conditionally create resources
variable "create_database" {
  type    = bool
  default = false
}

resource "aws_db_instance" "main" {
  count = var.create_database ? 1 : 0
  # ... database configuration
}

# Conditional values
variable "environment" {
  type = string
}

locals {
  instance_type = var.environment == "production" ? "t2.large" : "t2.micro"
  backup_retention = var.environment == "production" ? 30 : 7
}

resource "aws_instance" "app" {
  instance_type = local.instance_type
  tags = {
    BackupDays = local.backup_retention
  }
}

# Ternary with multiple conditions
resource "aws_instance" "web" {
  instance_type = (
    var.environment == "production" && var.high_performance ? "t2.xlarge" :
    var.environment == "production" ? "t2.large" :
    "t2.micro"
  )
}
```

---

### 5. Locals vs Variables

**Locals:** Computed values, cannot be overridden
**Variables:** Input values, can be overridden

```hcl
variable "project_name" {
  type = string
}

variable "environment" {
  type = string
}

locals {
  # Computed from variables
  common_tags = {
    Project     = var.project_name
    Environment = var.environment
    ManagedBy   = "Terraform"
    CreatedAt   = timestamp()
  }

  # Convenience name
  env_prefix = "${var.project_name}-${var.environment}"
}

resource "aws_instance" "web" {
  tags = merge(
    local.common_tags,
    {
      Name = "${local.env_prefix}-web-server"
    }
  )
}
```

---

### 6. Splat Syntax

**Splat Syntax** extracts values from resource collections.

```hcl
# Create multiple instances
resource "aws_instance" "web" {
  count         = 3
  ami           = data.aws_ami.ubuntu.id
  instance_type = "t2.micro"
}

# Extract all IDs using splat
output "all_instance_ids" {
  value = aws_instance.web[*].id
  # Output: ["i-123456", "i-234567", "i-345678"]
}

# With for_each
resource "aws_instance" "web" {
  for_each      = var.instances
  ami           = data.aws_ami.ubuntu.id
  instance_type = "t2.micro"
}

# Splat with for_each
output "instance_ips" {
  value = [for instance in aws_instance.web : instance.public_ip]
  # Same as: aws_instance.web[*].public_ip (only for count)
}
```

---

### 7. Provisioners (Use Cautiously)

**⚠️ Warning:** Provisioners are a last resort. Prefer user_data or configuration management.

```hcl
# Remote-exec provisioner
resource "aws_instance" "web" {
  ami           = data.aws_ami.ubuntu.id
  instance_type = "t2.micro"

  provisioner "remote-exec" {
    inline = [
      "sudo apt-get update",
      "sudo apt-get install -y nginx"
    ]

    connection {
      type        = "ssh"
      user        = "ec2-user"
      private_key = file("~/.ssh/id_rsa")
      host        = self.public_ip
    }
  }
}

# Local-exec provisioner
resource "aws_instance" "web" {
  ami           = data.aws_ami.ubuntu.id
  instance_type = "t2.micro"

  provisioner "local-exec" {
    command = "echo ${self.public_ip} >> inventory.txt"
  }
}

# Prevent destroy trigger
resource "aws_instance" "web" {
  ami           = data.aws_ami.ubuntu.id
  instance_type = "t2.micro"

  provisioner "local-exec" {
    when    = destroy
    command = "echo 'Instance ${self.id} is being destroyed'"
  }
}
```

---

### 8. Null Provider & Triggers

**Generate arbitrary data and manage arbitrary local resources:**

```hcl
resource "null_resource" "cluster" {
  # Triggers re-creation when any instance changes
  triggers = {
    cluster_instance_ids = join(",", aws_instance.web[*].id)
  }

  provisioner "local-exec" {
    command = "echo 'Cluster instances: ${self.triggers.cluster_instance_ids}'"
  }
}

# Null resource with triggers for re-deployment
resource "null_resource" "app_deployment" {
  triggers = {
    instance_ids = join(",", aws_instance.web[*].id)
    app_version  = var.app_version
  }

  provisioner "local-exec" {
    command = "bash ./scripts/deploy.sh"
  }
}
```

---

### 9. Terraform Graph & Visualization

```bash
# Generate dependency graph
terraform graph > graph.txt

# Visualize with Graphviz
terraform graph | dot -Tsvg > graph.svg

# View only resource dependencies
terraform graph -type=plan | dot -Tpng > plan.png
```

---

### 10. Sensitive Values

**Protect sensitive data from display:**

```hcl
# Variable marked as sensitive
variable "db_password" {
  type      = string
  sensitive = true
}

# Output marked as sensitive
output "database_password" {
  value     = aws_db_instance.main.password
  sensitive = true
}

# In terraform.tfvars
db_password = "SuperSecretPassword123"

# Access in code (still works, just not displayed)
resource "aws_db_instance" "main" {
  password = var.db_password
  # Password won't appear in terraform plan output
}
```

---

### 11. Testing Terraform Code

**Unit Testing with Terraform Validate:**

```bash
terraform validate
terraform fmt -recursive -check
```

**Integration Testing with Terratest:**

```go
package test

import (
	"testing"
	"github.com/gruntwork-io/terratest/modules/terraform"
)

func TestWebServerModule(t *testing.T) {
	terraformOptions := &terraform.Options{
		TerraformDir: "../",
		Vars: map[string]interface{}{
			"instance_type": "t2.micro",
		},
	}

	defer terraform.Destroy(t, terraformOptions)
	terraform.InitAndApply(t, terraformOptions)

	instanceId := terraform.Output(t, terraformOptions, "instance_id")
	if instanceId == "" {
		t.Fatal("Instance ID is empty")
	}
}
```

---

### 12. Custom Providers

**Creating custom providers (advanced):**

Custom providers are written in Go and can manage resources outside standard cloud providers.

```hcl
# Example: Custom provider for API management
resource "custom_api_resource" "example" {
  name        = "MyAPI"
  endpoint    = "https://api.example.com"
  description = "Custom API resource"
}
```

---

### 13. Terraform Backend Types

**Local Backend (Default):**
```hcl
terraform {
  backend "local" {
    path = "terraform.tfstate"
  }
}
```

**S3 Backend (AWS):**
```hcl
terraform {
  backend "s3" {
    bucket         = "my-terraform-state"
    key            = "prod/terraform.tfstate"
    region         = "us-east-1"
    encrypt        = true
    dynamodb_table = "terraform-locks"
  }
}
```

**Azure Backend:**
```hcl
terraform {
  backend "azurerm" {
    resource_group_name  = "my-rg"
    storage_account_name = "mystatefiles"
    container_name       = "tfstate"
    key                  = "prod.tfstate"
  }
}
```

**GCS Backend (Google Cloud):**
```hcl
terraform {
  backend "gcs" {
    bucket = "my-terraform-state"
    prefix = "prod"
  }
}
```

---

### 14. Terraform Cloud/Enterprise

**Key Features:**
- Remote state management
- Team management and policies
- VCS integration
- Run infrastructure
- Policy as Code (Sentinel)

```hcl
terraform {
  cloud {
    organization = "my-organization"
    
    workspaces {
      name = "my-workspace"
    }
  }
}
```

---

### 15. Import Existing Resources

**Import existing infrastructure into Terraform:**

```bash
# Syntax: terraform import <resource_type>.<resource_name> <resource_id>

# Import existing EC2 instance
terraform import aws_instance.existing i-1234567890abcdef0

# Import existing VPC
terraform import aws_vpc.main vpc-12345678

# Import existing security group
terraform import aws_security_group.web sg-12345678
```

**After importing, write the resource configuration:**

```hcl
resource "aws_instance" "existing" {
  # Terraform will now manage this instance
  # You need to write the configuration based on the imported state
  ami           = "ami-0c55b159cbfafe1f0"
  instance_type = "t2.micro"
}
```

---

## Interview Questions & Scenarios

### Basic Level

#### Q1: What is Terraform and why use it?

**Answer:**
Terraform is an Infrastructure as Code (IaC) tool that allows declarative infrastructure definition across multiple cloud providers. 

**Key Benefits:**
- **Declarative**: Write desired state, not imperative steps
- **Multi-cloud**: Manage AWS, Azure, GCP, etc., with same syntax
- **State management**: Tracks infrastructure state centrally
- **Version control**: Infrastructure can be versioned and reviewed
- **Team collaboration**: Code reviews and audit trails
- **Reproducibility**: Exact infrastructure in dev, staging, and production
- **Scalability**: Easy to replicate and scale infrastructure

**Example Scenario:**
Instead of manually clicking AWS console to create VPC, subnet, EC2, and security group, you write Terraform code once and deploy identically across environments.

---

#### Q2: Explain the difference between Plan and Apply.

**Answer:**

**terraform plan:**
- Previews what changes will be made
- Reads current state and compares with configuration
- Shows resource creation, modification, or deletion
- Doesn't make any changes
- Safe to run multiple times

**terraform apply:**
- Executes the changes shown in plan
- Modifies real infrastructure
- Updates state file
- Should follow careful review of plan

```bash
# Safe workflow
terraform init
terraform plan -out=tfplan          # Save plan to file
# Review tfplan carefully
terraform apply tfplan              # Apply only saved plan
```

---

#### Q3: What is State and why is it important?

**Answer:**

**State** is a file (terraform.tfstate) that tracks the current infrastructure.

**Importance:**
- **Source of truth**: Actual infrastructure state
- **Dependency tracking**: Knows resource relationships
- **Performance**: Avoids querying all resources every time
- **Coordination**: Prevents concurrent modifications (with locking)

**Critical Rules:**
1. ❌ Never commit state files to Git
2. ✅ Store remotely in S3, Azure, GCS, etc.
3. ✅ Enable encryption and access control
4. ✅ Enable state locking (DynamoDB for S3)

```hcl
# Good: Remote state with encryption and locking
terraform {
  backend "s3" {
    bucket         = "my-terraform-state"
    key            = "prod/terraform.tfstate"
    region         = "us-east-1"
    encrypt        = true
    dynamodb_table = "terraform-locks"
  }
}
```

---

#### Q4: How do you manage sensitive information?

**Answer:**

Multiple approaches:

1. **Terraform Variables (with sensitivity):**
```hcl
variable "db_password" {
  type      = string
  sensitive = true  # Won't display in outputs
}
```

2. **Environment Variables:**
```bash
export TF_VAR_db_password="my-secret-password"
terraform apply
```

3. **Secrets Management Services:**
```hcl
data "aws_secretsmanager_secret_version" "db_password" {
  secret_id = "prod/db/password"
}

resource "aws_db_instance" "main" {
  password = data.aws_secretsmanager_secret_version.db_password.secret_string
}
```

4. **HashiCorp Vault:**
```hcl
provider "vault" {
  address = var.vault_address
  token   = var.vault_token
}

data "vault_generic_secret" "db" {
  path = "secret/prod/database"
}

resource "aws_db_instance" "main" {
  password = data.vault_generic_secret.db.data["password"]
}
```

---

#### Q5: Explain Resource Dependencies in Terraform.

**Answer:**

Dependencies are relationships between resources that determine creation order.

**Explicit Dependencies:**
```hcl
resource "aws_instance" "web" {
  # Explicitly depends on NAT gateway
  depends_on = [aws_nat_gateway.main]
  # ... configuration
}
```

**Implicit Dependencies:**
```hcl
resource "aws_instance" "web" {
  # Terraform infers dependency from security_groups reference
  security_groups = [aws_security_group.web.name]
}

# Terraform automatically creates security group first
resource "aws_security_group" "web" {
  name = "web-sg"
}
```

**Graph & Visualization:**
```bash
terraform graph | dot -Tsvg > graph.svg
```

---

### Intermediate Level

#### Q6: Compare Count vs For_Each. When to use each?

**Answer:**

| Aspect | Count | For_Each |
|--------|-------|----------|
| **Indexing** | Numeric (0, 1, 2...) | Key-based (strings) |
| **Stability** | Unstable when count changes | Stable with map operations |
| **Use Case** | Simple lists | Complex, map-based configs |
| **Refactoring** | Changing count breaks references | Changing keys preserves stability |

**Count Example:**
```hcl
variable "instance_count" {
  default = 3
}

resource "aws_instance" "web" {
  count         = var.instance_count
  instance_type = "t2.micro"
  
  tags = { Name = "web-${count.index + 1}" }
}

# Problem: Changing from 3 to 2 instances renumbers remaining instances
# Before: web-0, web-1, web-2
# After: web-0, web-1
# Terraform destroys web-2 and recreates web-1 if configurations depend on index
```

**For_Each Example (Better):**
```hcl
variable "instances" {
  default = {
    "web-1"  = "t2.micro"
    "web-2"  = "t2.micro"
    "web-3"  = "t2.small"
  }
}

resource "aws_instance" "web" {
  for_each      = var.instances
  instance_type = each.value
  
  tags = { Name = each.key }
}

# Better: Removing "web-2" only affects that instance, not others
# Before: web-1, web-2, web-3
# After: web-1, web-3 (only web-2 destroyed)
```

**Recommendation:**
- Use **Count**: Simple lists with homogeneous resources
- Use **For_Each**: Maps, complex objects, stable configurations

---

#### Q7: How do you organize Terraform code for multiple environments?

**Answer:**

**Best Practice: Separate Directories per Environment**

```
project/
├── environments/
│   ├── dev/
│   │   ├── main.tf
│   │   ├── variables.tf
│   │   ├── terraform.tfvars
│   │   └── backend.tf
│   ├── staging/
│   │   ├── main.tf
│   │   ├── variables.tf
│   │   ├── terraform.tfvars
│   │   └── backend.tf
│   └── prod/
│       ├── main.tf
│       ├── variables.tf
│       ├── terraform.tfvars
│       └── backend.tf
├── modules/
│   ├── vpc/
│   │   ├── main.tf
│   │   ├── variables.tf
│   │   └── outputs.tf
│   ├── rds/
│   └── iam/
└── README.md
```

**terraform.tfvars for Each Environment:**

```hcl
# environments/dev/terraform.tfvars
environment       = "dev"
instance_type     = "t2.micro"
instance_count    = 1
enable_backups    = false
backup_retention  = 0

# environments/prod/terraform.tfvars
environment       = "prod"
instance_type     = "t2.large"
instance_count    = 3
enable_backups    = true
backup_retention  = 30
```

**Backend Configuration:**

```hcl
# environments/dev/backend.tf
terraform {
  backend "s3" {
    bucket = "company-terraform-state-dev"
    key    = "terraform.tfstate"
    region = "us-east-1"
  }
}

# environments/prod/backend.tf
terraform {
  backend "s3" {
    bucket = "company-terraform-state-prod"
    key    = "terraform.tfstate"
    region = "us-east-1"
  }
}
```

**Deployment Script:**

```bash
#!/bin/bash
ENV=${1:-dev}

cd environments/$ENV
terraform init
terraform plan -out=tfplan
# Review plan manually
terraform apply tfplan
```

**⚠️ Avoid:** Using Terraform Workspaces for production environments.

---

#### Q8: Explain Terraform Modules and their benefits.

**Answer:**

**Modules** are reusable, self-contained collections of resources.

**Benefits:**
- **Reusability**: Write once, use multiple times
- **Encapsulation**: Hide complexity from consumers
- **Consistency**: Ensure standard configurations
- **Maintainability**: Update once, affects all uses
- **Collaboration**: Teams can share module libraries

**Module Example:**

```hcl
# modules/vpc/main.tf
resource "aws_vpc" "main" {
  cidr_block = var.cidr_block
  # ... configuration
}

resource "aws_subnet" "public" {
  for_each   = var.public_subnets
  vpc_id     = aws_vpc.main.id
  cidr_block = each.value
}

# modules/vpc/variables.tf
variable "cidr_block" {
  type = string
}

variable "public_subnets" {
  type = map(string)
}

# modules/vpc/outputs.tf
output "vpc_id" {
  value = aws_vpc.main.id
}

output "subnet_ids" {
  value = aws_subnet.public[*].id
}
```

**Using the Module:**

```hcl
# main.tf
module "prod_vpc" {
  source = "./modules/vpc"
  
  cidr_block = "10.0.0.0/16"
  public_subnets = {
    subnet1 = "10.0.1.0/24"
    subnet2 = "10.0.2.0/24"
  }
}

module "dev_vpc" {
  source = "./modules/vpc"
  
  cidr_block = "10.1.0.0/16"
  public_subnets = {
    subnet1 = "10.1.1.0/24"
  }
}
```

---

#### Q9: What is a Data Source? Give examples.

**Answer:**

**Data Sources** fetch read-only information from cloud providers without creating resources.

**Use Cases:**
- Get latest AMI ID
- Fetch existing VPC information
- Retrieve security group details
- Query AWS availability zones

**Common Examples:**

```hcl
# Get latest Ubuntu AMI
data "aws_ami" "ubuntu" {
  most_recent = true
  
  filter {
    name   = "name"
    values = ["ubuntu/images/hvm-ssd/ubuntu-focal-20.04-*"]
  }
  
  owners = ["099720109477"] # Canonical
}

resource "aws_instance" "web" {
  ami = data.aws_ami.ubuntu.id  # Reference data source
}

# Get existing VPC
data "aws_vpc" "default" {
  default = true
}

# Get availability zones
data "aws_availability_zones" "available" {
  state = "available"
}

# Get AWS account ID
data "aws_caller_identity" "current" {}

output "account_id" {
  value = data.aws_caller_identity.current.account_id
}

# Reference S3 bucket
data "aws_s3_bucket" "existing" {
  bucket = "my-existing-bucket"
}

# Get Secrets Manager secret
data "aws_secretsmanager_secret_version" "db_password" {
  secret_id = "prod/database/password"
}
```

---

#### Q10: How do you handle Terraform state conflicts and recovery?

**Answer:**

**State Conflicts Scenarios:**

1. **Concurrent Modifications (State Lock):**
```bash
# Problem: Two users running terraform apply simultaneously

# Solution: Enable state locking with DynamoDB
terraform {
  backend "s3" {
    dynamodb_table = "terraform-locks"
    # ... other config
  }
}

# If someone's apply is stuck:
terraform force-unlock <LOCK_ID>  # Use with caution!
```

2. **State Drift (Manual Changes):**
```bash
# Problem: Someone manually modified AWS resources

# Solution: Refresh state to match reality
terraform refresh
# or
terraform apply -refresh-only

# Then review changes:
terraform plan
```

3. **Lost State File:**
```bash
# Problem: Local state file deleted but infrastructure exists

# Solution: Import resources back into Terraform
terraform import aws_instance.web i-1234567890abcdef0

# Write resource configuration and import others
```

4. **Corrupted State:**
```bash
# Problem: State file corrupted or unreadable

# Solution: Use remote backups
# S3 versioning: Enable versioning on state bucket
# Restore from previous version:
aws s3api get-object --bucket my-state --key terraform.tfstate --version-id <VERSION_ID> terraform.tfstate.recovered
```

---

### Advanced Level

#### Q11: Interview Scenario: Multi-Region Deployment

**Scenario:**
"Design Terraform code to deploy an application across multiple AWS regions with disaster recovery."

**Solution:**

```hcl
# variables.tf
variable "regions" {
  description = "Primary and DR regions"
  type = map(object({
    name              = string
    enable_replication = bool
  }))
  default = {
    primary = {
      name              = "us-east-1"
      enable_replication = true
    }
    dr = {
      name              = "us-west-2"
      enable_replication = false
    }
  }
}

# main.tf - Multi-region setup
terraform {
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 4.0"
    }
  }
}

# Primary region provider
provider "aws" {
  alias  = "primary"
  region = var.regions.primary.name
}

# DR region provider
provider "aws" {
  alias  = "dr"
  region = var.regions.dr.name
}

# Primary infrastructure
module "primary_vpc" {
  source = "./modules/vpc"
  providers = {
    aws = aws.primary
  }
  
  region            = var.regions.primary.name
  cidr_block        = "10.0.0.0/16"
  enable_replication = var.regions.primary.enable_replication
}

module "primary_app" {
  source = "./modules/application"
  providers = {
    aws = aws.primary
  }
  
  vpc_id = module.primary_vpc.vpc_id
  environment = "production"
}

# DR infrastructure
module "dr_vpc" {
  source = "./modules/vpc"
  providers = {
    aws = aws.dr
  }
  
  region            = var.regions.dr.name
  cidr_block        = "10.1.0.0/16"
  enable_replication = var.regions.dr.enable_replication
}

module "dr_app" {
  source = "./modules/application"
  providers = {
    aws = aws.dr
  }
  
  vpc_id = module.dr_vpc.vpc_id
  environment = "disaster-recovery"
}

# RDS with multi-region replication
resource "aws_db_instance" "primary" {
  provider   = aws.primary
  identifier = "app-db-primary"
  engine     = "postgres"
  # ... configuration
  
  enabled_cloudwatch_logs_exports = ["postgresql"]
}

resource "aws_db_instance_replica" "dr" {
  provider          = aws.dr
  identifier        = "app-db-dr"
  replicate_source_db = aws_db_instance.primary.identifier
  # Cross-region replication automatically created
}

# Global S3 bucket with replication
resource "aws_s3_bucket" "primary" {
  provider = aws.primary
  bucket   = "app-data-primary-${data.aws_caller_identity.current.account_id}"
}

resource "aws_s3_bucket_replication_configuration" "primary" {
  provider = aws.primary
  bucket   = aws_s3_bucket.primary.id
  
  role = aws_iam_role.replication.arn
  
  rule {
    status = "Enabled"
    
    destination {
      bucket       = aws_s3_bucket.dr.arn
      storage_class = "STANDARD_IA"
      replication_time {
        status = "Enabled"
        time {
          minutes = 15
        }
      }
    }
  }
  
  depends_on = [aws_s3_bucket_versioning.primary]
}

resource "aws_s3_bucket" "dr" {
  provider = aws.dr
  bucket   = "app-data-dr-${data.aws_caller_identity.current.account_id}"
}

# Route53 health checks and failover
resource "aws_route53_health_check" "primary" {
  provider          = aws.primary
  ip_address        = module.primary_app.load_balancer_ip
  port              = 443
  type              = "HTTPS"
  failure_threshold = 3
  
  tags = { Name = "primary-health-check" }
}

resource "aws_route53_record" "app" {
  provider = aws.primary
  zone_id  = var.hosted_zone_id
  name     = "app.example.com"
  type     = "A"
  
  failover_routing_policy {
    type = "PRIMARY"
  }
  
  alias {
    name                   = module.primary_app.load_balancer_dns
    zone_id                = module.primary_app.load_balancer_zone_id
    evaluate_target_health = true
  }
}

resource "aws_route53_record" "app_dr" {
  provider = aws.dr
  zone_id  = var.hosted_zone_id
  name     = "app.example.com"
  type     = "A"
  
  failover_routing_policy {
    type = "SECONDARY"
  }
  
  alias {
    name                   = module.dr_app.load_balancer_dns
    zone_id                = module.dr_app.load_balancer_zone_id
    evaluate_target_health = true
  }
}

# Outputs
output "primary_endpoint" {
  value = module.primary_app.load_balancer_dns
}

output "dr_endpoint" {
  value = module.dr_app.load_balancer_dns
}

output "failover_endpoint" {
  value = "app.example.com"
}
```

---

#### Q12: Interview Scenario: Complex Networking Setup

**Scenario:**
"You need to create a VPC with public and private subnets across multiple AZs, with NAT gateways for HA, and bastion hosts for secure access."

**Solution:**

```hcl
# modules/networking/variables.tf
variable "vpc_cidr" {
  type = string
}

variable "environment" {
  type = string
}

variable "availability_zones" {
  type = list(string)
}

variable "bastion_ami_id" {
  type = string
}

variable "bastion_instance_type" {
  type    = string
  default = "t2.micro"
}

variable "private_key_path" {
  type      = string
  sensitive = true
}

# modules/networking/main.tf
locals {
  azs_count = length(var.availability_zones)
  
  # CIDR subnetting
  public_subnet_cidrs  = [for i in range(local.azs_count) : cidrsubnet(var.vpc_cidr, 2, i)]
  private_subnet_cidrs = [for i in range(local.azs_count) : cidrsubnet(var.vpc_cidr, 2, i + local.azs_count)]
}

# VPC
resource "aws_vpc" "main" {
  cidr_block           = var.vpc_cidr
  enable_dns_hostnames = true
  enable_dns_support   = true
  
  tags = { Name = "${var.environment}-vpc" }
}

# Internet Gateway
resource "aws_internet_gateway" "main" {
  vpc_id = aws_vpc.main.id
  
  tags = { Name = "${var.environment}-igw" }
}

# Public Subnets
resource "aws_subnet" "public" {
  count                   = local.azs_count
  vpc_id                  = aws_vpc.main.id
  cidr_block              = local.public_subnet_cidrs[count.index]
  availability_zone       = var.availability_zones[count.index]
  map_public_ip_on_launch = true
  
  tags = { Name = "${var.environment}-public-subnet-${count.index + 1}" }
}

# Private Subnets
resource "aws_subnet" "private" {
  count             = local.azs_count
  vpc_id            = aws_vpc.main.id
  cidr_block        = local.private_subnet_cidrs[count.index]
  availability_zone = var.availability_zones[count.index]
  
  tags = { Name = "${var.environment}-private-subnet-${count.index + 1}" }
}

# Elastic IPs for NAT Gateways
resource "aws_eip" "nat" {
  count    = local.azs_count
  domain   = "vpc"
  
  depends_on = [aws_internet_gateway.main]
  
  tags = { Name = "${var.environment}-eip-${count.index + 1}" }
}

# NAT Gateways (one per AZ for HA)
resource "aws_nat_gateway" "main" {
  count         = local.azs_count
  allocation_id = aws_eip.nat[count.index].id
  subnet_id     = aws_subnet.public[count.index].id
  
  depends_on = [aws_internet_gateway.main]
  
  tags = { Name = "${var.environment}-nat-${count.index + 1}" }
}

# Public Route Table
resource "aws_route_table" "public" {
  vpc_id = aws_vpc.main.id
  
  route {
    cidr_block = "0.0.0.0/0"
    gateway_id = aws_internet_gateway.main.id
  }
  
  tags = { Name = "${var.environment}-public-rt" }
}

# Public Route Table Associations
resource "aws_route_table_association" "public" {
  count          = local.azs_count
  subnet_id      = aws_subnet.public[count.index].id
  route_table_id = aws_route_table.public.id
}

# Private Route Tables (one per AZ for isolated routing)
resource "aws_route_table" "private" {
  count  = local.azs_count
  vpc_id = aws_vpc.main.id
  
  route {
    cidr_block     = "0.0.0.0/0"
    nat_gateway_id = aws_nat_gateway.main[count.index].id
  }
  
  tags = { Name = "${var.environment}-private-rt-${count.index + 1}" }
}

# Private Route Table Associations
resource "aws_route_table_association" "private" {
  count          = local.azs_count
  subnet_id      = aws_subnet.private[count.index].id
  route_table_id = aws_route_table.private[count.index].id
}

# Bastion Security Group
resource "aws_security_group" "bastion" {
  name_prefix = "bastion-"
  vpc_id      = aws_vpc.main.id
  
  ingress {
    from_port   = 22
    to_port     = 22
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]  # ⚠️ Restrict this in production!
  }
  
  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }
  
  tags = { Name = "${var.environment}-bastion-sg" }
}

# Bastion Key Pair
resource "aws_key_pair" "bastion" {
  key_name   = "${var.environment}-bastion-key"
  public_key = file("${var.private_key_path}.pub")
}

# Bastion Hosts (one per AZ for HA)
resource "aws_instance" "bastion" {
  count                = local.azs_count
  ami                  = var.bastion_ami_id
  instance_type        = var.bastion_instance_type
  subnet_id            = aws_subnet.public[count.index].id
  vpc_security_group_ids = [aws_security_group.bastion.id]
  key_name             = aws_key_pair.bastion.key_name
  
  tags = { Name = "${var.environment}-bastion-${count.index + 1}" }
}

# Outputs
output "vpc_id" {
  value = aws_vpc.main.id
}

output "public_subnet_ids" {
  value = aws_subnet.public[*].id
}

output "private_subnet_ids" {
  value = aws_subnet.private[*].id
}

output "bastion_public_ips" {
  value = aws_instance.bastion[*].public_ip
}

output "nat_gateway_ips" {
  value = aws_eip.nat[*].public_ip
}
```

**Usage:**

```hcl
# main.tf
data "aws_ami" "ubuntu" {
  most_recent = true
  filter {
    name   = "name"
    values = ["ubuntu/images/hvm-ssd/ubuntu-focal-20.04-*"]
  }
  owners = ["099720109477"]
}

module "networking" {
  source = "./modules/networking"
  
  vpc_cidr                = "10.0.0.0/16"
  environment             = var.environment
  availability_zones      = data.aws_availability_zones.available.names
  bastion_ami_id          = data.aws_ami.ubuntu.id
  bastion_instance_type   = "t2.micro"
  private_key_path        = "~/.ssh/id_rsa"
}

data "aws_availability_zones" "available" {
  state = "available"
}
```

---

#### Q13: Interview Scenario: Database High Availability & Backup Strategy

**Scenario:**
"Design a multi-AZ RDS setup with automated backups, read replicas, and disaster recovery."

**Solution:**

```hcl
# modules/database/main.tf
variable "environment" {
  type = string
}

variable "allocated_storage" {
  type    = number
  default = 20
}

variable "engine_version" {
  type = string
}

variable "db_subnet_ids" {
  type = list(string)
}

variable "vpc_security_group_ids" {
  type = list(string)
}

variable "backup_retention_days" {
  type    = number
  default = 30
}

# DB Subnet Group (required for multi-AZ)
resource "aws_db_subnet_group" "main" {
  name       = "${var.environment}-db-subnet-group"
  subnet_ids = var.db_subnet_ids
  
  tags = { Name = "${var.environment}-db-subnet-group" }
}

# Primary Multi-AZ Database
resource "aws_db_instance" "primary" {
  identifier              = "${var.environment}-postgres"
  engine                  = "postgres"
  engine_version          = var.engine_version
  instance_class          = "db.t3.micro"
  allocated_storage       = var.allocated_storage
  storage_type            = "gp3"
  
  db_name                 = "appdb"
  username                = "postgres"
  password                = random_password.db_password.result
  
  db_subnet_group_name    = aws_db_subnet_group.main.name
  vpc_security_group_ids  = var.vpc_security_group_ids
  
  # Multi-AZ configuration
  multi_az                = true
  publicly_accessible     = false
  
  # Backup configuration
  backup_retention_period = var.backup_retention_days
  backup_window           = "03:00-04:00"
  maintenance_window      = "mon:04:00-mon:05:00"
  copy_tags_to_snapshot   = true
  
  # Performance monitoring
  enabled_cloudwatch_logs_exports = ["postgresql"]
  monitoring_interval      = 60
  monitoring_role_arn      = aws_iam_role.rds_monitoring.arn
  
  # Deletion protection
  skip_final_snapshot      = false
  final_snapshot_identifier = "${var.environment}-postgres-final-snapshot-$(date +%s)"
  
  tags = { Name = "${var.environment}-postgres-primary" }
}

# Password stored securely
resource "random_password" "db_password" {
  length  = 32
  special = true
}

# Store password in Secrets Manager
resource "aws_secretsmanager_secret" "db_password" {
  name = "${var.environment}/rds/password"
}

resource "aws_secretsmanager_secret_version" "db_password" {
  secret_id     = aws_secretsmanager_secret.db_password.id
  secret_string = random_password.db_password.result
}

# Read Replica for reporting/analytics
resource "aws_db_instance" "read_replica" {
  identifier           = "${var.environment}-postgres-read-replica"
  replicate_source_db  = aws_db_instance.primary.identifier
  instance_class       = "db.t3.micro"
  publicly_accessible  = false
  skip_final_snapshot  = true
  
  tags = { Name = "${var.environment}-postgres-read-replica" }
}

# Automated backup copy to different region (DR)
resource "aws_backup_vault" "dr" {
  name = "${var.environment}-backup-vault-dr"
}

resource "aws_backup_plan" "dr" {
  name = "${var.environment}-dr-backup-plan"
  
  rule {
    rule_name         = "daily_snapshots"
    target_backup_vault_name = aws_backup_vault.dr.name
    
    schedule = "cron(0 3 * * ? *)"  # Daily at 3 AM
    
    lifecycle {
      delete_after = var.backup_retention_days
    }
    
    copy_action {
      destination_vault_arn = aws_backup_vault.dr.arn
      lifecycle {
        delete_after = var.backup_retention_days
      }
    }
  }
}

# Enable automatic backups
resource "aws_backup_resource_assignment" "rds" {
  name             = "${var.environment}-rds-backup"
  plan_id          = aws_backup_plan.dr.id
  iam_role_arn     = aws_iam_role.backup.arn
  resource_type    = "RDS"
  resources        = [aws_db_instance.primary.arn]
}

# IAM Role for RDS monitoring
resource "aws_iam_role" "rds_monitoring" {
  name_prefix = "rds-monitoring-"
  
  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [{
      Action = "sts:AssumeRole"
      Effect = "Allow"
      Principal = {
        Service = "monitoring.rds.amazonaws.com"
      }
    }]
  })
}

resource "aws_iam_role_policy_attachment" "rds_monitoring" {
  role       = aws_iam_role.rds_monitoring.name
  policy_arn = "arn:aws:iam::aws:policy/service-role/AmazonRDSEnhancedMonitoringRole"
}

# IAM Role for backups
resource "aws_iam_role" "backup" {
  name_prefix = "backup-"
  
  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [{
      Action = "sts:AssumeRole"
      Effect = "Allow"
      Principal = {
        Service = "backup.amazonaws.com"
      }
    }]
  })
}

resource "aws_iam_role_policy_attachment" "backup" {
  role       = aws_iam_role.backup.name
  policy_arn = "arn:aws:iam::aws:policy/service-role/AWSBackupServiceRolePolicyForBackup"
}

# CloudWatch Alarms for monitoring
resource "aws_cloudwatch_metric_alarm" "db_cpu" {
  alarm_name          = "${var.environment}-db-high-cpu"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = "2"
  metric_name         = "CPUUtilization"
  namespace           = "AWS/RDS"
  period              = "300"
  statistic           = "Average"
  threshold           = "80"
  
  dimensions = {
    DBInstanceIdentifier = aws_db_instance.primary.identifier
  }
}

resource "aws_cloudwatch_metric_alarm" "db_connections" {
  alarm_name          = "${var.environment}-db-high-connections"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = "2"
  metric_name         = "DatabaseConnections"
  namespace           = "AWS/RDS"
  period              = "300"
  statistic           = "Average"
  threshold           = "100"
  
  dimensions = {
    DBInstanceIdentifier = aws_db_instance.primary.identifier
  }
}

# Outputs
output "primary_endpoint" {
  value     = aws_db_instance.primary.endpoint
  sensitive = false
}

output "read_replica_endpoint" {
  value = aws_db_instance.read_replica.endpoint
}

output "db_password_secret_arn" {
  value = aws_secretsmanager_secret.db_password.arn
  sensitive = true
}
```

---

#### Q14: Interview Scenario: CI/CD Pipeline with Terraform

**Scenario:**
"Design a GitOps workflow that automatically applies Terraform changes when code is pushed to specific branches."

**Solution:**

```bash
# .github/workflows/terraform.yml
name: Terraform CI/CD

on:
  push:
    branches:
      - main
      - develop
    paths:
      - 'infrastructure/**'
      - '.github/workflows/terraform.yml'
  pull_request:
    branches:
      - main
      - develop

env:
  AWS_REGION: us-east-1
  TF_VERSION: 1.5.0

jobs:
  terraform:
    runs-on: ubuntu-latest
    
    strategy:
      matrix:
        environment: [dev, staging, prod]
      max-parallel: 1  # Sequential to prevent conflicts
    
    environment:
      name: terraform-${{ matrix.environment }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Set up Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: ${{ env.TF_VERSION }}
          terraform_wrapper: true
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          role-to-assume: ${{ secrets[format('AWS_ROLE_{0}', matrix.environment)] }}
          role-session-name: terraform-ci-cd
          aws-region: ${{ env.AWS_REGION }}
      
      - name: Terraform Init
        working-directory: infrastructure/${{ matrix.environment }}
        run: terraform init
      
      - name: Terraform Validate
        working-directory: infrastructure/${{ matrix.environment }}
        run: terraform validate
      
      - name: Terraform Format Check
        working-directory: infrastructure/${{ matrix.environment }}
        run: terraform fmt -check -recursive
      
      - name: Terraform Plan
        working-directory: infrastructure/${{ matrix.environment }}
        run: |
          terraform plan -out=tfplan -no-color > plan_output.txt
          cat plan_output.txt
      
      - name: Comment PR with Plan
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const plan = fs.readFileSync('infrastructure/${{ matrix.environment }}/plan_output.txt', 'utf8');
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `## Terraform Plan - ${{ matrix.environment }}\n\`\`\`\n${plan}\n\`\`\``
            });
      
      - name: Approve Apply
        if: github.ref == 'refs/heads/main' && github.event_name == 'push'
        run: echo "Proceeding with apply..."
      
      - name: Terraform Apply
        if: github.ref == 'refs/heads/main' && github.event_name == 'push'
        working-directory: infrastructure/${{ matrix.environment }}
        run: terraform apply -auto-approve tfplan
      
      - name: Upload State Backup
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: terraform-state-${{ matrix.environment }}
          path: infrastructure/${{ matrix.environment }}/terraform.tfstate
```

---

#### Q15: Interview Question: State File Security

**Q: How would you secure a Terraform state file that contains sensitive data like database passwords and API keys?**

**Answer:**

Multiple layers of protection:

```hcl
# 1. Remote State with Encryption
terraform {
  backend "s3" {
    bucket         = "company-terraform-state"
    key            = "prod/terraform.tfstate"
    region         = "us-east-1"
    encrypt        = true                    # SSE-S3 encryption
    dynamodb_table = "terraform-locks"
  }
}

# 2. S3 Bucket Policies
resource "aws_s3_bucket" "terraform_state" {
  bucket = "company-terraform-state"
}

resource "aws_s3_bucket_versioning" "terraform_state" {
  bucket = aws_s3_bucket.terraform_state.id
  
  versioning_configuration {
    status = "Enabled"
  }
}

resource "aws_s3_bucket_server_side_encryption_configuration" "terraform_state" {
  bucket = aws_s3_bucket.terraform_state.id

  rule {
    apply_server_side_encryption_by_default {
      sse_algorithm     = "aws:kms"
      kms_master_key_id = aws_kms_key.terraform_state.arn
    }
  }
}

resource "aws_s3_bucket_public_access_block" "terraform_state" {
  bucket = aws_s3_bucket.terraform_state.id

  block_public_acls       = true
  block_public_policy     = true
  ignore_public_acls      = true
  restrict_public_buckets = true
}

# 3. KMS Key for Enhanced Security
resource "aws_kms_key" "terraform_state" {
  description             = "KMS key for Terraform state encryption"
  deletion_window_in_days = 30
  enable_key_rotation     = true

  tags = { Name = "terraform-state-key" }
}

# 4. DynamoDB for State Locking
resource "aws_dynamodb_table" "terraform_locks" {
  name           = "terraform-locks"
  billing_mode   = "PAY_PER_REQUEST"
  hash_key       = "LockID"

  attribute {
    name = "LockID"
    type = "S"
  }

  server_side_encryption {
    enabled = true
  }

  point_in_time_recovery {
    enabled = true
  }

  tags = { Name = "terraform-locks" }
}

# 5. IAM Access Control
resource "aws_iam_policy" "terraform_state_access" {
  name   = "terraform-state-access"
  policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Effect = "Allow"
        Action = [
          "s3:GetObject",
          "s3:PutObject",
          "s3:DeleteObject"
        ]
        Resource = "${aws_s3_bucket.terraform_state.arn}/*"
      },
      {
        Effect = "Allow"
        Action = [
          "dynamodb:GetItem",
          "dynamodb:PutItem",
          "dynamodb:DeleteItem",
          "dynamodb:DescribeTable"
        ]
        Resource = aws_dynamodb_table.terraform_locks.arn
      },
      {
        Effect = "Allow"
        Action = [
          "kms:Decrypt",
          "kms:GenerateDataKey"
        ]
        Resource = aws_kms_key.terraform_state.arn
      }
    ]
  })
}

# 6. Mark Sensitive Outputs
output "db_password" {
  description = "RDS password"
  value       = aws_db_instance.main.password
  sensitive   = true  # Won't show in terminal output
}

# 7. Use Secrets Management
resource "aws_secretsmanager_secret" "terraform_vars" {
  name = "terraform/prod/secrets"
}

resource "aws_secretsmanager_secret_version" "terraform_vars" {
  secret_id = aws_secretsmanager_secret.terraform_vars.id
  secret_string = jsonencode({
    db_password = random_password.db_password.result
    api_key     = var.api_key
  })
}
```

**Best Practices Summary:**
1. ✅ Store state remotely (S3, Azure, GCS, etc.)
2. ✅ Enable encryption (SSE or KMS)
3. ✅ Use IAM policies to restrict access
4. ✅ Enable state locking
5. ✅ Enable versioning for recovery
6. ✅ Use secrets management for sensitive values
7. ✅ Mark outputs as sensitive
8. ✅ Never commit state files to Git
9. ✅ Enable MFA delete protection
10. ✅ Regular backup and disaster recovery testing

---

## Complete Interview Questions Repository

### Category: Fundamentals & Concepts

#### Q16: What is the difference between Terraform and CloudFormation?

**Answer:**

| Feature | Terraform | CloudFormation |
|---------|-----------|----------------|
| **Provider Support** | Multi-cloud (50+) | AWS only |
| **Language** | HCL (custom) | JSON/YAML |
| **State Management** | Explicit state file | Implicit (in AWS) |
| **Learning Curve** | Moderate | Steeper (AWS-specific) |
| **Community** | Large, platform-agnostic | AWS-focused |
| **Modularity** | Native modules | Nested stacks |
| **Cost** | Open-source (free) | Integrated in AWS |
| **Drift Detection** | Manual (terraform refresh) | Native CloudFormation Drift |

**When to use Terraform:**
- Multi-cloud environments
- Preference for HCL syntax
- Need for community modules

**When to use CloudFormation:**
- AWS-only infrastructure
- Deep AWS integration required
- Team already knows CloudFormation

---

#### Q17: Explain what happens when you run `terraform apply` without `terraform plan`.

**Answer:**

Running `terraform apply` without prior `terraform plan`:

```bash
terraform apply  # Runs plan internally, then asks for confirmation
```

**What happens:**
1. Terraform runs plan internally (not saved to file)
2. Shows changes and asks for confirmation
3. If approved, applies changes
4. Updates state file

**Risks:**
- Cannot review plan before executing
- No saved plan for audit trail
- Potential for mistakes

**Best Practice:**

```bash
# Always use this workflow
terraform plan -out=tfplan
# Review tfplan manually
terraform apply tfplan  # Applies exact plan, no confirmation needed
```

---

#### Q18: What is the purpose of `.terraformignore` file?

**Answer:**

`.terraformignore` specifies files and directories to exclude when packaging modules for Terraform Cloud/Enterprise or module registries.

```
# .terraformignore
.git/
.gitignore
.terraform/
*.tfstate
*.tfstate.*
*.swp
*.swo
.DS_Store
*.pem
*.key
README.md
CONTRIBUTING.md
```

**Common use cases:**
- Exclude documentation
- Exclude git metadata
- Exclude sensitive files (keys, credentials)
- Exclude large binaries

---

#### Q19: What is the difference between `terraform destroy` and manually deleting resources?

**Answer:**

| Aspect | Terraform Destroy | Manual Deletion |
|--------|------------------|-----------------|
| **State Sync** | Updates state automatically | State remains outdated |
| **Dependency Handling** | Respects dependencies | May fail due to dependencies |
| **Reproducibility** | Consistent | Unpredictable |
| **Audit Trail** | State history preserved | No record |
| **Safety** | Prompts for confirmation | Immediate deletion |

**Using terraform destroy safely:**

```bash
# Review what will be destroyed
terraform plan -destroy

# Confirm before destroying
terraform destroy

# Force destroy (skip confirmation)
terraform destroy -auto-approve

# Destroy specific resource
terraform destroy -target=aws_instance.web[0]
```

---

#### Q20: What does `terraform refresh` do?

**Answer:**

`terraform refresh` queries cloud providers and updates the state file to match real infrastructure without modifying it.

```bash
terraform refresh
```

**Use cases:**
- Infrastructure modified outside Terraform
- State file out of sync with reality
- Manual changes made in AWS console

**Example:**
```bash
# Someone manually deleted an EC2 instance
terraform refresh
# terraform.tfstate now shows instance as deleted

terraform plan
# Shows destruction of deleted instance in state
```

**Modern alternative:**
```bash
# Better: refresh-only apply
terraform apply -refresh-only
```

---

### Category: State Management

#### Q21: How do you migrate state from local to remote?

**Answer:**

**Step-by-step migration to S3:**

```bash
# 1. Current: Local state (terraform.tfstate exists)
# 2. Create S3 backend (manual or separate Terraform code)

aws s3 mb s3://my-terraform-state
aws dynamodb create-table \
  --table-name terraform-locks \
  --attribute-definitions AttributeName=LockID,AttributeType=S \
  --key-schema AttributeName=LockID,KeyType=HASH \
  --provisioned-throughput ReadCapacityUnits=5,WriteCapacityUnits=5

# 3. Add backend configuration
# main.tf (or backend.tf)
terraform {
  backend "s3" {
    bucket         = "my-terraform-state"
    key            = "prod/terraform.tfstate"
    region         = "us-east-1"
    encrypt        = true
    dynamodb_table = "terraform-locks"
  }
}

# 4. Reinitialize
terraform init  # Terraform detects local state and asks to migrate
# Answer: yes (to migrate state to S3)

# 5. Verify
terraform state list  # Should work with remote state
```

---

#### Q22: Can you have multiple states for the same infrastructure?

**Answer:**

**No, you should avoid this.** One infrastructure should have one state file. However:

**Valid multi-state scenarios:**

```hcl
# Scenario 1: Different environments (separate directories)
environments/
├── dev/
│   └── main.tf  # dev state
├── staging/
│   └── main.tf  # staging state
└── prod/
    └── main.tf  # prod state

# Scenario 2: Using workspaces (not recommended for prod)
terraform workspace new dev
terraform workspace new staging
terraform workspace new prod
# Each has separate state, but same directory
```

**Anti-pattern (avoid):**
```hcl
# ❌ Bad: Multiple state files for same infrastructure
state_file_1.tfstate  # Contains VPC
state_file_2.tfstate  # Also contains VPC
# Creates conflicts and state inconsistency
```

**Best Practice:**
```hcl
# ✅ Good: One state per environment in separate directories
.
├── environments/
│   ├── dev/
│   │   ├── backend.tf       # Separate backend
│   │   ├── main.tf
│   │   ├── variables.tf
│   │   └── terraform.tfstate
│   ├── prod/
│   │   ├── backend.tf       # Different backend
│   │   ├── main.tf
│   │   ├── variables.tf
│   │   └── terraform.tfstate
```

---

#### Q23: What is state locking and when is it important?

**Answer:**

**State Locking** prevents concurrent modifications to state file.

**Without locking:**
```bash
# User A
terraform apply
# Takes 5 minutes

# User B (during user A's apply)
terraform apply
# Both modify state simultaneously
# Data corruption/conflict
```

**With locking:**
```bash
# User A
terraform apply
# Acquires lock on state file

# User B (during user A's apply)
terraform apply
# Waits for lock to be released
# Applies after user A completes
```

**Implementation:**

```hcl
terraform {
  backend "s3" {
    bucket         = "my-state"
    key            = "prod/terraform.tfstate"
    region         = "us-east-1"
    dynamodb_table = "terraform-locks"  # Enables locking
  }
}
```

**Lock enforcement:**
- S3 + DynamoDB (AWS)
- Azure Storage with Blob lease
- Terraform Cloud (automatic)

---

#### Q24: How do you restore a deleted resource from state backup?

**Answer:**

**Scenario:** Someone ran `terraform destroy` accidentally.

**Recovery steps:**

```bash
# 1. Check S3 versioning (if enabled)
aws s3api list-object-versions \
  --bucket my-terraform-state \
  --prefix prod/terraform.tfstate

# 2. Restore from previous version
aws s3api get-object \
  --bucket my-terraform-state \
  --key prod/terraform.tfstate \
  --version-id <VERSION_ID> \
  terraform.tfstate.recovered

# 3. Verify restored state
mv terraform.tfstate terraform.tfstate.corrupt
mv terraform.tfstate.recovered terraform.tfstate

# 4. Check state
terraform state list
terraform state show aws_instance.web

# 5. Reapply
terraform apply  # Recreates deleted resources
```

**Prevention:**
```hcl
# 1. Enable S3 versioning
resource "aws_s3_bucket_versioning" "terraform_state" {
  bucket = aws_s3_bucket.terraform_state.id
  
  versioning_configuration {
    status = "Enabled"
  }
}

# 2. Prevent accidental destroy
resource "aws_instance" "critical" {
  # ... configuration
  
  lifecycle {
    prevent_destroy = true
  }
}

# 3. Require explicit destroy
terraform destroy -target=aws_instance.critical
# Error: Resource has prevent_destroy set to true
```

---

### Category: Advanced Scenarios

#### Q25: How do you handle zero-downtime deployments with Terraform?

**Answer:**

**Strategy: Blue-Green Deployment**

```hcl
variable "active_environment" {
  type    = string
  default = "blue"  # or "green"
}

locals {
  blue_weight  = var.active_environment == "blue" ? 100 : 0
  green_weight = var.active_environment == "green" ? 100 : 0
}

# Blue environment
resource "aws_launch_configuration" "blue" {
  image_id      = var.blue_ami_id
  instance_type = "t2.small"
  # ...
}

resource "aws_autoscaling_group" "blue" {
  name                = "blue-asg"
  launch_configuration = aws_launch_configuration.blue.name
  min_size            = 2
  max_size            = 5
  desired_capacity    = local.blue_weight > 0 ? 3 : 0
  # ...
}

# Green environment (new version)
resource "aws_launch_configuration" "green" {
  image_id      = var.green_ami_id  # New version
  instance_type = "t2.small"
  # ...
}

resource "aws_autoscaling_group" "green" {
  name                = "green-asg"
  launch_configuration = aws_launch_configuration.green.name
  min_size            = 2
  max_size            = 5
  desired_capacity    = local.green_weight > 0 ? 3 : 0
  # ...
}

# Load Balancer routes to active environment
resource "aws_lb_target_group" "blue" {
  name = "blue-tg"
  # ...
}

resource "aws_lb_target_group" "green" {
  name = "green-tg"
  # ...
}

resource "aws_lb_listener" "app" {
  load_balancer_arn = aws_lb.main.arn
  port              = 80
  protocol          = "HTTP"
  
  default_action {
    type             = "forward"
    target_group_arn = local.blue_weight > 0 ? aws_lb_target_group.blue.arn : aws_lb_target_group.green.arn
  }
}

# To deploy green:
# 1. terraform apply -var="active_environment=green"
#    (Green infrastructure created, Blue still active)
# 2. Test green endpoint thoroughly
# 3. terraform apply -var="active_environment=blue"
#    (Switch traffic to green, Blue becomes standby)
# 4. If issues, switch back immediately
```

**Alternative: Canary Deployment**

```hcl
resource "aws_lb_listener_rule" "canary" {
  listener_arn = aws_lb_listener.app.arn
  priority     = 100
  
  action {
    type = "forward"
    forward {
      target_group {
        arn    = aws_lb_target_group.blue.arn
        weight = 90
      }
      target_group {
        arn    = aws_lb_target_group.green.arn
        weight = 10
      }
    }
  }
}
```

---

#### Q26: How do you integrate Terraform with a CI/CD pipeline?

**Answer:**

**GitOps Workflow with GitHub Actions:**

```yaml
# .github/workflows/terraform.yml
name: Terraform Plan & Apply

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  terraform:
    runs-on: ubuntu-latest
    
    env:
      TF_VERSION: 1.5.0
      AWS_REGION: us-east-1
    
    steps:
      # 1. Checkout code
      - uses: actions/checkout@v3
      
      # 2. Setup Terraform
      - uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: ${{ env.TF_VERSION }}
      
      # 3. AWS credentials
      - uses: aws-actions/configure-aws-credentials@v2
        with:
          role-to-assume: ${{ secrets.AWS_ROLE }}
          aws-region: ${{ env.AWS_REGION }}
      
      # 4. Init
      - run: terraform init
      
      # 5. Validate
      - run: terraform validate
      - run: terraform fmt -check
      
      # 6. Plan
      - run: terraform plan -out=tfplan
      
      # 7. Comment plan on PR
      - if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            const plan = require('fs').readFileSync('tfplan', 'utf8');
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `## Terraform Plan\n\`\`\`\n${plan}\n\`\`\``
            });
      
      # 8. Apply (only on main)
      - if: github.ref == 'refs/heads/main'
        run: terraform apply -auto-approve tfplan
```

**Key Points:**
- Plan on PR, apply on merge
- Use OIDC for AWS auth (no long-lived keys)
- Require PR approval before apply
- Comment plans on PRs for visibility

---

#### Q27: How do you test Terraform code?

**Answer:**

**Testing Strategy:**

```bash
# 1. Syntax validation
terraform validate

# 2. Code formatting
terraform fmt -recursive -check

# 3. Linting
tfsec .              # Security scanning
checkov -d .         # Compliance checking

# 4. Unit testing (mocking)
# Use Terratest (Go-based)
```

**Terratest Example:**

```go
// test_main.go
package test

import (
	"testing"
	"github.com/gruntwork-io/terratest/modules/terraform"
	"github.com/stretchr/testify/assert"
)

func TestVPCCreation(t *testing.T) {
	terraformOptions := &terraform.Options{
		TerraformDir: "./",
		Vars: map[string]interface{}{
			"vpc_cidr": "10.0.0.0/16",
		},
	}

	defer terraform.Destroy(t, terraformOptions)

	terraform.InitAndApply(t, terraformOptions)

	vpc_id := terraform.Output(t, terraformOptions, "vpc_id")
	assert.NotEmpty(t, vpc_id)
}
```

**5. Integration testing**
```bash
# Run in test environment
terraform init
terraform apply -var-file=test.tfvars
# Run application tests
terraform destroy
```

**Testing Best Practices:**
- Test in ephemeral environments
- Use mocking for expensive resources
- Test both happy paths and error cases
- Test variable validation
- Document test coverage

---

#### Q28: How do you handle sensitive data rotation in Terraform?

**Answer:**

**Scenario:** Rotating database passwords.

```hcl
# variables.tf
variable "force_password_rotation" {
  type    = bool
  default = false
  description = "Set to true to force password rotation"
}

# main.tf
resource "random_password" "db_password" {
  length  = 32
  special = true
  
  keepers = {
    rotate = var.force_password_rotation
  }
}

resource "aws_db_instance" "main" {
  password = random_password.db_password.result
  # ... other config
}

# To rotate:
# 1. Set terraform.tfvars:
#    force_password_rotation = true
# 2. Run:
terraform apply -var="force_password_rotation=true"

# 3. After password is updated, reset:
#    force_password_rotation = false
terraform apply -var="force_password_rotation=false"
```

**Advanced: Automatic rotation with Secrets Manager:**

```hcl
resource "aws_secretsmanager_secret" "db_password" {
  name                    = "prod/rds/password"
  recovery_window_in_days = 7
}

resource "aws_secretsmanager_secret_version" "db_password" {
  secret_id     = aws_secretsmanager_secret.db_password.id
  secret_string = random_password.db_password.result
}

resource "aws_secretsmanager_secret_rotation" "db_password" {
  secret_id           = aws_secretsmanager_secret.db_password.id
  rotation_enabled    = true
  rotation_lambda_arn = aws_lambda_function.rotate.arn
  rotation_rules {
    automatically_after_days = 30
  }
}

resource "aws_lambda_function" "rotate" {
  filename = "rotate_password.zip"
  # ... Lambda function that rotates RDS password
}
```

---

#### Q29: How do you manage Terraform in a large enterprise with multiple teams?

**Answer:**

**Enterprise Terraform Structure:**

```
company/
├── terraform-registry/          # Module registry
│   ├── modules/
│   │   ├── vpc/
│   │   ├── rds/
│   │   ├── security-group/
│   │   └── iam/
│   └── README.md
│
├── platform-team/               # Core infrastructure
│   ├── environments/
│   │   ├── dev/
│   │   ├── staging/
│   │   └── prod/
│   ├── terraform/
│   │   ├── main.tf
│   │   ├── backend.tf
│   │   └── variables.tf
│   └── README.md
│
├── application-teams/
│   ├── team-a/
│   │   ├── environments/
│   │   │   ├── dev/
│   │   │   ├── staging/
│   │   │   └── prod/
│   │   └── terraform/
│   │       └── main.tf
│   └── team-b/
│       └── ...
│
└── policies/                    # Governance
    ├── sentinel/               # Policy as Code
    ├── tfvars-templates/
    └── guidelines.md
```

**Terraform Cloud Organization:**

```hcl
# Terraform Cloud setup
terraform {
  cloud {
    organization = "my-company"
    
    workspaces {
      tags = ["team-a", "prod"]
    }
  }
}
```

**Policy as Code (Sentinel):**

```hcl
# policy/require-tags.sentinel
import "tfplan/v2" as tfplan

main = rule {
  all tfplan.resource_changes as _, rc {
    rc.change.after.tags contains "Environment"
  }
}
```

**Team Governance:**

1. **Shared Module Registry:**
   ```hcl
   module "vpc" {
     source = "app.terraform.io/my-company/vpc/aws"
     version = "~> 2.0"
   }
   ```

2. **Variable Constraints:**
   ```hcl
   variable "instance_type" {
     type    = string
     default = "t2.micro"
     
     validation {
       condition     = contains(["t2.micro", "t2.small", "t2.medium"], var.instance_type)
       error_message = "Only approved instance types allowed."
     }
   }
   ```

3. **Cost Controls:**
   ```bash
   # Estimate costs before apply
   terraform plan -out=tfplan
   terraform estimate [tfplan]
   ```

---

#### Q30: How do you handle Terraform version compatibility?

**Answer:**

**Version Management:**

```hcl
# main.tf - Specify minimum version
terraform {
  required_version = ">= 1.0"
  
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 4.0, < 5.0"
    }
    azurerm = {
      source  = "hashicorp/azurerm"
      version = "~> 3.0"
    }
  }
}
```

**Upgrade Process:**

```bash
# 1. Check current version
terraform version

# 2. Upgrade Terraform
# On macOS: brew upgrade terraform
# On Windows: choco upgrade terraform

# 3. Upgrade providers
terraform init -upgrade

# 4. Check for breaking changes
terraform validate

# 5. Test in dev environment
terraform plan

# 6. Commit lock file
git add .terraform.lock.hcl
git commit -m "Upgrade Terraform and providers"
```

**Lock File Management:**

```bash
# .terraform.lock.hcl stores exact versions
# Always commit this file to version control
git add .terraform.lock.hcl
```

---

### Category: Common Errors & Troubleshooting

#### Q31: Error: `Error acquiring the state lock`. How do you resolve it?

**Answer:**

**Cause:** Another process is holding the state lock (crashed apply, network issue, etc.).

**Resolution:**

```bash
# 1. Check lock status
terraform state list
# If command hangs, state is locked

# 2. Find lock ID
aws dynamodb scan --table-name terraform-locks

# 3. Force unlock (use cautiously!)
terraform force-unlock <LOCK_ID>

# 4. Investigate what went wrong
# Check previous apply logs
# Run terraform plan to verify state

# 5. Retry apply
terraform apply
```

**Prevention:**

```hcl
# 1. Use state locking
terraform {
  backend "s3" {
    dynamodb_table = "terraform-locks"
  }
}

# 2. Set lock timeout
TF_HTTP_LOCK_TIMEOUT=5m terraform apply

# 3. Monitor CI/CD pipelines
# Ensure applies complete or fail properly
```

---

#### Q32: Error: `Module not found`. What could be wrong?

**Answer:**

**Possible causes and solutions:**

```bash
# 1. Path issue
# ❌ Wrong: relative path
module "vpc" {
  source = "modules/vpc"
}

# ✅ Correct: relative path from root
module "vpc" {
  source = "./modules/vpc"
}

# 2. Git SSH key not found
# ❌ Wrong: HTTPS without auth
module "vpc" {
  source = "https://github.com/company/vpc-module.git"
}

# ✅ Correct: SSH with configured key
module "vpc" {
  source = "git::ssh://git@github.com/company/vpc-module.git"
}

# 3. Missing module initialization
terraform init
terraform get -update

# 4. Version mismatch
module "vpc" {
  source  = "terraform-aws-modules/vpc/aws"
  version = "~> 3.0"  # Specify version
}
```

**Troubleshooting:**

```bash
# List loaded modules
terraform providers

# Get module details
terraform get -update

# Validate configuration
terraform validate

# Check module location
ls -la .terraform/modules/
```

---

#### Q33: Error: `Resource already exists`. What does it mean?

**Answer:**

**Cause:** Resource exists in cloud but not in Terraform state.

```bash
# Error: error creating EC2 Instance: InvalidParameterValue: 
# Value (my-instance) already exists
```

**Solutions:**

```bash
# Option 1: Import existing resource
terraform import aws_instance.web i-1234567890abcdef0

# Write resource config
resource "aws_instance" "web" {
  ami           = "ami-0c55b159cbfafe1f0"
  instance_type = "t2.micro"
}

# Option 2: Use different name
resource "aws_instance" "web_v2" {
  ami           = "ami-0c55b159cbfafe1f0"
  instance_type = "t2.micro"
  
  tags = { Name = "my-instance-v2" }
}

# Option 3: Remove from state (dangerous)
terraform state rm aws_instance.web
# Now Terraform won't manage it

# Option 4: Rename resource
terraform state mv aws_instance.old aws_instance.new
```

---

#### Q34: How do you debug Terraform issues?

**Answer:**

**Debug Techniques:**

```bash
# 1. Enable debug logging
export TF_LOG=DEBUG
export TF_LOG_PATH=terraform-debug.log
terraform apply

# 2. Trace API calls
export TF_LOG=TRACE
terraform apply

# 3. Pretty print state
terraform state show -json | jq .

# 4. Graph dependencies
terraform graph | dot -Tpng > graph.png

# 5. Validate syntax
terraform validate

# 6. Format check
terraform fmt -check -recursive

# 7. Show detailed plan
terraform plan -input=false -lock=false

# 8. Inspect variables
terraform console
> var.instance_type
> aws_instance.web.id
```

**Common Debug Patterns:**

```hcl
# Add debug output
output "debug_instance_details" {
  value = {
    id              = aws_instance.web.id
    public_ip       = aws_instance.web.public_ip
    security_groups = aws_instance.web.security_groups
  }
}

# Conditional debugging
output "debug_info" {
  value = var.debug_mode ? aws_instance.web : null
}
```

---

### Category: Real-World Scenarios

#### Q35: You have 1000 resources managed by Terraform. A developer accidentally ran `terraform destroy` on production. What do you do?

**Answer:**

**Immediate Actions (0-5 minutes):**

```bash
# 1. Stop the destroy if it's still running
# Press Ctrl+C (if applied hasn't finished)

# 2. Check state file status
aws s3 ls s3://terraform-state/prod/

# 3. Verify versioning was enabled
aws s3api get-bucket-versioning --bucket terraform-state

# 4. Alert the team
# (while taking next steps)
```

**Recovery Actions (5-30 minutes):**

```bash
# 5. Restore state from backup
aws s3api list-object-versions \
  --bucket terraform-state \
  --prefix prod/terraform.tfstate | head -20

# 6. Get previous version ID
export VERSION_ID="abc123def456"

# 7. Restore to local
aws s3api get-object \
  --bucket terraform-state \
  --key prod/terraform.tfstate \
  --version-id $VERSION_ID \
  terraform.tfstate.backup

# 8. Backup current state
mv terraform.tfstate terraform.tfstate.destroyed
mv terraform.tfstate.backup terraform.tfstate

# 9. Verify restored state
terraform state list | wc -l
# Should show ~1000 resources
```

**Replication Actions (30-60 minutes):**

```bash
# 10. Plan to recreate
terraform plan

# 11. This will show all 1000 resources need creation
# 12. Apply in phases (avoid hitting API limits)
terraform apply -parallelism=5

# 13. Monitor progress
# Watch CloudWatch for resource creation
```

**Prevention for Future:**

```hcl
# Add prevent_destroy to critical resources
resource "aws_rds_cluster" "production" {
  # ... configuration
  
  lifecycle {
    prevent_destroy = true
  }
}

# Require confirmation for destructive operations
# Use Terraform Cloud with require_approval policy

# Enable state versioning
resource "aws_s3_bucket_versioning" "terraform_state" {
  bucket = aws_s3_bucket.terraform_state.id
  
  versioning_configuration {
    status = "Enabled"
  }
}
```

**Timeline:**
- 0-5 min: Assess damage
- 5-15 min: Restore state
- 15-45 min: Recreate resources
- 45-60 min: Verify and test
- Post-incident: Root cause analysis

---

#### Q36: How do you handle infrastructure that has both Terraform and manual changes?

**Answer:**

**Scenario:** Some resources managed by Terraform, others modified manually.

```bash
# 1. Detect drift
terraform refresh

# 2. Check what changed
terraform plan

# Plan will show discrepancies
```

**Solutions:**

```bash
# Option 1: Refresh and update Terraform code
terraform refresh
# Update configuration files to match reality
terraform plan  # Should show no changes

# Option 2: Let Terraform take over (dangerous)
# Ensure all manual resources are imported
terraform import aws_instance.manual i-1234567890abcdef0

# Option 3: Keep manual resources out of Terraform
# Document which resources are manual
# Use data sources to reference them

data "aws_instance" "manual_instance" {
  filter {
    name   = "tag:Name"
    values = ["manual-instance"]
  }
}

# Reference in other resources
resource "aws_security_group_rule" "allow_manual" {
  security_group_id       = aws_security_group.main.id
  source_security_group_id = data.aws_instance.manual_instance.security_groups[0]
  # ...
}
```

**Best Practice:**

```hcl
# Document external resources
# external.tf
data "aws_vpc" "production" {
  filter {
    name   = "tag:Name"
    values = ["production-vpc"]
  }
}

data "aws_security_group" "manual_sg" {
  name = "manual-security-group"
}

# reference these in your code
resource "aws_instance" "app" {
  vpc_id              = data.aws_vpc.production.id
  vpc_security_group_ids = [data.aws_security_group.manual_sg.id]
}
```

---

#### Q37: You need to change a provider from AWS to Azure for part of your infrastructure. How do you approach this?

**Answer:**

**Migration Strategy:**

```hcl
# Step 1: Add Azure provider
terraform {
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 4.0"
    }
    azurerm = {
      source  = "hashicorp/azurerm"
      version = "~> 3.0"
    }
  }
}

provider "aws" {
  region = "us-east-1"
}

provider "azurerm" {
  features {}
}

# Step 2: Create parallel infrastructure in Azure
# resources/
# ├── aws/
# │   ├── main.tf         # Keep existing AWS
# │   └── variables.tf
# └── azure/
#     ├── main.tf         # New Azure resources
#     └── variables.tf

# Step 3: Create both in parallel
resource "aws_instance" "app" {
  # ... AWS instance
}

resource "azurerm_virtual_machine" "app" {
  # ... Azure VM
}

# Step 4: Switch load balancer to route to both
resource "aws_lb_target_group" "hybrid" {
  # ... configuration
}

# Step 5: Once Azure is stable, remove AWS
# Option A: Gradually reduce capacity
# Option B: Use terraform state mv to transfer

# Step 6: Clean up AWS resources
# terraform destroy -target=aws_instance.app
```

**Using Modules for Multi-Cloud:**

```hcl
# modules/compute/
# ├── aws/
# │   ├── main.tf
# │   ├── variables.tf
# │   └── outputs.tf
# ├── azure/
# │   ├── main.tf
# │   ├── variables.tf
# │   └── outputs.tf
# └── variables.tf (shared interface)

module "compute" {
  count   = var.use_azure ? 0 : 1
  source  = "./modules/compute/aws"
  # ...
}

module "compute_azure" {
  count   = var.use_azure ? 1 : 0
  source  = "./modules/compute/azure"
  # ...
}
```

---

#### Q38: How do you manage costs when using Terraform?

**Answer:**

**Cost Management Strategies:**

```hcl
# 1. Use cost-effective instance types
variable "instance_type" {
  type    = string
  default = "t3.micro"  # Lower cost than t2
  
  validation {
    condition = can(regex("^t[23]\\.(micro|small|medium)$", var.instance_type))
    error_message = "Only use t2/t3 micro/small/medium"
  }
}

# 2. Implement resource scheduling
resource "aws_autoscaling_group" "app" {
  min_size         = var.environment == "production" ? 2 : 0
  desired_capacity = var.environment == "production" ? 3 : 0
  max_size         = var.environment == "production" ? 5 : 1
}

# 3. Use spot instances
resource "aws_launch_template" "app" {
  instance_type = "t3.medium"
  
  instance_market_options {
    market_type = "spot"
  }
}

# 4. Set up cost alerts
resource "aws_budgets_budget" "monthly" {
  name       = "monthly-budget"
  budget_type = "COST"
  
  limit_unit  = "USD"
  limit_value = "1000"
  
  time_period_start = "2024-01-01"
  time_period_type  = "MONTHLY"
  
  cost_filter {
    name   = "Service"
    values = ["Amazon Elastic Compute Cloud - Compute"]
  }
}

# 5. Destroy dev/test resources automatically
resource "null_resource" "daily_destroy_dev" {
  provisioner "local-exec" {
    # Runs at 10 PM to destroy dev environment
    command = "aws events put-rule --schedule-expression 'cron(0 22 * * ? *)'"
  }
}

# 6. Use Terraform for cost estimation
# terraform estimate <plan_file>
```

**Cost Monitoring:**

```bash
# Estimate costs before applying
terraform plan -out=tfplan
terraform estimate tfplan

# Or use third-party tools
infracost breakdown --path tfplan
infracost comment github --path tfplan  # Comment on PR
```

---

#### Q39: You're migrating a on-premises database to AWS RDS. How do you minimize downtime?

**Answer:**

**Migration Strategy:**

```hcl
# Phase 1: Create parallel RDS (preparation)
resource "aws_db_instance" "migration_target" {
  identifier              = "production-db-rds"
  engine                  = "postgres"
  engine_version          = "14.7"
  instance_class          = "db.r5.large"
  allocated_storage       = "1000"
  multi_az                = true
  
  # Read replica for DNS testing
  publicly_accessible = false
  
  tags = { Name = "migration-target" }
}

# Phase 2: Setup replication from on-prem to RDS
# Use AWS DMS (Database Migration Service)
resource "aws_dms_replication_instance" "main" {
  replication_instance_id   = "dms-migration"
  replication_instance_class = "dms.r5.xlarge"
  allocated_storage          = 200
  
  engine_version = "3.4.6"
  multi_az       = true
}

resource "aws_dms_endpoint" "source" {
  endpoint_type = "source"
  engine_name   = "postgres"
  server_name   = var.onprem_db_host
  port          = 5432
  database_name = "production"
  username      = var.onprem_db_user
  password      = var.onprem_db_password
}

resource "aws_dms_endpoint" "target" {
  endpoint_type = "target"
  engine_name   = "postgres"
  server_name   = aws_db_instance.migration_target.address
  port          = 5432
  database_name = "production"
  username      = var.rds_db_user
  password      = var.rds_db_password
}

resource "aws_dms_replication_task" "main" {
  replication_instance_arn    = aws_dms_replication_instance.main.arn
  replication_task_id         = "production-migration"
  migration_type              = "cdc"  # Change Data Capture
  source_endpoint_arn         = aws_dms_endpoint.source.arn
  target_endpoint_arn         = aws_dms_endpoint.target.arn
  table_mappings              = jsonencode({
    rules = [
      {
        rule_type   = "selection"
        rule_id     = "1"
        rule_name   = "include-all-tables"
        object_locator = {
          schema_name = "%"
          table_name  = "%"
        }
        rule_action = "include"
      }
    ]
  })
  
  start_replication_task = true
}

# Phase 3: Application connection changes
variable "database_endpoint" {
  type    = string
  default = var.use_rds ? aws_db_instance.migration_target.address : var.onprem_db_host
}

resource "aws_ssm_parameter" "db_endpoint" {
  name  = "/prod/database/endpoint"
  value = variable.database_endpoint
}

# Phase 4: Cutover (minimal downtime)
# 1. Stop writes to on-prem database
# 2. Wait for DMS to replicate remaining changes
# 3. Switch application DNS to RDS
# 4. Monitor for issues
# 5. Keep on-prem database as backup for 24 hours

# Phase 5: Cleanup
resource "null_resource" "cutover_validation" {
  provisioner "local-exec" {
    command = "echo 'Validate RDS has all data and application works correctly'"
  }
}
```

**Timeline:**
- Week 1-2: Create RDS, setup DMS, initial sync
- Week 3: Continuous replication, test failover
- Week 4: Cutover window (30 minutes), monitor
- Week 5: Decommission on-prem database

---

#### Q40: You manage infrastructure with Terraform but a developer pushed breaking changes. How do you prevent this?

**Answer:**

**Prevention Strategies:**

```hcl
# 1. Pre-commit hooks
# .git/hooks/pre-commit (executable)
#!/bin/bash
terraform fmt -check
terraform validate
tfsec .
# Exit 1 if any fail
```

```yaml
# 2. GitHub branch protection rules
# GitHub UI: Settings > Branches > Branch protection rules
# Require:
# - PR reviews
# - Status checks pass (CI/CD pipeline)
# - Dismiss stale reviews

# 3. Terraform validation in CI
# .github/workflows/terraform-validation.yml
name: Validate Terraform

on: [pull_request]

jobs:
  validate:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: hashicorp/setup-terraform@v2
      - run: terraform fmt -check -recursive
      - run: terraform validate
      - run: tfsec .
      - run: terraform plan -lock=false
```

```hcl
# 4. Code review checklist in Terraform
# README.md - Mandatory review checklist
# - No hardcoded passwords
# - No public access without justification
# - All variables documented
# - Backwards compatible
```

```hcl
# 5. Limit destructive operations
# Terraform Cloud Policy
# policy/prevent_destroy.sentinel
import "tfplan/v2" as tfplan

main = rule {
  all tfplan.resource_changes as rc {
    if rc.type is "aws_db_instance" {
      rc.change.actions[0] != "delete"
    } else {
      true
    }
  }
}
```

```hcl
# 6. Require approval for production
# Terraform Cloud - Require speculative plan review

# 7. Use modules to limit blast radius
# Don't let developers directly create resources
# Force use of company-approved modules

module "vpc" {
  source = "internal/vpc-module"
  # Limited and validated inputs
}
```

**Process Controls:**

```
1. Feature branch → PR
2. Automated validation (PR checks)
3. Manual review (2+ approvals)
4. Merge to main
5. CI/CD applies to staging
6. Manual approval for prod
7. CI/CD applies to production
```

---

## Conclusion

This comprehensive guide covers Terraform from fundamentals to production scenarios. Key takeaways:

**Fundamentals:**
- IaC benefits and declarative approach
- Plan-apply workflow
- State management is critical

**Advanced Topics:**
- Multi-environment architecture
- Modules and reusability
- Security and sensitive data
- CI/CD integration
- Testing strategies

**Real-World Skills:**
- Troubleshooting common errors
- Handling migrations
- Cost management
- Team collaboration
- Disaster recovery

**Interview Success:**
- Understand concepts deeply
- Provide practical examples
- Discuss trade-offs
- Emphasize best practices
- Share real experiences

Practice these concepts in lab environments and you'll be ready for any Terraform interview!



Terraform enables infrastructure automation and consistency across cloud platforms. Master these concepts:
- **Declarative Infrastructure**: Define desired state
- **State Management**: Central source of truth
- **Modularity**: Reusable, composable components
- **Best Practices**: Version control, remote state, naming standards
- **Testing**: Plan before apply

Key Commands:
- `terraform init`: Initialize working directory
- `terraform plan`: Preview changes
- `terraform apply`: Apply changes
- `terraform destroy`: Destroy infrastructure
- `terraform fmt`: Format code
- `terraform validate`: Validate syntax

