# Python Complete Notes

## Table of Contents
1. [Fundamentals](#fundamentals)
2. [Data Types](#data-types)
3. [Operators](#operators)
4. [Control Structures](#control-structures)
5. [Functions](#functions)
6. [Object-Oriented Programming](#object-oriented-programming)
7. [Modules and Packages](#modules-and-packages)
8. [File Operations](#file-operations)
9. [Exception Handling](#exception-handling)
10. [Advanced Concepts](#advanced-concepts)
11. [Best Practices](#best-practices)

---

## Fundamentals

### What is Python?

**Theory**: Python is a high-level, interpreted, dynamically-typed programming language designed for readability and simplicity. It follows the philosophy that code should be readable and explicit (The Zen of Python).

### Why Python?
- **Readability**: Clean, readable syntax
- **Versatility**: Web, data science, automation, AI/ML, automation, scripting
- **Large Ecosystem**: Extensive standard library and third-party packages
- **Community**: Large active community with abundant resources
- **Rapid Development**: Quick to write and test code

### Running Python

```bash
# Interactive interpreter
python3

# Run script
python3 script.py

# Run with arguments
python3 script.py arg1 arg2

# One-liner
python3 -c "print('Hello, World!')"

# Execute module
python3 -m module_name
```

### Python Philosophy - The Zen of Python

```python
import this  # Displays Python design philosophy
```

Key principles:
- Readability counts
- Explicit is better than implicit
- Simple is better than complex
- Beautiful is better than ugly

### Comments

```python
# Single-line comment

# Multi-line comments
# Line 1
# Line 2

"""
Multi-line string (docstring)
Often used for documentation
"""

def function():
    """This is a docstring"""
    pass
```

---

## Data Types

### Numeric Types

**Detailed Theory**: 
Python's numeric types follow these principles:

1. **Integers** - Arbitrary precision (can be as large as memory allows)
2. **Floats** - IEEE 754 double precision (limited to ~15-17 decimal digits)
3. **Complex** - Pairs of floats (real + imaginary)

Critical behaviors:

```python
# Integer division vs float division
print(10 / 3)              # 3.3333... (float division)
print(10 // 3)             # 3 (floor division - rounds down)
print(-10 // 3)            # -4 (floor division rounds toward -∞)
print(int(10 / 3))         # 3 (truncates toward zero)

# Float precision issues (IEEE 754)
print(0.1 + 0.2)           # 0.30000000000000004 (not 0.3!)
print(0.1 + 0.2 == 0.3)    # False!

# Use Decimal for precise decimal arithmetic
from decimal import Decimal
print(Decimal('0.1') + Decimal('0.2'))  # 0.3 (exact)

# Comparing floats with tolerance
import math
a = 0.1 + 0.2
b = 0.3
print(math.isclose(a, b))   # True (compares with tolerance)

# Type coercion rules
print(5 + 2.0)             # 7.0 (int + float → float)
print(5 + complex(1, 2))   # (6+2j) (int + complex → complex)
```

**Keypoints:**
- Integers have unlimited precision
- Floats have precision issues (IEEE 754 standard)
- Use `//` for floor division, `/` for true division
- Use `Decimal` for exact decimal arithmetic
- Use `math.isclose()` to compare floats
- Type promotion: int → float → complex
- `divmod(a, b)` returns (quotient, remainder)

### Strings

**Theory**: Strings are immutable sequences of Unicode characters. They support extensive manipulation operations.

```python
# String creation
STR1 = "Double quotes"
STR2 = 'Single quotes'
STR3 = '''Multi-line
string'''

# Raw strings (backslashes not escaped)
RAW_STR = r"C:\new\file"

# String escape sequences
ESCAPED = "Line1\nLine2"     # \n: newline
ESCAPED = "Tab\there"       # \t: tab
ESCAPED = "Quote: \"text\"" # \": quote
ESCAPED = "Backslash: \\"   # \\: backslash

# String length
print(len("Hello"))          # 5

# Indexing and slicing
TEXT = "Python"
print(TEXT[0])               # P
print(TEXT[-1])              # n (last character)
print(TEXT[1:4])             # yth (from index 1 to 3)
print(TEXT[:3])              # Pyt (first 3)
print(TEXT[3:])              # hon (from index 3 onwards)
print(TEXT[::2])             # Pto (every 2nd character)
print(TEXT[::-1])            # nohtyP (reversed)

# String methods
print("hello".upper())       # HELLO
print("HELLO".lower())       # hello
print("hello".title())       # Hello
print("hello world".capitalize())  # Hello world
print("  hello  ".strip())   # hello (remove leading/trailing)
print("hello".replace("l", "L"))   # heLLo
print("a,b,c".split(","))   # ['a', 'b', 'c']
print(" ".join(['a', 'b', 'c']))  # a b c
print("hello".find("l"))     # 2
print("hello".count("l"))    # 2
print("hello".startswith("he"))    # True
print("hello".endswith("lo"))      # True

# String formatting
NAME = "Alice"
AGE = 30
SALARY = 50000.50

# f-strings (Recommended)
print(f"{NAME} is {AGE} years old")
print(f"Salary: ${SALARY:.2f}")
print(f"Name: {NAME:>10}")    # Right-align

# .format() method
print("{} is {} years old".format(NAME, AGE))
print("{0} is {1}".format(NAME, AGE))
print("{name} is {age}".format(name=NAME, age=AGE))

# % formatting (older)
print("%s is %d years old" % (NAME, AGE))
print("Price: $%.2f" % 19.99)

# String operations
print("Hello" + " " + "World")      # Concatenation
print("Ha" * 3)                     # Repetition: HaHaHa
print("H" in "Hello")               # True (membership)
```

### Lists

**Detailed Theory**: 
Lists are Python's primary sequence type. Understanding their implementation is crucial:

1. **Dynamic Arrays** - Allocate extra space for efficiency
2. **Reference Containers** - Store references to objects, not objects themselves
3. **Mutable** - Can change size and content after creation

```python
# Memory management in lists
import sys

lst = []
print(sys.getsizeof(lst))        # Small initial size

lst = list(range(1000))
print(sys.getsizeof(lst))        # Much larger

# Python allocates more space than needed for efficiency
# When capacity exceeded, size grows (roughly by 1.125x)

# Reference storage, not value storage
a = [1, 2, 3]
b = [1, 2, 3]
print(a is b)                    # False - different lists
print(a == b)                    # True - same content

# Nested references
inner = [1, 2]
outer = [inner, inner]           # Same list referenced twice
outer[0].append(3)
print(outer)                     # [[1, 2, 3], [1, 2, 3]]

# Common pitfall: aliasing
original = [1, 2, 3]
copy = original                  # NOT a copy - same object!
copy.append(4)
print(original)                  # [1, 2, 3, 4] - modified!
```

**Slicing - Advanced:**
```python
TEXT = "Python"
print(TEXT[1:4])             # yth (indices 1, 2, 3)
print(TEXT[:3])              # Pyt (from start)
print(TEXT[3:])              # hon (to end)
print(TEXT[::2])             # Pto (every 2nd)
print(TEXT[::-1])            # nohtyP (reversed)
print(TEXT[-3:])             # hon (last 3)

# Slicing creates new objects (important!)
ORIGINAL = [1, 2, 3, 4, 5]
SLICE = ORIGINAL[1:4]        # New list: [2, 3, 4]
SLICE.append(99)
print(ORIGINAL)              # [1, 2, 3, 4, 5] - unchanged

# Slice assignment (advanced)
lst = [1, 2, 3, 4, 5]
lst[1:3] = [20, 30]          # Replace indices 1, 2
print(lst)                   # [1, 20, 30, 4, 5]

lst[1:4] = [200]             # Replace 3 items with 1
print(lst)                   # [1, 200, 5]
```

**List Comprehension - Advanced:**
```python
# Basic list comprehension
SQUARES = [x**2 for x in range(10)]

# With filtering
EVENS = [x for x in range(10) if x % 2 == 0]

# Nested loops (outer loop outer, inner loop inner)
PAIRS = [(x, y) for x in range(3) for y in range(3)]
# [(0,0), (0,1), (0,2), (1,0), ..., (2,2)]

# Matrix flattening
MATRIX = [[1, 2, 3], [4, 5, 6]]
FLAT = [item for row in MATRIX for item in row]
# [1, 2, 3, 4, 5, 6]

# Comprehension vs loop - comprehension is faster
# [x**2 for x in range(1000)] is ~2x faster than loop
```

**Keypoints:**
- Lists are mutable, ordered sequences
- Elements are stored as references (can be any type)
- Slicing creates new list, doesn't modify original
- List comprehensions are faster than loops
- Negative indices count from end (-1 is last item)
- Assignment creates reference, not copy
- Use `.copy()` or slicing for shallow copies
- Append is O(1) amortized, insert is O(n)

### Tuples

**Theory**: Tuples are immutable, ordered collections. Once created, they cannot be modified.

```python
# Tuple creation
EMPTY_TUPLE = ()
TUPLE1 = (1, 2, 3, 4, 5)
TUPLE2 = (1, "two", 3.0)
SINGLE = (1,)                # Single element (comma required)
TUPLE3 = 1, 2, 3             # Parentheses optional

# Tuple indexing
print(TUPLE1[0])             # 1
print(TUPLE1[-1])            # 5

# Tuple operations (cannot modify)
print(len(TUPLE1))           # 5
print(2 in TUPLE1)           # True
print(TUPLE1 + (6, 7))       # (1,2,3,4,5,6,7)
print(TUPLE1 * 2)            # (1,2,3,4,5,1,2,3,4,5)

# Tuple unpacking
A, B, C = (1, 2, 3)
print(A, B, C)               # 1 2 3

# Swapping with tuples
X, Y = 10, 20
X, Y = Y, X                  # X=20, Y=10
```

### Dictionaries

**Theory**: Dictionaries are mutable, unordered collections of key-value pairs. Keys must be hashable.

```python
# Dictionary creation
EMPTY_DICT = {}
DICT1 = {"name": "Alice", "age": 30, "job": "Engineer"}
DICT2 = dict(name="Bob", age=25)

# Dictionary access
print(DICT1["name"])         # Alice
print(DICT1.get("age"))      # 30
print(DICT1.get("unknown", "N/A"))  # N/A (default)

# Dictionary modification
DICT1["salary"] = 50000      # Add/update key
DICT1["age"] = 31            # Update value
DICT1.pop("job")             # Remove key
DICT1.clear()                # Empty dictionary

# Dictionary operations
print(len(DICT1))            # Number of key-value pairs
print("name" in DICT1)       # True (check keys)
print(list(DICT1.keys()))    # ['name', 'age', 'job']
print(list(DICT1.values()))  # ['Alice', 30, 'Engineer']
print(list(DICT1.items()))   # [('name', 'Alice'), ...]

# Dictionary iteration
for KEY in DICT1:
    print(KEY, DICT1[KEY])

for KEY, VALUE in DICT1.items():
    print(KEY, VALUE)

# Dictionary comprehension
SQUARES = {x: x**2 for x in range(5)}  # {0:0, 1:1, 2:4, 3:9, 4:16}
```

### Sets

**Theory**: Sets are mutable, unordered collections of unique elements. Useful for membership testing and removing duplicates.

```python
# Set creation
EMPTY_SET = set()
SET1 = {1, 2, 3, 4, 5}
SET2 = {3, 4, 5, 6, 7}
SET3 = set([1, 2, 2, 3])     # {1, 2, 3}

# Set operations
print(len(SET1))             # 5
print(2 in SET1)             # True
SET1.add(6)                  # Add element
SET1.remove(3)               # Remove (error if not present)
SET1.discard(10)             # Remove (no error if not present)

# Set operations
UNION = SET1 | SET2          # {1,2,3,4,5,6,7}
INTERSECTION = SET1 & SET2   # {3,4,5}
DIFFERENCE = SET1 - SET2     # {1,2}
SYM_DIFF = SET1 ^ SET2       # {1,2,6,7}

# Set methods
print(SET1.union(SET2))
print(SET1.intersection(SET2))
print(SET1.difference(SET2))

# Set comprehension
EVENS = {x for x in range(10) if x % 2 == 0}  # {0,2,4,6,8}
```

### Boolean and None

```python
# Boolean
BOOL_TRUE = True
BOOL_FALSE = False

# None (null/undefined)
VALUE = None

# Truthiness
print(bool(1))               # True
print(bool(0))               # False
print(bool("text"))          # True
print(bool(""))              # False
print(bool([1, 2]))          # True
print(bool([]))              # False
```

---

## Operators

### Arithmetic Operators

```python
A = 10
B = 3

print(A + B)                 # 13 (addition)
print(A - B)                 # 7 (subtraction)
print(A * B)                 # 30 (multiplication)
print(A / B)                 # 3.333... (division)
print(A // B)                # 3 (integer division)
print(A % B)                 # 1 (modulo)
print(A ** B)                # 1000 (exponentiation)
```

### Comparison Operators

```python
A = 10
B = 20

print(A == B)                # False (equal)
print(A != B)                # True (not equal)
print(A < B)                 # True (less than)
print(A <= B)                # True (less or equal)
print(A > B)                 # False (greater than)
print(A >= B)                # False (greater or equal)

# Chaining comparisons
print(5 < 10 < 15)           # True
print(10 < 10 <= 10)         # False
```

### Logical Operators

**Detailed Theory**: 
Logical operators in Python have unique behavior compared to many languages. They don't return boolean; they return **the actual value** of one of the operands. This is called **short-circuit evaluation**.

**Critical Behaviors:**

```python
# and operator - returns first falsy value or last value if all truthy
print(5 and 10)                 # 10 (both truthy, returns last)
print(0 and 10)                 # 0 (first is falsy, returns it)
print(10 and 0)                 # 0 (last is falsy, returns it)
print(False and "never")        # False (short-circuits, doesn't evaluate "never")

# or operator - returns first truthy value or last value if all falsy
print(5 or 10)                  # 5 (first is truthy, returns it)
print(0 or 10)                  # 10 (first falsy, tries next)
print(0 or False)               # False (all falsy, returns last)
print("value" or "never")       # "value" (first is truthy)

# not operator - DOES return boolean
print(not True)                 # False
print(not 5)                    # False (5 is truthy)
print(not 0)                    # True (0 is falsy)
```

**Practical Applications:**

```python
# Default values using or
USER_INPUT = input()
USERNAME = USER_INPUT or "Guest"   # If empty string (falsy), use "Guest"

CONFIG = None
SETTING = CONFIG or get_default()  # If None (falsy), call function

# Short-circuit protection
VALUE = None
if VALUE and VALUE.upper():        # Won't crash - short-circuits
    print(VALUE.upper())
# If we didn't short-circuit: AttributeError: 'NoneType' has no attribute 'upper'

# Avoiding expensive operations
CACHE = {}
result = CACHE.get('key') or expensive_computation()  # Only calls if cache miss

# Ternary with logical operators
MAX_VAL = 100
value = 50
result = value if value < MAX_VAL else MAX_VAL  # Using ternary (preferred)
result = (value < MAX_VAL and value) or MAX_VAL # Using logical (less clear)

# Chaining conditions
if 5 < 10 < 15 < 20:            # All evaluated left to right
    print("All true")

if 5 < 10 and 10 < 15 and 15 < 20:  # Explicit, same result
    print("All true")
```

**Truthiness Rules:**

```python
# Falsy values (evaluate to False in boolean context)
print(bool(0))                  # False
print(bool(0.0))                # False
print(bool(""))                 # False
print(bool([]))                 # False
print(bool({}))                 # False
print(bool(None))               # False
print(bool(set()))              # False
print(bool(False))              # False

# Everything else is truthy
print(bool(1))                  # True
print(bool(-1))                 # True
print(bool(0.001))              # True
print(bool("text"))             # True
print(bool([1]))                # True
```

**Keypoints:**
- `and` returns first falsy value or last value
- `or` returns first truthy value or last value
- `not` always returns boolean (True or False)
- Short-circuit evaluation: second operand may not evaluate
- Exploit short-circuiting for efficiency (avoid expensive ops)
- Use truthiness for implicit boolean checks
- Falsy: None, False, 0, 0.0, "", [], {}, set()
- Prefer explicit comparisons over truthiness for clarity
- and/or return values, not booleans (usually works anyway)

### Membership Operators

```python
LIST = [1, 2, 3, 4, 5]
STR = "hello"

print(2 in LIST)             # True
print(10 not in LIST)        # True
print("h" in STR)            # True
print("x" not in STR)        # True
```

### Identity Operators

```python
A = [1, 2, 3]
B = [1, 2, 3]
C = A

print(A == B)                # True (same content)
print(A is B)                # False (different objects)
print(A is C)                # True (same object)
print(A is not B)            # True
```

### Bitwise Operators

```python
A = 6      # 0110
B = 3      # 0011

print(A & B)                 # 2 (AND: 0010)
print(A | B)                 # 7 (OR: 0111)
print(A ^ B)                 # 5 (XOR: 0101)
print(~A)                    # -7 (NOT)
print(A << 1)                # 12 (Left shift)
print(A >> 1)                # 3 (Right shift)
```

---

## Control Structures

### If-Elif-Else

**Theory**: Conditional execution allows branching based on conditions.

```python
# Basic if
AGE = 25
if AGE >= 18:
    print("Adult")

# If-else
if AGE >= 18:
    print("Adult")
else:
    print("Minor")

# If-elif-else
SCORE = 85
if SCORE >= 90:
    print("A")
elif SCORE >= 80:
    print("B")
elif SCORE >= 70:
    print("C")
else:
    print("F")

# Ternary operator
STATUS = "Adult" if AGE >= 18 else "Minor"

# One-liner with and/or
AGE >= 18 and print("Adult")  # Prints if True
AGE < 18 or print("Adult")    # Prints if False
```

### For Loops

**Detailed Theory**: 
Python's for loop is fundamentally an **iterator pattern** implementation. Unlike traditional C-style loops, Python for loops work with any iterable object (sequences, iterators, generators).

**How Python For Loops Work:**
```
for VARIABLE in ITERABLE:
    # Automatically calls iter() on ITERABLE
    # Repeatedly calls next() until StopIteration
    # Assigns each value to VARIABLE
```

```python
# Under the hood, this:
for ITEM in [1, 2, 3]:
    print(ITEM)

# Is equivalent to:
ITERATOR = iter([1, 2, 3])
try:
    while True:
        ITEM = next(ITERATOR)
        print(ITEM)
except StopIteration:
    pass

# Practical - works with any iterable
for ITEM in [1, 2, 3, 4, 5]:
    print(ITEM)

for CHAR in "Hello":
    print(CHAR)

for NUM in range(5):
    print(NUM)

for VALUE in {1, 2, 3}:          # Sets are iterable
    print(VALUE)

# range() creates a generator-like object (not a list)
for I in range(1, 6):            # 1, 2, 3, 4, 5
    print(I)

for I in range(0, 10, 2):        # 0, 2, 4, 6, 8 (step parameter)
    print(I)

# enumerate() provides index and value
for INDEX, ITEM in enumerate(["a", "b", "c"]):
    print(f"{INDEX}: {ITEM}")    # 0: a, 1: b, 2: c

# zip() combines iterables
NAMES = ["Alice", "Bob", "Charlie"]
AGES = [30, 25, 35]
for NAME, AGE in zip(NAMES, AGES):
    print(f"{NAME}: {AGE}")      # Stops at shortest iterable

# Dictionary iteration
PERSON = {"name": "Alice", "age": 30, "job": "Engineer"}
for KEY in PERSON:              # Iterates over keys
    print(KEY, PERSON[KEY])

for KEY, VALUE in PERSON.items():  # Iterate key-value pairs
    print(KEY, VALUE)

for VALUE in PERSON.values():      # Iterate values only
    print(VALUE)

# Loop with else (executes ONLY if no break)
for I in range(5):
    if I == 10:
        break
else:
    print("Loop completed without break")  # This runs

for I in range(5):
    if I == 3:
        break
else:
    print("Never runs - loop broke")      # This doesn't run

# Nested loops
for I in range(3):
    for J in range(3):
        print(f"({I}, {J})", end=" ")
        # Output: (0, 0) (0, 1) (0, 2) (1, 0) ...

# Break and continue
for I in range(10):
    if I == 3:
        continue             # Skip this iteration
    if I == 7:
        break                # Exit loop
    print(I)                 # 0, 1, 2, 4, 5, 6
```

**Why Python For Loops Are Powerful:**
- Work with **any iterable** (not just sequences)
- Generator functions can produce infinite sequences
- Memory efficient (iterators generate on-the-fly)
- Pythonic and readable

**Keypoints:**
- For loops use iterator protocol (iter(), next())
- Works with any iterable (lists, strings, dicts, generators, ranges)
- `enumerate()` provides index along with value
- `zip()` combines multiple iterables
- `for...else` else executes only if no break occurred
- Loop variable exists after loop (don't rely on it)
- Break exits immediately; continue skips to next iteration
- Nested loops work naturally but can be slow
    print("Loop completed")

# Continue and break
for I in range(10):
    if I == 3:
        continue             # Skip this iteration
    if I == 7:
        break                # Exit loop
    print(I)                 # 0,1,2,4,5,6
```

### While Loops

```python
# Basic while
COUNT = 0
while COUNT < 5:
    print(COUNT)
    COUNT += 1

# While with else
COUNT = 0
while COUNT < 5:
    COUNT += 1
    if COUNT == 10:
        break
else:
    print("Completed")

# Infinite loop with break
while True:
    USER_INPUT = input("Enter 'quit' to exit: ")
    if USER_INPUT == "quit":
        break
    print(f"You entered: {USER_INPUT}")
```

---

## Functions

### Function Definition and Calling

**Detailed Theory**: 
Functions in Python are first-class objects. Understanding function mechanics is crucial for writing pythonic code.

**Function Call Mechanics:**
1. **Definition** - Creates function object in memory
2. **Call** - Executes function, creates new scope
3. **Return** - Exits function, returns value (or None)

```python
# Functions are objects
def greet():
    """Docstring for the function."""
    return "Hello"

# Function object properties
print(type(greet))              # <class 'function'>
print(greet.__name__)           # 'greet'
print(greet.__doc__)            # Docstring
print(callable(greet))          # True

# Can assign to variables
say_hi = greet
print(say_hi())                 # "Hello"

# Can pass as arguments
def execute(func):
    return func()

print(execute(greet))           # "Hello"

# Argument passing - Pass by Object Reference
# Immutable objects appear "pass by value"
def modify_int(num):
    num = num + 1               # Creates new local int
    return num

x = 5
modify_int(x)                   # Doesn't affect x
print(x)                        # 5

# Mutable objects can be modified by function
def modify_list(items):
    items.append(99)            # Modifies the list object

my_list = [1, 2, 3]
modify_list(my_list)
print(my_list)                  # [1, 2, 3, 99]

# Reassigning parameter doesn't affect caller
def reassign(items):
    items = [99, 99, 99]        # Local assignment only

my_list = [1, 2, 3]
reassign(my_list)
print(my_list)                  # [1, 2, 3] unchanged
```

**Return Values:**
```python
# Implicit return (returns None)
def no_return():
    pass

print(no_return())              # None

# Early return
def find_number(lst, target):
    for item in lst:
        if item == target:
            return True         # Exit function early
    return False

# Multiple return values (returns tuple)
def get_coordinates():
    return 10, 20               # Tuple (10, 20)

x, y = get_coordinates()        # Unpacking
print(x, y)                     # 10 20
```

**Keypoints:**
- Functions are objects (first-class citizens)
- Arguments passed by object reference (mutable/immutable distinction)
- Default parameters evaluated at definition time (danger with mutables!)
- Return value defaults to None if not specified
- Multiple return values use tuple packing/unpacking
- Function scope is created fresh on each call
- Global/nonlocal keywords modify scope resolution

### Default Arguments

```python
# Default arguments
def greet(NAME, GREETING="Hello"):
    print(f"{GREETING}, {NAME}!")

greet("Alice")               # Hello, Alice!
greet("Bob", "Hi")           # Hi, Bob!

# Mutable defaults (avoid!)
def append_to_list(ITEM, LIST=[]):  # Don't do this!
    LIST.append(ITEM)
    return LIST

# Instead, use None
def append_to_list(ITEM, LIST=None):
    if LIST is None:
        LIST = []
    LIST.append(ITEM)
    return LIST
```

### Variable-Length Arguments

```python
# *args - variable positional arguments (as tuple)
def print_args(*ARGS):
    for ARG in ARGS:
        print(ARG)

print_args(1, 2, 3)          # Prints: 1, 2, 3

# **kwargs - variable keyword arguments (as dict)
def print_kwargs(**KWARGS):
    for KEY, VALUE in KWARGS.items():
        print(f"{KEY}: {VALUE}")

print_kwargs(name="Alice", age=30)  # name: Alice, age: 30

# Combining all
def func(A, B, *ARGS, **KWARGS):
    print(f"A: {A}, B: {B}")
    print(f"Args: {ARGS}")
    print(f"Kwargs: {KWARGS}")

func(1, 2, 3, 4, x=10, y=20)
```

### Lambda Functions

**Theory**: Lambda functions are anonymous, one-line functions for simple operations.

```python
# Lambda definition
ADD = lambda X, Y: X + Y
print(ADD(5, 3))             # 8

# Lambda with default argument
GREET = lambda NAME="Guest": f"Hello, {NAME}"
print(GREET())               # Hello, Guest

# Lambda in function calls
NUMBERS = [1, 2, 3, 4, 5]
SQUARED = list(map(lambda X: X**2, NUMBERS))  # [1, 4, 9, 16, 25]

EVENS = list(filter(lambda X: X % 2 == 0, NUMBERS))  # [2, 4]

# Lambda with sorted
STUDENTS = [("Alice", 85), ("Bob", 75), ("Charlie", 90)]
SORTED_BY_SCORE = sorted(STUDENTS, key=lambda S: S[1])
```

### Decorators

**Theory**: Decorators are functions that modify other functions without changing their source code.

```python
# Simple decorator
def my_decorator(FUNC):
    def WRAPPER():
        print("Before function call")
        FUNC()
        print("After function call")
    return WRAPPER

@my_decorator
def say_hello():
    print("Hello!")

say_hello()
# Output:
# Before function call
# Hello!
# After function call

# Decorator with arguments
def repeat(TIMES):
    def DECORATOR(FUNC):
        def WRAPPER(*ARGS, **KWARGS):
            for _ in range(TIMES):
                FUNC(*ARGS, **KWARGS)
        return WRAPPER
    return DECORATOR

@repeat(3)
def greet(NAME):
    print(f"Hello, {NAME}!")

greet("Alice")               # Prints 3 times

# Using functools.wraps
from functools import wraps

def my_decorator(FUNC):
    @wraps(FUNC)
    def WRAPPER(*ARGS, **KWARGS):
        print("Before")
        return FUNC(*ARGS, **KWARGS)
    return WRAPPER
```

---

## Object-Oriented Programming

### Classes and Objects

**Detailed Theory**:
Classes are blueprints; objects are instances. The relationship between class attributes and instance attributes is crucial to understand:

```python
# Class structure
class Person:
    # Class attribute (shared by all instances)
    SPECIES = "Homo sapiens"
    instance_count = 0
    
    # Constructor - called when instance created
    def __init__(self, NAME, AGE):
        # Instance attributes (unique to each instance)
        self.name = NAME
        self.age = AGE
        
        # Modify class attribute
        Person.instance_count += 1
    
    # Instance method (receives self)
    def introduce(self):
        return f"Hello, I'm {self.name}, {self.age} years old"
    
    # Class method (receives cls, not self)
    @classmethod
    def from_birth_year(cls, name, birth_year):
        age = 2024 - birth_year
        return cls(name, age)
    
    # Static method (no self or cls)
    @staticmethod
    def is_adult_age(age):
        return age >= 18
    
    # String representation
    def __str__(self):
        return f"Person(name={self.name}, age={self.age})"
    
    def __repr__(self):
        return f"Person({self.name!r}, {self.age!r})"

# Creating and using objects
p1 = Person("Alice", 30)
p2 = Person("Bob", 25)

# Instance attributes are separate
p1.name = "Alice Smith"
print(p2.name)              # "Bob" (unchanged)

# Class attributes are shared
print(Person.SPECIES)       # "Homo sapiens"
print(Person.instance_count) # 2

# Class method constructor
p3 = Person.from_birth_year("Charlie", 2000)

# Static method
print(Person.is_adult_age(20)) # True
print(p1.is_adult_age(20))     # True (callable on instance too)
```

**Attribute Resolution (CRUCIAL):**
```python
class Test:
    CLASS_VAR = "class"
    
    def __init__(self):
        self.INSTANCE_VAR = "instance"

obj = Test()

# Looking up attribute: first check instance, then class
print(obj.INSTANCE_VAR)     # "instance" (from instance __dict__)
print(obj.CLASS_VAR)        # "class" (from class, not found in instance)

# Modifying class attribute
Test.CLASS_VAR = "modified"
print(obj.CLASS_VAR)        # "modified" (instance doesn't have it)

# Creating instance attribute shadows class attribute
obj.CLASS_VAR = "instance shadowing"
print(obj.CLASS_VAR)        # "instance shadowing"
print(Test.CLASS_VAR)       # "modified" (class unchanged)
```

**Special Methods (Dunder Methods):**
```python
class Vector:
    def __init__(self, x, y):
        self.x = x
        self.y = y
    
    # String representation
    def __str__(self):
        return f"Vector({self.x}, {self.y})"
    
    def __repr__(self):
        return f"Vector({self.x}, {self.y})"
    
    # Operator overloading
    def __add__(self, other):
        return Vector(self.x + other.x, self.y + other.y)
    
    def __sub__(self, other):
        return Vector(self.x - other.x, self.y - other.y)
    
    def __len__(self):
        return int((self.x**2 + self.y**2)**0.5)
    
    def __eq__(self, other):
        return self.x == other.x and self.y == other.y
    
    def __lt__(self, other):
        return len(self) < len(other)

v1 = Vector(3, 4)
v2 = Vector(1, 2)
print(v1 + v2)              # Vector(4, 6)
print(v1 == v2)             # False
print(len(v1))              # 5
```

**Keypoints:**
- Classes create blueprint; objects are instances
- Class attributes are shared; instance attributes are unique
- `__init__` is constructor (initializes instance)
- Instance methods receive `self` (the instance)
- Class methods receive `cls` (the class)
- Static methods receive neither
- Attribute lookup: instance → class → parent classes
- Dunder methods enable operator overloading
- `__str__` for user-friendly, `__repr__` for debugging

### Inheritance

**Detailed Theory**:
Inheritance creates hierarchical relationships between classes. Python uses **Method Resolution Order (MRO)** to determine which method to call in complex hierarchies.

```python
# Single inheritance
class Animal:
    def __init__(self, NAME):
        self.name = NAME
    
    def speak(self):
        return f"{self.name} makes a sound"
    
    def sleep(self):
        return f"{self.name} is sleeping"

class Dog(Animal):
    # Override method
    def speak(self):
        return f"{self.name} barks"
    
    # New method (Dog-specific)
    def fetch(self):
        return f"{self.name} is fetching"
    
    # Call parent method with super()
    def sleep(self):
        parent_behavior = super().sleep()
        return f"{parent_behavior} with toys"

dog = Dog("Rex")
print(dog.speak())          # Rex barks (overridden)
print(dog.sleep())          # Rex is sleeping with toys (super call)
print(dog.fetch())          # Rex is fetching (new method)

# Multiple inheritance - MRO becomes important
class Mammal:
    def warm_blooded(self):
        return True

class Swimmer:
    def swim(self):
        return "Swimming"

class Dolphin(Mammal, Swimmer):
    pass

dolphin = Dolphin()
print(dolphin.warm_blooded())   # True
print(dolphin.swim())           # Swimming

# MRO determines method resolution order
print(Dolphin.__mro__)
# (<class 'Dolphin'>, <class 'Mammal'>, <class 'Swimmer'>, <class 'object'>)

# Diamond problem - resolved by MRO
class A:
    def method(self):
        return "A"

class B(A):
    def method(self):
        return "B"

class C(A):
    def method(self):
        return "C"

class D(B, C):
    pass

d = D()
print(d.method())           # "B" (follows MRO: D → B → C → A)
print(D.__mro__)            # Shows resolution order
```

**super() - Critical Understanding:**
```python
class Parent:
    def __init__(self, name):
        self.name = name

class Child(Parent):
    def __init__(self, name, age):
        super().__init__(name)      # Calls parent __init__
        self.age = age

# super() calls the NEXT class in MRO, not Parent
# This is crucial for multiple inheritance

class Mixin1:
    def process(self):
        print("Mixin1 processing")
        super().process()

class Mixin2:
    def process(self):
        print("Mixin2 processing")
        # Base class doesn't have process, so no super call

class Base:
    pass

class Combined(Mixin1, Mixin2, Base):
    def process(self):
        print("Combined processing")
        super().process()

c = Combined()
c.process()
# Output:
# Combined processing
# Mixin1 processing
# Mixin2 processing
```

**isinstance vs issubclass:**
```python
class Vehicle:
    pass

class Car(Vehicle):
    pass

car = Car()
vehicle = Vehicle()

# isinstance - checks if object is instance of class (or subclass)
print(isinstance(car, Car))        # True
print(isinstance(car, Vehicle))    # True (checks inheritance)

# issubclass - checks class hierarchy
print(issubclass(Car, Vehicle))    # True
print(issubclass(Vehicle, Car))    # False
```

**Keypoints:**
- Child class inherits all parent methods/attributes
- Override methods by redefining them in child
- Use `super()` to call parent methods
- MRO (Method Resolution Order) determines method lookup
- In multiple inheritance, MRO prevents calling methods twice
- `super()` calls NEXT class in MRO, not necessarily parent
- isinstance checks both exact type and inheritance
- issubclass checks class hierarchy relationships

### Encapsulation

**Theory**: Encapsulation hides internal implementation details and controls access.

```python
class BankAccount:
    def __init__(self, BALANCE):
        self.__balance = BALANCE  # Private attribute (name mangling)
    
    def get_balance(self):
        return self.__balance
    
    def deposit(self, AMOUNT):
        if AMOUNT > 0:
            self.__balance += AMOUNT
            return True
        return False
    
    def withdraw(self, AMOUNT):
        if 0 < AMOUNT <= self.__balance:
            self.__balance -= AMOUNT
            return True
        return False

# Using encapsulation
ACCOUNT = BankAccount(1000)
print(ACCOUNT.get_balance())   # 1000
ACCOUNT.deposit(500)           # OK
print(ACCOUNT.get_balance())   # 1500
ACCOUNT.withdraw(200)          # OK

# Cannot directly access private attribute
# print(ACCOUNT.__balance)     # Error
```

### Properties

**Theory**: Properties provide getter/setter functionality while maintaining clean syntax.

```python
class Circle:
    def __init__(self, RADIUS):
        self._radius = RADIUS
    
    @property
    def radius(self):
        return self._radius
    
    @radius.setter
    def radius(self, VALUE):
        if VALUE > 0:
            self._radius = VALUE
        else:
            raise ValueError("Radius must be positive")
    
    @property
    def area(self):
        return 3.14159 * self._radius ** 2

# Using properties
CIRCLE = Circle(5)
print(CIRCLE.radius)           # 5
print(CIRCLE.area)             # 78.53975
CIRCLE.radius = 10             # Uses setter
print(CIRCLE.area)             # 314.159
```

### Static and Class Methods

```python
class MathUtils:
    PI = 3.14159
    
    @staticmethod
    def add(A, B):
        return A + B
    
    @classmethod
    def create_circle(cls, RADIUS):
        return f"Circle with radius {RADIUS}"

# Static method (no self or cls)
print(MathUtils.add(5, 3))     # 8

# Class method (receives class as first argument)
print(MathUtils.create_circle(10))  # Circle with radius 10
```

---

## Modules and Packages

### Importing Modules

**Theory**: Modules are Python files containing reusable code. Packages are directories with modules.

```python
# Import entire module
import math
print(math.pi)               # 3.14159
print(math.sqrt(16))         # 4.0

# Import specific items
from math import pi, sqrt
print(pi)
print(sqrt(16))

# Import with alias
import json as js
from math import sqrt as square_root

# Import all (avoid in production)
from math import *

# Import from custom module
import mymodule
from mymodule import my_function
from mymodule import MyClass

# Relative imports
from . import sibling_module  # Current package
from .. import parent_module  # Parent package
```

### Creating Modules and Packages

```bash
# Module structure
myproject/
    __init__.py
    utils/
        __init__.py
        helpers.py
        validators.py
    core/
        __init__.py
        engine.py
```

```python
# myproject/__init__.py
"""MyProject package"""

# myproject/utils/__init__.py
"""Utilities package"""

# myproject/utils/helpers.py
def helper_function():
    return "helper"

# Using the package
from myproject.utils.helpers import helper_function
```

### Standard Library Modules

```python
# os - Operating system interaction
import os
os.getcwd()                  # Current working directory
os.listdir('.')              # List files
os.path.join('a', 'b')       # Path joining

# sys - System functions
import sys
sys.exit(0)                  # Exit program
sys.argv                     # Command-line arguments

# datetime - Date and time
from datetime import datetime, timedelta
NOW = datetime.now()
TOMORROW = NOW + timedelta(days=1)

# re - Regular expressions
import re
PATTERN = r"\d{3}-\d{4}"
if re.match(PATTERN, "123-4567"):
    print("Match!")

# json - JSON handling
import json
DATA = {"name": "Alice", "age": 30}
JSON_STR = json.dumps(DATA)
PARSED = json.loads(JSON_STR)

# collections - Specialized data structures
from collections import Counter, defaultdict, namedtuple
COUNTS = Counter([1, 2, 2, 3, 3, 3])  # {3: 3, 2: 2, 1: 1}
```

---

## File Operations

### Reading Files

**Theory**: File I/O requires opening, reading/writing, and closing. Context managers handle this safely.

```python
# Basic file reading
with open('file.txt', 'r') as FILE:
    CONTENT = FILE.read()   # Read entire file
    
with open('file.txt', 'r') as FILE:
    LINES = FILE.readlines() # List of lines (with \n)
    
with open('file.txt', 'r') as FILE:
    for LINE in FILE:       # Iterate line by line
        print(LINE.strip()) # Remove \n

# Read specific lines
with open('file.txt', 'r') as FILE:
    FIRST_LINE = FILE.readline()
```

### Writing Files

```python
# Write to file (overwrites)
with open('output.txt', 'w') as FILE:
    FILE.write("Hello\n")
    FILE.write("World\n")

# Append to file
with open('output.txt', 'a') as FILE:
    FILE.write("Appended line\n")

# Write multiple lines
with open('output.txt', 'w') as FILE:
    LINES = ["Line 1\n", "Line 2\n", "Line 3\n"]
    FILE.writelines(LINES)
```

### Working with JSON

```python
import json

# Reading JSON
with open('data.json', 'r') as FILE:
    DATA = json.load(FILE)

# Writing JSON
DATA = {"name": "Alice", "age": 30}
with open('data.json', 'w') as FILE:
    json.dump(DATA, FILE, indent=2)

# JSON string operations
JSON_STR = '{"name": "Alice"}'
DICT = json.loads(JSON_STR)
JSON_STR = json.dumps(DICT)
```

### Working with CSV

```python
import csv

# Reading CSV
with open('data.csv', 'r') as FILE:
    READER = csv.reader(FILE)
    for ROW in READER:
        print(ROW)

# Reading CSV as dictionaries
with open('data.csv', 'r') as FILE:
    READER = csv.DictReader(FILE)
    for ROW in READER:
        print(ROW['name'], ROW['age'])

# Writing CSV
DATA = [
    ['name', 'age'],
    ['Alice', 30],
    ['Bob', 25]
]
with open('output.csv', 'w', newline='') as FILE:
    WRITER = csv.writer(FILE)
    WRITER.writerows(DATA)
```

---

## Exception Handling

### Try-Except-Finally

**Detailed Theory**:
Exception handling in Python follows a specific execution flow. Understanding when each block runs is critical:

**Execution Flow:**
```
try:
    code that might raise exception
except SpecificError:
    handle that specific error
except Exception:
    handle more general errors
else:
    runs ONLY if no exception in try block
finally:
    ALWAYS runs (cleanup code)
```

**Crucial Behaviors:**
```python
# 1. Exception propagation stops at first match
try:
    value = int("not a number")
except ValueError as e:
    print(f"Caught: {e}")       # Executes
except Exception as e:
    print("Generic handler")    # Does NOT execute

# 2. else block only if try succeeds
try:
    value = int("42")
except ValueError:
    print("Error")
else:
    print(f"Success: {value}")  # This runs (no exception)

# 3. finally ALWAYS runs
def test():
    try:
        return "from try"
    finally:
        print("finally runs")   # ALWAYS runs, even after return!

print(test())                   # Output: finally runs, then: from try

# 4. Exception in except/else/finally overrides
try:
    value = int("abc")
except ValueError:
    raise ValueError("New error")  # This exception propagates
finally:
    print("finally")            # Still runs before exception propagates

# 5. Accessing exception information
try:
    1 / 0
except ZeroDivisionError as e:
    print(f"Type: {type(e)}")    # Exception type
    print(f"Message: {str(e)}")  # Error message
    print(f"Args: {e.args}")     # Arguments tuple

# 6. Traceback information
import traceback
try:
    function_call()
except Exception:
    traceback.print_exc()       # Prints full traceback
    tb_string = traceback.format_exc()
```

**Exception Hierarchy:**
```
BaseException
├── SystemExit
├── KeyboardInterrupt
└── Exception
    ├── StopIteration
    ├── ArithmeticError
    │   └── ZeroDivisionError
    ├── ValueError
    ├── TypeError
    ├── AttributeError
    ├── KeyError
    ├── IndexError
    ├── NameError
    └── ... (40+ built-in exceptions)
```

```python
# Catching by hierarchy (specific to general)
try:
    code_here()
except ZeroDivisionError:       # Specific
    print("Divide by zero")
except ArithmeticError:         # More general
    print("Math error")
except Exception:               # Most general
    print("Any exception")
except BaseException:           # Catches SystemExit too (don't do this)
    print("Everything")

# Catching multiple exceptions in one handler
try:
    code()
except (ValueError, TypeError, KeyError) as e:
    print(f"Common handling: {e}")
```

**Keypoints:**
- Exceptions stop normal execution and jump to except block
- First matching except block executes; others skipped
- else block runs only if no exception
- finally block ALWAYS runs (for cleanup)
- Exception in finally overrides previous exceptions
- Use specific exceptions before general ones
- Access exception info with `as variable`
- Traceback shows full call stack
- `raise` can re-raise current exception
- Custom exceptions should inherit from Exception

### Custom Exceptions

```python
# Define custom exception
class InsufficientFundsError(Exception):
    pass

class InvalidAmountError(Exception):
    def __init__(self, MESSAGE):
        self.message = MESSAGE
        super().__init__(self.message)

# Using custom exceptions
def withdraw(BALANCE, AMOUNT):
    if AMOUNT <= 0:
        raise InvalidAmountError("Amount must be positive")
    if AMOUNT > BALANCE:
        raise InsufficientFundsError("Not enough funds")
    return BALANCE - AMOUNT

# Catching custom exceptions
try:
    withdraw(100, 150)
except InsufficientFundsError as E:
    print(f"Error: {E}")
except InvalidAmountError as E:
    print(f"Error: {E.message}")
```

### Raising Exceptions

```python
def validate_age(AGE):
    if not isinstance(AGE, int):
        raise TypeError("Age must be an integer")
    if AGE < 0:
        raise ValueError("Age cannot be negative")
    if AGE > 150:
        raise ValueError("Age is unrealistic")
    return True

try:
    validate_age(-5)
except (TypeError, ValueError) as E:
    print(f"Validation error: {E}")
```

---

## Advanced Concepts

### List Comprehensions

**Theory**: List comprehensions provide a concise way to create lists.

```python
# Basic list comprehension
SQUARES = [X**2 for X in range(10)]  # [0, 1, 4, 9, 16, ...]

# With condition
EVENS = [X for X in range(10) if X % 2 == 0]  # [0, 2, 4, 6, 8]

# Nested list comprehension
MATRIX = [[X+Y for X in range(3)] for Y in range(3)]

# With multiple conditions
NUMBERS = [X for X in range(20) if X % 2 == 0 if X % 3 == 0]  # [0, 6, 12, 18]

# String operations
WORDS = ["hello", "world", "python"]
UPPERCASE = [W.upper() for W in WORDS]  # ['HELLO', 'WORLD', 'PYTHON']

# Dictionary comprehension
SQUARES_DICT = {X: X**2 for X in range(5)}  # {0:0, 1:1, 2:4, 3:9, 4:16}

# Set comprehension
UNIQUE_LENGTHS = {len(W) for W in WORDS}  # {5}
```

### Generators

**Theory**: Generators produce values on-the-fly, saving memory for large datasets.

```python
# Generator function
def count_up_to(MAX):
    NUM = 0
    while NUM < MAX:
        yield NUM
    NUM += 1

# Using generator
for VALUE in count_up_to(5):
    print(VALUE)  # 0, 1, 2, 3, 4

# Generator expression
GEN = (X**2 for X in range(10))
print(next(GEN))  # 0
print(next(GEN))  # 1

# Practical example
def read_large_file(FILE_PATH):
    with open(FILE_PATH) as FILE:
        for LINE in FILE:
            yield LINE.strip()

# Memory efficient
for LINE in read_large_file('large_file.txt'):
    print(LINE)
```

### Decorators with Arguments

```python
# Decorator factory
def repeat(TIMES):
    def DECORATOR(FUNC):
        def WRAPPER(*ARGS, **KWARGS):
            RESULTS = []
            for _ in range(TIMES):
                RESULTS.append(FUNC(*ARGS, **KWARGS))
            return RESULTS
        return WRAPPER
    return DECORATOR

@repeat(3)
def greet(NAME):
    return f"Hello, {NAME}"

print(greet("Alice"))  # ['Hello, Alice', 'Hello, Alice', 'Hello, Alice']

# Timing decorator
import time
from functools import wraps

def timeit(FUNC):
    @wraps(FUNC)
    def WRAPPER(*ARGS, **KWARGS):
        START = time.time()
        RESULT = FUNC(*ARGS, **KWARGS)
        END = time.time()
        print(f"{FUNC.__name__} took {END - START:.4f} seconds")
        return RESULT
    return WRAPPER

@timeit
def slow_function():
    time.sleep(1)
    return "Done"

slow_function()
```

### Context Managers

**Theory**: Context managers handle resource setup and cleanup using `with` statements.

```python
# Using context managers
with open('file.txt') as FILE:
    CONTENT = FILE.read()
# File automatically closed

# Creating custom context managers
class DatabaseConnection:
    def __init__(self, HOST):
        self.host = HOST
        self.connection = None
    
    def __enter__(self):
        self.connection = f"Connected to {self.host}"
        print(self.connection)
        return self.connection
    
    def __exit__(self, EXC_TYPE, EXC_VAL, EXC_TB):
        print("Disconnecting...")
        self.connection = None
        return False  # Don't suppress exceptions

# Using custom context manager
with DatabaseConnection('localhost') as CONN:
    print(CONN)

# Using contextlib
from contextlib import contextmanager

@contextmanager
def database(HOST):
    print(f"Connecting to {HOST}")
    yield f"Connection to {HOST}"
    print("Disconnecting")

with database('localhost') as CONN:
    print(CONN)
```

### Type Hints

**Theory**: Type hints provide documentation and enable static type checking with tools like mypy.

```python
def add(A: int, B: int) -> int:
    return A + B

def greet(NAME: str) -> str:
    return f"Hello, {NAME}"

from typing import List, Dict, Optional, Union

def process_list(ITEMS: List[int]) -> Dict[str, int]:
    return {"count": len(ITEMS), "sum": sum(ITEMS)}

def get_user_age(USER_ID: int) -> Optional[int]:
    # Returns int or None
    return 30

def parse_value(VALUE: Union[int, str]) -> str:
    # Accepts int or str
    return str(VALUE)

# Complex types
def process_data(
    DATA: List[Dict[str, int]]
) -> Dict[str, List[str]]:
    pass
```

---

## Core Concepts Deep Dive

### 1. Python Object Model and Memory Management

**Detailed Theory:**
Python is built on a fundamental principle: **everything is an object**. This includes integers, strings, functions, and even types themselves. Understanding this is crucial:

```python
# Everything is an object
a = 42
type(a)                         # <class 'int'>
type(int)                       # <class 'type'>
type(type)                      # <class 'type'>

# Objects have identity, type, and value
x = 100
y = 100
print(id(x) == id(y))          # True (small integers cached)

x = 1000
y = 1000
print(id(x) == id(y))          # False (large integers not cached)

# Reference counting - automatic memory management
import sys
a = []
sys.getrefcount(a)              # Shows reference count

# Mutable vs Immutable affects behavior
# Immutable: int, str, tuple, frozenset (create new on change)
s = "hello"
s = s + " world"                # Creates new string object

# Mutable: list, dict, set (modify in place)
lst = [1, 2, 3]
lst.append(4)                   # Modifies existing list
```

**Memory Management Implications:**
```python
# Garbage collection
import gc
gc.collect()                    # Manually trigger garbage collection

# Memory leaks from circular references
class Node:
    def __init__(self):
        self.ref = self          # Circular reference
        
# Python's garbage collector handles this

# Variable assignment creates references
a = [1, 2, 3]
b = a                           # b references same list as a
b.append(4)
print(a)                        # [1, 2, 3, 4] - same object!

c = a[:]                        # Shallow copy - new list, same elements
d = [x for x in a]              # Another way to copy
```

**Keypoints:**
- Everything is an object with identity, type, and value
- Python uses reference counting + garbage collection
- Immutable objects create new instances on change
- Mutable objects modify in-place
- Assignment creates references, not copies
- Multiple references to same object affect all references
- Use copy/deepcopy for actual object duplication
- Circular references are handled by garbage collector

---

### 2. Name Binding and Scope Resolution (LEGB Rule)

**Detailed Theory:**
When Python looks up a name, it searches in a specific order. Understanding this prevents subtle bugs:

**LEGB Rule (Local → Enclosing → Global → Built-in):**

```python
# Global scope
GLOBAL = "global"

def outer():
    # Enclosing scope
    ENCLOSING = "enclosing"
    
    def inner():
        # Local scope
        LOCAL = "local"
        
        # Name lookup: Local → Enclosing → Global → Built-in
        print(LOCAL)            # Local scope
        print(ENCLOSING)        # Enclosing scope
        print(GLOBAL)           # Global scope
        print(len)              # Built-in (function)
    
    inner()

outer()

# Modifying variables at different scopes
GLOBAL_VAR = "global"

def modify():
    # This creates LOCAL variable, doesn't modify global
    GLOBAL_VAR = "local"
    print(GLOBAL_VAR)           # "local"

modify()
print(GLOBAL_VAR)               # "global" (unchanged)

# To modify global variable:
def modify_global():
    global GLOBAL_VAR
    GLOBAL_VAR = "modified"

modify_global()
print(GLOBAL_VAR)               # "modified"

# Nonlocal modifies enclosing scope
def outer_func():
    VALUE = "outer"
    
    def inner_func():
        nonlocal VALUE
        VALUE = "modified"
    
    inner_func()
    print(VALUE)                # "modified"

outer_func()

# Common mistake: reading before assignment
def problem():
    print(X)                    # UnboundLocalError!
    X = 10

# Because X assignment makes it local in entire function
```

**Keypoints:**
- Python searches for names in order: Local → Enclosing → Global → Built-in
- Assignment always creates local variable (unless global/nonlocal)
- Mutable objects can be modified without assignment
- `global` keyword modifies global variable
- `nonlocal` keyword modifies enclosing scope variable
- Function scope is created on every call
- Class body has its own scope (limited closure access)

---

### 3. Dynamic Typing and Duck Typing

**Detailed Theory:**
Python's dynamic type system is one of its defining features. Variables don't have types; objects do.

```python
# Dynamic typing - variable can hold any type
x = 42              # int
x = "hello"         # string
x = [1, 2, 3]       # list
x = lambda: None    # function

# Type checking at runtime
print(type(x))      # <class 'list'>
isinstance(x, list) # True
isinstance(x, (list, tuple))  # True if list OR tuple

# Duck typing - "if it walks like a duck and quacks like a duck..."
def process(obj):
    # Doesn't care about type, only that it has certain methods
    return obj.upper()

process("hello")                # Works - string has upper()
process(["H", "E", "L"])        # Fails - list doesn't have upper()

# Polymorphism through duck typing
class Dog:
    def speak(self):
        return "Woof"

class Cat:
    def speak(self):
        return "Meow"

def make_sound(animal):
    # Works with any object that has speak() method
    print(animal.speak())

make_sound(Dog())               # Woof
make_sound(Cat())               # Meow
```

**Advantages and Disadvantages:**

```python
# Advantage: Flexibility
def process_iterable(items):
    for item in items:
        print(item)

process_iterable([1, 2, 3])      # Works with list
process_iterable((1, 2, 3))      # Works with tuple
process_iterable("abc")          # Works with string

# Disadvantage: Runtime errors
def get_first_char(obj):
    return obj[0]  # Assumes obj supports indexing

get_first_char([1, 2, 3])        # OK - [1]
get_first_char(42)               # TypeError: 'int' object is not subscriptable

# Type hints help but don't enforce
def process(items: list) -> int:
    return len(items)            # Type hint, but not enforced at runtime
```

**Keypoints:**
- Variables are names, not types (objects have types)
- Type is determined at runtime
- Duck typing: "does it have the method?" not "what's its type?"
- Polymorphism through interface matching
- Type hints improve code documentation but don't enforce types
- Runtime type checking possible with isinstance()
- Protocol/ABC can define expected interfaces

---

### 4. Mutable vs Immutable Objects and Side Effects

**Detailed Theory:**
The distinction affects code behavior dramatically, especially with function arguments:

```python
# Immutable types - create new objects on modification
s = "hello"
s = s.upper()          # Creates new string "HELLO"
n = 5
n = n + 1              # Creates new int 6 (old 5 not modified)

# Immutable objects are safe to share
SHARED_TUPLE = (1, 2, 3)
a = SHARED_TUPLE       # Multiple references safe
b = SHARED_TUPLE

# Mutable types - modify in place
lst = [1, 2, 3]
lst.append(4)          # Modifies existing list object
lst[0] = 99            # Modifies in place

# This causes side effects through shared references
original = [1, 2, 3]
reference = original   # Same object
reference.append(4)
print(original)        # [1, 2, 3, 4] - surprised!

# Function arguments show this clearly
def modify_list(items):
    items.append(99)   # Modifies caller's list!

def modify_int(num):
    num = num + 1      # Only affects local num, not caller's

my_list = [1, 2, 3]
modify_list(my_list)
print(my_list)         # [1, 2, 3, 99] - modified!

my_int = 5
modify_int(my_int)
print(my_int)          # 5 - not modified

# Safe copying patterns
original_list = [1, 2, 3]

# Shallow copy - copies list, but not nested objects
copy1 = original_list[:]
copy2 = list(original_list)
copy3 = original_list.copy()

# Deep copy - copies recursively
import copy
nested = [[1, 2], [3, 4]]
shallow = nested[:]     # Still references nested lists
shallow[0].append(99)
print(nested)           # [[1, 2, 99], [3, 4]] - affected!

deep = copy.deepcopy(nested)
deep[0].append(99)
print(nested)           # [[1, 2], [3, 4]] - not affected
```

**Keypoints:**
- Immutable: int, float, str, tuple, frozenset (safe to share)
- Mutable: list, dict, set (careful with references)
- Function arguments are passed by object reference
- Modifying mutable objects affects all references
- Assignment (=) doesn't copy, it creates reference
- Use .copy() or slicing for shallow copies
- Use copy.deepcopy() for nested structures
- Default mutable arguments in functions are dangerous

---

### 5. Iterators, Iterables, and Generators

**Detailed Theory:**
This is a critical concept for Pythonic code. Many beginners confuse these terms:

```python
# Iterable: object that implements __iter__() method
# Returns an iterator
ITERABLE = [1, 2, 3]           # List is iterable
ITERABLE = "abc"                # String is iterable
ITERABLE = {1, 2, 3}            # Set is iterable

# Iterator: object with __iter__() and __next__()
# Maintains state (position/next item)
iterator = iter([1, 2, 3])
print(next(iterator))           # 1
print(next(iterator))           # 2
print(next(iterator))           # 3
# next(iterator)                # StopIteration

# Generator: special function that returns iterator
def count_up(max_val):
    count = 0
    while count < max_val:
        yield count             # Pause and return value
        count += 1

# Generator creates iterator
gen = count_up(3)               # Function not executed yet!
print(next(gen))                # 0 (execution starts)
print(next(gen))                # 1
print(next(gen))                # 2
# next(gen)                     # StopIteration

# Generator expression (lazy evaluation)
gen_exp = (x**2 for x in range(5))  # Not computed yet
list(gen_exp)                   # [0, 1, 4, 9, 16]

# Memory implications
# List: allocates all memory upfront
BIG_LIST = [x**2 for x in range(1_000_000)]

# Generator: allocates one at a time
BIG_GEN = (x**2 for x in range(1_000_000))
next(BIG_GEN)                   # One value computed

# Common pattern: processing files
def read_lines(filename):
    with open(filename) as f:
        for line in f:
            yield line.strip()

# Memory efficient - reads one line at a time
for line in read_lines('large_file.txt'):
    process(line)
```

**Why This Matters:**

```python
# for loop works with any iterable
for item in [1, 2, 3]:          # List
    pass

for item in "abc":              # String
    pass

for item in range(5):           # Range object (generator-like)
    pass

# Under the hood, for loop does:
# 1. Call iter() to get iterator
# 2. Repeatedly call next() until StopIteration
items = [1, 2, 3]
iterator = iter(items)
try:
    while True:
        item = next(iterator)
        print(item)
except StopIteration:
    pass
```

**Keypoints:**
- **Iterable**: implements __iter__() returning an iterator
- **Iterator**: implements __next__() and maintains state
- **Generator**: function with yield, creates iterator lazily
- Generators save memory for large or infinite sequences
- for loops work with any iterable
- next(iterator) advances to next item (raises StopIteration when done)
- Generator expressions use () like list comprehensions but lazy
- Iterators are exhausted after iteration (can't iterate twice)

---

## Best Practices

### 1. **PEP 8 - Style Guide**

```python
# Function names: lowercase_with_underscores
def calculate_sum(NUMBERS):
    pass

# Class names: CapitalizedWords
class DataProcessor:
    pass

# Constants: UPPERCASE_WITH_UNDERSCORES
MAX_RETRIES = 5
DEFAULT_TIMEOUT = 30

# Line length: max 79 characters
# Indentation: 4 spaces

# Imports at top
import sys
import os
from datetime import datetime
```

### 2. **Documentation with Docstrings**

```python
def function_example(PARAM1: str, PARAM2: int) -> bool:
    """
    Brief description of what the function does.
    
    Longer description explaining the function's behavior,
    important details, and usage notes.
    
    Args:
        PARAM1: Description of PARAM1
        PARAM2: Description of PARAM2
    
    Returns:
        Description of return value
    
    Raises:
        ValueError: When validation fails
        TypeError: When wrong type is passed
    
    Example:
        >>> result = function_example("test", 42)
        >>> print(result)
        True
    """
    pass
```

### 3. **DRY Principle (Don't Repeat Yourself)**

```python
# Bad
def process_file_1():
    with open('file1.txt') as F:
        DATA = F.read()
        return DATA.upper()

def process_file_2():
    with open('file2.txt') as F:
        DATA = F.read()
        return DATA.upper()

# Good
def process_file(FILENAME: str) -> str:
    with open(FILENAME) as F:
        return F.read().upper()

process_file('file1.txt')
process_file('file2.txt')
```

### 4. **Error Handling**

```python
def read_config(PATH: str) -> dict:
    try:
        with open(PATH) as FILE:
            import json
            return json.load(FILE)
    except FileNotFoundError:
        print(f"Config file not found: {PATH}")
        return {}
    except json.JSONDecodeError:
        print(f"Invalid JSON in {PATH}")
        return {}
```

### 5. **Testing**

```python
import unittest

class TestCalculations(unittest.TestCase):
    def test_add(self):
        self.assertEqual(add(2, 3), 5)
    
    def test_add_negative(self):
        self.assertEqual(add(-1, 1), 0)
    
    def test_divide_by_zero(self):
        with self.assertRaises(ZeroDivisionError):
            divide(10, 0)

if __name__ == '__main__':
    unittest.main()
```

### 6. **Virtual Environments**

```bash
# Create virtual environment
python -m venv venv

# Activate (Linux/Mac)
source venv/bin/activate

# Activate (Windows)
venv\Scripts\activate

# Install packages
pip install -r requirements.txt

# Deactivate
deactivate
```

### 7. **Logging**

```python
import logging

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

LOGGER = logging.getLogger(__name__)

def main():
    LOGGER.info("Application started")
    try:
        result = 10 / 0
    except ZeroDivisionError:
        LOGGER.error("Division by zero", exc_info=True)
```

### 8. **List Comprehension Over Loops**

```python
# Less readable
SQUARES = []
for X in range(10):
    SQUARES.append(X**2)

# More Pythonic
SQUARES = [X**2 for X in range(10)]
```

### 9. **Use Meaningful Names**

```python
# Bad
def f(x):
    return x * 2

# Good
def double_value(NUMBER: int) -> int:
    return NUMBER * 2
```

### 10. **Avoid Mutable Default Arguments**

```python
# Bad
def add_to_list(ITEM, LIST=[]):
    LIST.append(ITEM)
    return LIST

# Good
def add_to_list(ITEM, LIST=None):
    if LIST is None:
        LIST = []
    LIST.append(ITEM)
    return LIST
```

---

## Common Patterns

### Singleton Pattern

```python
class Singleton:
    _instance = None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
```

### Factory Pattern

```python
class DataProcessor:
    @staticmethod
    def create_processor(PROCESSOR_TYPE):
        if PROCESSOR_TYPE == 'json':
            return JsonProcessor()
        elif PROCESSOR_TYPE == 'csv':
            return CsvProcessor()
        else:
            raise ValueError("Unknown processor type")
```

### Observer Pattern

```python
class Subject:
    def __init__(self):
        self._observers = []
    
    def attach(self, OBSERVER):
        self._observers.append(OBSERVER)
    
    def notify(self, EVENT):
        for OBSERVER in self._observers:
            OBSERVER.update(EVENT)
```

---

## Interview Questions and Answers

### 1. Explain the difference between `==` and `is` in Python. When would you use each?

**Question**: What's the difference between comparing with `==` and `is`? Provide examples.

**Answer**:
- `==` checks **value equality** (calls `__eq__()`)
- `is` checks **object identity** (same memory address)

```python
# Value equality
a = [1, 2, 3]
b = [1, 2, 3]
print(a == b)               # True (same content)
print(a is b)               # False (different objects)

# Object identity
c = a
print(c == a)               # True
print(c is a)               # True (same object)

# With immutables (Python caches small integers)
x = 256
y = 256
print(x is y)               # True (cached)

x = 257
y = 257
print(x is y)               # False (not cached)

# Practical use cases
# Use == for value comparison
if user_input == expected_value:
    process()

# Use is for singleton checks
if config is None:
    config = load_default()

if obj is True:             # Rarely needed
    pass

# Comparison with None - always use is
if value is None:           # Correct
if value == None:           # Works but discouraged
if not value:               # Wrong - falsy values match
```

**Key Point**: Use `==` for value comparison; use `is` for identity checks (mainly `None`, `True`, `False`).

---

### 2. What's the difference between a shallow copy and a deep copy? Provide examples.

**Question**: Explain when you need each type of copy and the implications.

**Answer**:

```python
import copy

# Shallow copy - copies container, not nested objects
original = [[1, 2], [3, 4]]
shallow = copy.copy(original)    # Or original[:]

# Modifying nested object affects both
shallow[0].append(99)
print(original)                  # [[1, 2, 99], [3, 4]] - AFFECTED!

# Deep copy - recursively copies everything
original = [[1, 2], [3, 4]]
deep = copy.deepcopy(original)

deep[0].append(99)
print(original)                  # [[1, 2], [3, 4]] - NOT affected

# Other shallow copy methods
list1 = [1, 2, 3]
list2 = list1[:]               # Slicing creates shallow copy
list3 = list(list1)            # Constructor creates shallow copy
list4 = list1.copy()           # .copy() method

# Dictionary shallow copy
dict1 = {"a": [1, 2], "b": [3, 4]}
dict2 = dict1.copy()           # Shallow copy
dict2["a"].append(99)
print(dict1)                   # Modified! (nested list shared)

# When to use each
# Use shallow copy:
- Copying simple data structures
- When nested objects shouldn't be affected
- Performance critical (cheaper operation)

# Use deep copy:
- When you need complete independence
- Complex nested structures
- Objects with mutable attributes

# Performance impact
import timeit

original = [[i for i in range(100)] for _ in range(100)]

# Shallow copy is fast
t1 = timeit.timeit(lambda: original.copy(), number=10000)

# Deep copy is slow
import copy
t2 = timeit.timeit(lambda: copy.deepcopy(original), number=10000)

print(f"Shallow: {t1}s, Deep: {t2}s")  # Deep is ~100x slower
```

**Key Point**: Shallow copy copies the container; deep copy copies everything recursively.

---

### 3. Explain the difference between `*args` and `**kwargs`. How would you use them?

**Question**: When do you use `*args` and `**kwargs`? Provide practical examples.

**Answer**:

```python
# *args - variable positional arguments (tuple)
def print_args(*args):
    print(f"Type: {type(args)}")     # <class 'tuple'>
    for arg in args:
        print(arg)

print_args(1, 2, 3)                  # Collects into tuple
# Output:
# Type: <class 'tuple'>
# 1
# 2
# 3

# **kwargs - variable keyword arguments (dict)
def print_kwargs(**kwargs):
    print(f"Type: {type(kwargs)}")   # <class 'dict'>
    for key, value in kwargs.items():
        print(f"{key}: {value}")

print_kwargs(name="Alice", age=30, job="Engineer")
# Output:
# Type: <class 'dict'>
# name: Alice
# age: 30
# job: Engineer

# Combining all types
def flexible_function(required, *args, optional=None, **kwargs):
    print(f"Required: {required}")
    print(f"Args: {args}")
    print(f"Optional: {optional}")
    print(f"Kwargs: {kwargs}")

flexible_function(1, 2, 3, 4, optional="value", x=10, y=20)
# Output:
# Required: 1
# Args: (2, 3, 4)
# Optional: value
# Kwargs: {'x': 10, 'y': 20}

# Practical use: wrappers and decorators
def log_calls(func):
    def wrapper(*args, **kwargs):
        print(f"Calling {func.__name__}")
        print(f"Args: {args}, Kwargs: {kwargs}")
        return func(*args, **kwargs)
    return wrapper

@log_calls
def add(a, b):
    return a + b

# Unpacking arguments
def greet(name, greeting="Hello"):
    return f"{greeting}, {name}!"

# Unpack list
args = ["Alice", "Hi"]
print(greet(*args))                  # "Hi, Alice!"

# Unpack dictionary
kwargs = {"name": "Bob", "greeting": "Hey"}
print(greet(**kwargs))               # "Hey, Bob!"

# Practical: configuration merging
DEFAULT_CONFIG = {"debug": False, "timeout": 30}

def create_app(**custom_config):
    config = {**DEFAULT_CONFIG, **custom_config}  # Merge configs
    return config

app_config = create_app(debug=True, port=8000)
# {'debug': True, 'timeout': 30, 'port': 8000}
```

**Key Point**: `*args` collects positional into tuple; `**kwargs` collects keyword into dict. Use for flexible APIs.

---

### 4. What's the difference between `append()` and `extend()` on lists?

**Question**: When would you use each and what's the difference in behavior?

**Answer**:

```python
# append() - adds single element (or single object)
lst = [1, 2, 3]
lst.append([4, 5])
print(lst)                          # [1, 2, 3, [4, 5]]

# extend() - adds multiple elements (unpacks iterable)
lst = [1, 2, 3]
lst.extend([4, 5])
print(lst)                          # [1, 2, 3, 4, 5]

# Key difference with iterables
lst = [1, 2, 3]

# append with string - adds whole string as element
lst.append("hello")
print(lst)                          # [1, 2, 3, 'hello']

# extend with string - unpacks each character
lst = [1, 2, 3]
lst.extend("hello")
print(lst)                          # [1, 2, 3, 'h', 'e', 'l', 'l', 'o']

# Performance difference
import timeit

lst = list(range(1000))

# append in loop
t1 = timeit.timeit(lambda: lst.append(1), number=100000)

# extend with single-item list (inefficient)
t2 = timeit.timeit(lambda: lst.extend([1]), number=100000)

# extend is slower for single items (unpacking overhead)

# Practical recommendations
# Use append() for single items:
results = []
for user in users:
    results.append(user.name)

# Use extend() for combining lists:
list1 = [1, 2, 3]
list2 = [4, 5, 6]
list1.extend(list2)                 # list1 = [1, 2, 3, 4, 5, 6]

# Or use list concatenation (creates new list):
combined = list1 + list2            # [1, 2, 3, 4, 5, 6]

# Or use unpacking (modern Python 3.5+):
combined = [*list1, *list2]         # [1, 2, 3, 4, 5, 6]
```

**Key Point**: `append()` adds element as-is; `extend()` unpacks iterable into elements.

---

### 5. Explain Python's garbage collection and how reference counting works.

**Question**: How does Python manage memory? When are objects deleted?

**Answer**:

```python
import sys

# Reference counting
obj = []
print(sys.getrefcount(obj))         # 2 (obj + function parameter)

a = obj                             # Another reference
print(sys.getrefcount(obj))         # 3

b = obj
print(sys.getrefcount(obj))         # 4

del a                               # Remove reference
print(sys.getrefcount(obj))         # 3

# When reference count reaches 0, object is deleted
def create_temp():
    temp_list = [1, 2, 3]
    return len(temp_list)

create_temp()  # temp_list deleted when function exits (refcount = 0)

# Circular references - not immediately deleted
class Node:
    def __init__(self):
        self.ref = self              # Circular reference

node = Node()
del node                            # Still in memory! (circular ref)

# Garbage collector handles circular references
import gc
gc.collect()                        # Manual collection

# Check for circular references
import weakref

class SafeNode:
    def __init__(self):
        self.ref = weakref.ref(self)  # Weak reference (doesn't increase count)

# Demonstration: when objects are deleted
class Tracker:
    def __init__(self, name):
        self.name = name
        print(f"Created: {name}")
    
    def __del__(self):
        print(f"Deleted: {self.name}")

a = Tracker("A")
b = Tracker("B")
del a                               # Prints: Deleted: A

# Lifetime
def scope_test():
    c = Tracker("C")
    print("Inside function")
    # c deleted here (refcount = 0)

scope_test()                        # Prints: Inside function, Deleted: C

# Garbage collection cycle
import gc

# Disable automatic collection
gc.disable()

# Create circular reference
obj1 = {}
obj2 = {}
obj1['ref'] = obj2
obj2['ref'] = obj1
del obj1, obj2                      # Not immediately deleted

# Manual collection
print(gc.collect())                 # Shows number of unreachable objects

gc.enable()                         # Re-enable automatic collection
```

**Key Points**:
- Reference counting: object deleted when refcount = 0
- Circular references: handled by garbage collector
- `del` removes reference (may not immediately delete if other refs exist)
- `__del__()` called when object deleted (use sparingly)
- Most Python objects are immediately deleted via reference counting

---

### 6. What's a decorator and how would you write one?

**Question**: Explain decorators and write a decorator that adds functionality.

**Answer**:

```python
# Simple decorator
def my_decorator(func):
    def wrapper():
        print("Before function")
        func()
        print("After function")
    return wrapper

@my_decorator
def say_hello():
    print("Hello!")

say_hello()
# Output:
# Before function
# Hello!
# After function

# Decorator with arguments to decorated function
def decorator_with_args(func):
    def wrapper(*args, **kwargs):
        print(f"Calling {func.__name__}")
        return func(*args, **kwargs)    # Pass through arguments
    return wrapper

@decorator_with_args
def greet(name):
    return f"Hello, {name}!"

print(greet("Alice"))
# Output:
# Calling greet
# Hello, Alice!

# Decorator with arguments
def repeat(times):
    def decorator(func):
        def wrapper(*args, **kwargs):
            for _ in range(times):
                func(*args, **kwargs)
        return wrapper
    return decorator

@repeat(3)
def say_hi():
    print("Hi!")

say_hi()
# Output:
# Hi!
# Hi!
# Hi!

# Practical decorators

# Timing decorator
import time
from functools import wraps

def timeit(func):
    @wraps(func)  # Preserves func metadata
    def wrapper(*args, **kwargs):
        start = time.time()
        result = func(*args, **kwargs)
        elapsed = time.time() - start
        print(f"{func.__name__} took {elapsed:.4f}s")
        return result
    return wrapper

@timeit
def slow_function():
    time.sleep(1)
    return "Done"

slow_function()

# Memoization decorator
def memoize(func):
    cache = {}
    @wraps(func)
    def wrapper(n):
        if n not in cache:
            cache[n] = func(n)
        return cache[n]
    return wrapper

@memoize
def fibonacci(n):
    if n <= 1:
        return n
    return fibonacci(n-1) + fibonacci(n-2)

print(fibonacci(30))  # Fast even for large n

# Validation decorator
def validate_positive(*arg_indices):
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            for idx in arg_indices:
                if args[idx] < 0:
                    raise ValueError(f"Argument {idx} must be positive")
            return func(*args, **kwargs)
        return wrapper
    return decorator

@validate_positive(0, 1)
def divide(a, b):
    return a / b

divide(10, 2)           # OK
divide(-10, 2)          # Raises ValueError
```

**Key Points**:
- Decorators wrap functions to modify behavior
- Use `@wraps` to preserve function metadata
- Can be used for logging, timing, validation, caching, etc.
- Multiple decorators stack: `@decorator1 @decorator2 def func():`

---

### 7. Explain the concept of duck typing and provide an example.

**Question**: What is duck typing and how does it differ from static typing?

**Answer**:

```python
# Duck typing: "If it walks like a duck and quacks like a duck, it's a duck"
# Focus on what an object can do, not what it is

# Example 1: Polymorphism without inheritance
class Dog:
    def speak(self):
        return "Woof"

class Cat:
    def speak(self):
        return "Meow"

class Robot:
    def speak(self):
        return "Beep boop"

# Function works with ANY object that has speak()
def make_sound(animal):
    print(animal.speak())

make_sound(Dog())       # Works
make_sound(Cat())       # Works
make_sound(Robot())     # Works - no shared base class!

# Example 2: File-like objects
class TextFile:
    def read(self):
        return "File content"
    
    def write(self, data):
        pass

class StringIO:
    def read(self):
        return "String content"
    
    def write(self, data):
        self.data = data

def process_file(file_obj):
    # Doesn't care about type, only that it has read/write
    content = file_obj.read()
    file_obj.write(content.upper())

process_file(TextFile())    # Works
process_file(StringIO())    # Works
process_file(open("file.txt"))  # Works

# Example 3: Iteration protocol
def iterate_and_print(iterable):
    # Works with any iterable (list, string, dict, generator, etc.)
    for item in iterable:
        print(item)

iterate_and_print([1, 2, 3])
iterate_and_print("hello")
iterate_and_print({1, 2, 3})

# Example 4: Numeric operations
class CustomNumber:
    def __init__(self, value):
        self.value = value
    
    def __add__(self, other):
        return CustomNumber(self.value + other.value)
    
    def __mul__(self, other):
        return CustomNumber(self.value * other.value)

num = CustomNumber(5)
result = num + CustomNumber(3) + CustomNumber(2)  # Works!

# Advantages of duck typing
# 1. Flexibility - works with any compatible object
# 2. Less boilerplate - no inheritance needed
# 3. Late binding - errors only at usage time

# Disadvantages
# 1. Less explicit - not clear what methods required
# 2. Runtime errors - misspelled method name causes error
# 3. IDE support - harder to autocomplete

# Modern Python: Protocols for duck typing clarity
from typing import Protocol

class Drawable(Protocol):
    def draw(self) -> None:
        ...

class Circle:
    def draw(self):
        print("Drawing circle")

def render(shape: Drawable):
    shape.draw()

render(Circle())  # Works - Circle "implements" Drawable protocol
```

**Key Point**: Duck typing focuses on interface (what methods exist), not inheritance. Pythonic and flexible.

---

### 8. What's a generator and how is it different from returning a list?

**Question**: Explain generators and when to use them instead of lists.

**Answer**:

```python
# Generator - returns values one at a time (lazy)
def count_up(max_val):
    num = 0
    while num < max_val:
        yield num           # Pause execution, return value
        num += 1

# Create generator (execution not started yet)
gen = count_up(3)
print(type(gen))            # <class 'generator'>

# Iterate and consume values
print(next(gen))            # 0 (execution resumes)
print(next(gen))            # 1
print(next(gen))            # 2
# next(gen)                 # StopIteration

# Or use in loop
for num in count_up(3):
    print(num)              # 0, 1, 2

# Generator expression (like list comprehension but lazy)
list_comp = [x**2 for x in range(5)]        # Creates list: [0, 1, 4, 9, 16]
gen_exp = (x**2 for x in range(5))          # Creates generator (parentheses)

print(len(list_comp))                       # 5
print(len(gen_exp))                         # Error! Generators don't have len()

# Memory comparison
import sys

# List - stores all values
big_list = [x for x in range(1_000_000)]
print(f"List size: {sys.getsizeof(big_list)} bytes")  # ~8+ MB

# Generator - stores nothing (just function)
big_gen = (x for x in range(1_000_000))
print(f"Generator size: {sys.getsizeof(big_gen)} bytes")  # ~128 bytes

# Practical: reading large files
def read_large_file(filepath):
    with open(filepath) as f:
        for line in f:
            yield line.strip()

# Memory efficient - reads one line at a time
for line in read_large_file("huge_file.txt"):
    process(line)

# vs loading entire file
with open("huge_file.txt") as f:
    lines = f.readlines()   # All in memory!
    for line in lines:
        process(line)

# Generator with multiple yields
def fibonacci(max_count):
    a, b = 0, 1
    count = 0
    while count < max_count:
        yield a
        a, b = b, a + b
        count += 1

for fib in fibonacci(10):
    print(fib, end=" ")     # 0 1 1 2 3 5 8 13 21 34

# Generator with send() - two-way communication
def echo():
    print("Ready to receive")
    while True:
        received = yield
        print(f"Received: {received}")

gen = echo()
next(gen)                   # Prime the generator
gen.send("Hello")
gen.send("World")

# When to use generators
# 1. Large datasets - memory efficient
# 2. Infinite sequences - can't store in list
# 3. Pipeline processing - chain operations
# 4. Lazy evaluation - compute only when needed

# When to use lists
# 1. Need length - len(list)
# 2. Need indexing - list[5]
# 3. Need multiple passes - generators exhausted after use
# 4. Small datasets - simpler code
```

**Key Point**: Generators produce values on-the-fly (lazy), lists store all values. Generators are memory efficient for large data.

---

### 9. What is a context manager and when would you use one?

**Question**: Explain context managers and write a custom one.

**Answer**:

```python
# Built-in context manager - file handling
with open("file.txt") as f:
    content = f.read()
# File automatically closed (even if error)

# Why context managers matter
# 1. Resource cleanup guaranteed
# 2. Exception safe
# 3. Clean, readable code

# Custom context manager (class-based)
class DatabaseConnection:
    def __init__(self, database_url):
        self.url = database_url
        self.connection = None
    
    def __enter__(self):
        print(f"Connecting to {self.url}")
        self.connection = "connected"  # Simulated
        return self.connection
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        print("Disconnecting...")
        self.connection = None
        # Return False to propagate exceptions
        return False

# Usage
with DatabaseConnection("localhost:5432") as conn:
    print(f"Using connection: {conn}")
# Output:
# Connecting to localhost:5432
# Using connection: connected
# Disconnecting...

# Exception handling in context managers
class SafeDatabaseConnection:
    def __init__(self, database_url):
        self.url = database_url
    
    def __enter__(self):
        print("Connecting...")
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type is not None:
            print(f"Error occurred: {exc_type.__name__}: {exc_val}")
        print("Cleaning up...")
        return False  # Propagate exception

# Exception propagates after cleanup
try:
    with SafeDatabaseConnection("localhost") as db:
        raise ValueError("Test error")
except ValueError:
    print("Caught exception")

# Output:
# Connecting...
# Error occurred: ValueError: Test error
# Cleaning up...
# Caught exception

# Context manager using decorator (@contextmanager)
from contextlib import contextmanager

@contextmanager
def timer(name):
    import time
    print(f"Starting {name}")
    start = time.time()
    try:
        yield                   # Execution goes to with block
    finally:
        elapsed = time.time() - start
        print(f"{name} took {elapsed:.2f}s")

# Usage
with timer("my task"):
    # do work
    time.sleep(1)

# Output:
# Starting my task
# my task took 1.00s

# Practical: temporary directory
import tempfile
import os

with tempfile.TemporaryDirectory() as tmpdir:
    filepath = os.path.join(tmpdir, "temp.txt")
    with open(filepath, "w") as f:
        f.write("temporary data")
    # Both file and directory automatically cleaned up

# Resource locking
from threading import Lock

class ThreadSafeResource:
    def __init__(self):
        self.lock = Lock()
        self.data = []
    
    def safe_append(self, item):
        with self.lock:         # Acquires lock, releases after block
            self.data.append(item)
```

**Key Points**:
- Context managers ensure cleanup via `__enter__` and `__exit__`
- Use `with` statement for automatic resource management
- `@contextmanager` decorator simplifies custom context managers
- Exception-safe (cleanup happens even if error)

---

### 10. What is a metaclass and when would you use one?

**Question**: Explain metaclasses and provide a practical example.

**Answer**:

```python
# Metaclass - "class of a class"
# Most classes are instances of 'type' (the default metaclass)

class SimpleClass:
    pass

print(type(SimpleClass))    # <class 'type'>
print(type(int))            # <class 'type'>

# All classes are instances of a metaclass
# By default, that metaclass is 'type'

# Custom metaclass - controls class creation
class Singleton(type):
    _instances = {}
    
    def __call__(cls, *args, **kwargs):
        if cls not in cls._instances:
            instance = super().__call__(*args, **kwargs)
            cls._instances[cls] = instance
        return cls._instances[cls]

class Database(metaclass=Singleton):
    def __init__(self):
        print("Initializing database")
        self.connection = "connected"

# Usage - only one instance created
db1 = Database()
db2 = Database()
print(db1 is db2)           # True - same instance!

# Output:
# Initializing database

# Practical: automatic property creation
class AutoPropertyMeta(type):
    def __new__(mcs, name, bases, namespace):
        # Automatically create properties for _name attributes
        for attr, value in list(namespace.items()):
            if attr.startswith('_') and not attr.startswith('__'):
                prop_name = attr[1:]  # Remove leading underscore
                
                # Create property
                def make_property(attr_name):
                    def getter(self):
                        return getattr(self, attr_name)
                    def setter(self, value):
                        setattr(self, attr_name, value)
                    return property(getter, setter)
                
                namespace[prop_name] = make_property(attr)
        
        return super().__new__(mcs, name, bases, namespace)

class Person(metaclass=AutoPropertyMeta):
    def __init__(self, name):
        self._name = name

# Usage
person = Person("Alice")
print(person.name)          # Alice (property automatically created)
person.name = "Bob"
print(person._name)         # Bob

# Enforcing interface
class InterfaceMeta(type):
    def __new__(mcs, name, bases, namespace):
        # Check that required methods are implemented
        required_methods = ['process', 'validate']
        
        for method in required_methods:
            if method not in namespace:
                raise TypeError(f"{name} must implement {method}")
        
        return super().__new__(mcs, name, bases, namespace)

class DataProcessor(metaclass=InterfaceMeta):
    def process(self):
        pass
    
    def validate(self):
        pass

# This works
processor = DataProcessor()

# This fails
try:
    class BadProcessor(metaclass=InterfaceMeta):
        def process(self):
            pass
        # Missing validate() - raises TypeError
except TypeError as e:
    print(f"Error: {e}")

# When to use metaclasses
# 1. Frameworks - ORM, web frameworks
# 2. Enforcing patterns - singletons, interfaces
# 3. Automatic code generation
# 4. Advanced registration systems

# When NOT to use
# 1. Most regular classes - overkill
# 2. When decorators/inheritance can solve it
# 3. Code becomes hard to debug
# 4. Team not familiar with them

# Quote: "Metaclasses are deeper magic than 99% of users should ever worry about"
# - Tim Peters, Python core developer
```

**Key Point**: Metaclasses control class creation. Powerful but rarely needed; usually better alternatives exist.

---

## Resources and References

- Official Python Documentation: https://docs.python.org/3/
- PEP 8 Style Guide: https://pep8.org/
- Real Python: https://realpython.com/
- Python Enhancement Proposals: https://peps.python.org/
- Awesome Python: https://awesome-python.com/
# Shell Scripting Complete Notes

## Table of Contents
1. [Fundamentals](#fundamentals)
2. [Variables and Data Types](#variables-and-data-types)
3. [Operators](#operators)
4. [Control Structures](#control-structures)
5. [Functions](#functions)
6. [Input/Output](#inputoutput)
7. [File Operations](#file-operations)
8. [Text Processing](#text-processing)
9. [Advanced Concepts](#advanced-concepts)
10. [Best Practices](#best-practices)

---

## Fundamentals

### What is Shell?
A shell is a command interpreter that executes commands typed by users or in scripts. It serves as the interface between the user and the operating system kernel.

### Types of Shells
- **Bash** (Bourne Again Shell) - Most common, feature-rich
- **Sh** (Bourne Shell) - Original, portable
- **Zsh** - Extended Bash with advanced features
- **Fish** - User-friendly, focuses on usability
- **Ksh** (Korn Shell) - Combines Bourne and C shell features

### Why Shell Scripting?
- **Automation**: Automate repetitive tasks
- **System Administration**: Manage system resources
- **Deployment**: Deploy applications and services
- **Batch Processing**: Process multiple files
- **Portability**: Works across Unix-like systems

### Shebang Line
```bash
#!/bin/bash
#!/bin/sh
#!/usr/bin/env python3
```
The shebang (`#!`) tells the system which interpreter to use. The `env` approach is more portable.

### Execution Methods
```bash
# Method 1: Direct execution (needs execute permission)
./script.sh

# Method 2: Bash interpreter
bash script.sh

# Method 3: Source (runs in current shell)
source script.sh
. script.sh
```

---

## Variables and Data Types

### Variable Declaration and Assignment

**Theory**: Shell variables are containers for storing data. They're weakly typed - everything is initially a string unless explicitly treated as a number.

```bash
# Variable assignment (no spaces around =)
NAME="John Doe"
AGE=30
PRICE=19.99

# Accessing variables
echo $NAME
echo ${NAME}  # Preferred syntax (safer)

# Read-only variables
readonly PI=3.14159

# Unsetting variables
unset NAME
```

### Variable Naming Rules
- Start with letter or underscore
- Contain letters, numbers, underscores
- Case-sensitive (name ≠ NAME)
- Avoid shell keywords (if, for, etc.)

### Variable Scope
```bash
# Global variable
GLOBAL_VAR="visible everywhere"

function my_function() {
    # Local variable
    local LOCAL_VAR="only in function"
    echo $GLOBAL_VAR  # Can access global
    echo $LOCAL_VAR   # Can access local
}

my_function
echo $LOCAL_VAR  # Error: undefined
```

### Special Variables

**Detailed Theory:**
Special variables provide access to shell state and function arguments. Understanding `$@` vs `$*` is critical for handling arguments correctly.

| Variable | Meaning | Example |
|----------|---------|---------|
| `$0` | Script name | `bash script.sh` → `$0` = `script.sh` |
| `$1, $2, ...` | Positional parameters | `$1` = first arg, `$2` = second |
| `$@` | **All parameters as separate words** | `"$@"` expands each arg as separate word |
| `$*` | **All parameters as single word** | `"$*"` concatenates all args |
| `$#` | Number of parameters | `script.sh a b c` → `$#` = 3 |
| `$?` | Exit status of last command | `0` = success, non-zero = failure |
| `$$` | Process ID (PID) | Unique process number |
| `$!` | PID of last background process | Used to wait on background job |
| `$-` | Current shell options | Shows set options |

```bash
#!/bin/bash
# Save script name for error messages
SCRIPT_NAME="$0"

# Critical: $@ vs $*
function show_args() {
    echo "Using \$@ (CORRECT for preserving args):"
    for arg in "$@"; do
        echo "  [$arg]"
    done
    
    echo "Using \$* (WRONG - concatenates):"
    for arg in $*; do
        echo "  [$arg]"
    done
}

# With arguments: script.sh "arg 1" "arg 2"
# $@ expands to: "arg 1" "arg 2" (preserves spaces)
# $* expands to: arg 1 arg 2 (loses word boundaries)

# Always use "$@" to preserve arguments
function safe_function() {
    # "$@" preserves each argument
    for ARG in "$@"; do
        echo "Processing: $ARG"
    done
}

# Check exit status
ls /nonexistent
EXIT_CODE=$?
if [[ $EXIT_CODE -ne 0 ]]; then
    echo "Command failed with code $EXIT_CODE"
fi

# Background process tracking
long_task &
BG_PID=$!
wait $BG_PID  # Wait for this specific process
```

**Keypoints:**
- `$@` vs `$*` distinction is crucial for argument handling
- Always use `"$@"` in functions and scripts (preserves arguments)
- `$?` must be checked immediately (it changes after each command)
- `$$` is process ID; `$!` is last background process PID
- `$0` should be quoted when used in error messages
- `${1:-default}` provides default if argument missing
- `${@:2}` gets arguments starting from position 2
echo "First arg: $1"
echo "All args: $@"
echo "Arg count: $#"
```

### Environment Variables
```bash
# Display all environment variables
env
printenv

# Export makes variable available to child processes
export MY_VAR="value"

# Common environment variables
echo $HOME       # User's home directory
echo $PATH       # Executable search paths
echo $USER       # Current user
echo $PWD        # Current directory
echo $LANG       # Language setting
```

### Variable Expansion and Substitution

```bash
# Basic expansion
NAME="Alice"
echo "Hello $NAME"  # Hello Alice

# Braces prevent ambiguity
echo "${NAME}123"   # Alice123 (not $NAME123)

# Default values
echo ${NAME:-default}      # Use NAME or "default"
echo ${NAME:=default}      # Set to default if unset
echo ${NAME:?error msg}    # Show error if unset
echo ${NAME:+alternate}    # Use alternate if set

# String manipulation
TEXT="hello world"
echo ${TEXT:0:5}           # hello (substring)
echo ${TEXT#hello }        # world (remove prefix)
echo ${TEXT%world}         # hello (remove suffix)
echo ${TEXT//o/O}          # hellO wOrld (replace all)
echo ${#TEXT}              # 11 (length)

# Uppercase/lowercase (Bash 4+)
echo ${TEXT^^}             # HELLO WORLD
echo ${TEXT,,}             # hello world
```

---

## Operators

### Arithmetic Operators

**Detailed Theory**: 
Bash is fundamentally a string processor. When you set `A=10`, the variable `A` contains the STRING "10", not the number 10. To perform arithmetic, you must explicitly enter **arithmetic context** using `$((…))`. 

The `$((…))` syntax:
- Evaluates the expression mathematically
- Treats variables as numbers (no $ needed inside)
- Ignores spaces within the expression
- Returns the numeric result

Why this matters:
```bash
A="10"
B="3"

# Without arithmetic context - string concatenation
echo $A$B                  # Output: 103 (concatenation)

# With arithmetic context - mathematical operation
echo $((A + B))            # Output: 13 (addition)

# Inside $(()), variable name alone is sufficient
echo $((A + B))            # Works
echo $(($A + $B))          # Also works but $ is redundant
```

```bash
# Method 1: Arithmetic expansion $((expression)) - Preferred
A=10
B=3
echo $((A + B))            # 13
echo $((A - B))            # 7
echo $((A * B))            # 30
echo $((A / B))            # 3 (integer division)
echo $((A % B))            # 1 (modulo)
echo $((A ** 2))           # 100 (exponentiation)

# Compound assignments
((A += 5))                 # A = A + 5 = 15
((A -= 3))                 # A = A - 3 = 12
((A *= 2))                 # A = A * 2 = 24
((A /= 4))                 # A = A / 4 = 6
((A++))                    # Increment A
((A--))                    # Decrement A

# Method 2: let command (less common)
let "C = A + B"
let "C += 5"               # C = C + 5

# Method 3: expr (external command, slowest)
C=$(expr $A + $B)          # Note: spaces required in expr
```

**Keypoints:**
- Bash variables are strings; arithmetic requires explicit context
- `$((expression))` is the modern, preferred method
- Inside `$((…))`, spaces are ignored and $ is optional
- Integer division rounds down (no floating point)
- Modulo (%) gets remainder after division
- Compound operators (+=, -=, etc.) modify variables
- `expr` is POSIX portable but slower than `$((…))`

### String Comparison

**Detailed Theory:**
String comparison in Bash is lexicographic (dictionary order), not numeric. The `[[ ]]` syntax is Bash-specific and preferred over `[ ]` because it handles spaces better and supports pattern matching.

```bash
STR1="hello"
STR2="world"

# Equality
[[ $STR1 == $STR2 ]]       # false
[[ $STR1 != $STR2 ]]       # true
[[ $STR1 < $STR2 ]]        # true (lexicographic: h < w)

# String tests
[[ -z $STR1 ]]             # true if empty (zero length)
[[ -n $STR1 ]]             # true if not empty
[[ $STR1 ]]                # true if not empty (implicit -n)

# Pattern matching (ONLY in [[ ]])
[[ $STR1 == h* ]]          # true (matches pattern)
[[ $STR1 =~ ^h.*o$ ]]      # true (regex match)
```

**Why [[ ]] is safer:**
```bash
VAR=""

# With [ ] - dangerous
[ $VAR = "value" ]         # Error: [ "value" ]
[ "$VAR" = "value" ]       # Works: [ = value ]

# With [[ ]] - safe
[[ $VAR = "value" ]]       # Works: quotes not needed
[[ $VAR == "value" ]]      # Works: == for comparison in [[ ]]
```

**Keypoints:**
- Use `[[ ]]` for comparison (Bash-specific, safer)
- Use `==` or `=` for string equality (same in Bash)
- Use `!=` for inequality
- `<` and `>` are lexicographic (dictionary order)
- `-z` tests for empty string
- `-n` tests for non-empty string
- Pattern matching (glob) works in `[[ ]]` only
- Always quote variables in `[ ]`, unnecessary in `[[ ]]`

### Numeric Comparison

```bash
NUM1=10
NUM2=20

# Must use -eq, -ne, -lt, -le, -gt, -ge
[[ $NUM1 -eq $NUM2 ]]      # false (equal)
[[ $NUM1 -ne $NUM2 ]]      # true (not equal)
[[ $NUM1 -lt $NUM2 ]]      # true (less than)
[[ $NUM1 -le $NUM2 ]]      # true (less or equal)
[[ $NUM1 -gt $NUM2 ]]      # false (greater than)
[[ $NUM1 -ge $NUM2 ]]      # false (greater or equal)
```

### File Tests

```bash
FILE="/path/to/file"

[[ -e $FILE ]]             # Exists
[[ -f $FILE ]]             # Regular file
[[ -d $FILE ]]             # Directory
[[ -r $FILE ]]             # Readable
[[ -w $FILE ]]             # Writable
[[ -x $FILE ]]             # Executable
[[ -s $FILE ]]             # Non-empty
[[ -L $FILE ]]             # Symbolic link
[[ $FILE1 -nt $FILE2 ]]    # FILE1 newer than FILE2
[[ $FILE1 -ot $FILE2 ]]    # FILE1 older than FILE2
```

### Logical Operators

```bash
# AND
[[ $A -gt 0 && $B -lt 100 ]]
[[ $A -gt 0 ]] && [[ $B -lt 100 ]]

# OR
[[ $A -gt 100 || $A -lt 0 ]]

# NOT
[[ ! $CONDITION ]]

# Combining
[[ ($A -gt 0 && $B -lt 100) || $C -eq 0 ]]
```

### Differences: [[ ]] vs [ ]

- `[[ ]]`: Bash-specific, safer, supports regex, no word splitting
- `[ ]`: POSIX-compatible, requires quotes, external command

```bash
FILE="file with spaces.txt"

# [[ ]] handles spaces correctly
[[ -f $FILE ]]             # Works correctly

# [ ] needs quotes
[ -f "$FILE" ]             # Must quote

# [[ ]] supports regex
[[ $EMAIL =~ ^[a-z]+@[a-z]+\.[a-z]+$ ]]

# [[ ]] supports pattern matching
[[ $FILENAME == *.txt ]]
```

---

## Control Structures

### If-Else

```bash
# Basic if
if [[ $AGE -ge 18 ]]; then
    echo "Adult"
fi

# If-else
if [[ $AGE -ge 18 ]]; then
    echo "Adult"
else
    echo "Minor"
fi

# If-elif-else
if [[ $GRADE == "A" ]]; then
    echo "Excellent"
elif [[ $GRADE == "B" ]]; then
    echo "Good"
elif [[ $GRADE == "C" ]]; then
    echo "Fair"
else
    echo "Poor"
fi

# One-liner
[[ $AGE -ge 18 ]] && echo "Adult" || echo "Minor"
```

### Case Statement

```bash
case $OPTION in
    1)
        echo "Option 1 selected"
        ;;
    2|3)
        echo "Option 2 or 3"
        ;;
    [4-6])
        echo "Option 4, 5, or 6"
        ;;
    *)
        echo "Invalid option"
        ;;
esac

# Practical example
case "${OSTYPE}" in
    linux*)
        echo "Linux detected"
        ;;
    darwin*)
        echo "macOS detected"
        ;;
    msys*)
        echo "Windows detected"
        ;;
esac
```

### For Loop

**Detailed Theory**: 
Bash for loops iterate over **words**, not structured data like Python. Understanding word splitting is critical.

**Key Concepts:**
1. The for loop expands its list first, creating words
2. Each word becomes the loop variable value
3. Word splitting respects IFS (Internal Field Separator)

```bash
# For loop expands BEFORE iteration
for ITEM in apple banana orange; do
    echo "I like $ITEM"
done
# Expands to: for ITEM in apple banana orange

# But what if we have multiple items from expansion?
for ITEM in $(echo "apple banana orange"); do
    echo "$ITEM"              # Same as above - word splitting on spaces
done

# Word splitting happens on IFS
IFS=:
for ITEM in one:two:three; do
    echo "$ITEM"              # one, two, three
done
```

**Arrays and Iteration (Critical Difference):**
```bash
# Without quotes - wrong!
COLORS=("red" "green" "blue")
for COLOR in $COLORS; do
    echo $COLOR               # Only prints "red" (first element)
done

# With quotes and [@] - correct!
for COLOR in "${COLORS[@]}"; do
    echo $COLOR               # Prints: red, green, blue
done

# ${COLORS[@]} expands to all elements as separate words
# "${COLORS[@]}" expands with proper quoting

# Compare to:
for COLOR in ${COLORS[@]}; do   # Without quotes - word splitting
    echo $COLOR
done
```

```bash
# Iterate over list
for FRUIT in apple banana orange; do
    echo "I like $FRUIT"
done

# Iterate over array
COLORS=("red" "green" "blue")
for COLOR in "${COLORS[@]}"; do
    echo "Color: $COLOR"
done

# Iterate over range
for i in {1..5}; do
    echo "Number: $i"
done

# C-style for loop
for ((i=1; i<=5; i++)); do
    echo "Count: $i"
done

# Iterate over command output
for FILE in $(ls *.txt); do
    echo "Processing: $FILE"
done

# Iterate over array with index
for i in "${!COLORS[@]}"; do
    echo "Index $i: ${COLORS[$i]}"
done
```

### While Loop

**Detailed Theory**:
While loops repeat as long as a condition is true. They're versatile and commonly used for reading input line-by-line.

**Key Concept: The Condition**
The condition is a command; the loop continues if exit status is 0 (success).

```bash
# Basic while loop
COUNT=1
while [[ $COUNT -le 5 ]]; do
    echo "Count: $COUNT"
    ((COUNT++))
done

# While with command condition (exit status 0 = continue)
while grep -q "pattern" file.txt; do
    echo "Still has pattern"
    # Code to modify file.txt
done

# Infinite loop (true always returns 0)
while true; do
    echo "Running..."
    sleep 1
    # break to exit
done

# Common pattern: read file line by line
while IFS= read -r LINE; do
    echo "Processing: $LINE"
done < file.txt

# IFS='' prevents stripping leading/trailing spaces
# read -r prevents interpreting backslashes

# Read from command output
while IFS= read -r LINE; do
    echo "$LINE"
done < <(ls -la)

# Until loop (opposite - continues while condition FALSE)
COUNT=1
until [[ $COUNT -gt 5 ]]; do
    echo "Count: $COUNT"
    ((COUNT++))
done
# Same as: while [[ $COUNT -le 5 ]]
```

**Critical Pattern: Reading Input**
```bash
# Reading stdin line by line
while read -r LINE; do
    echo "You entered: $LINE"
done

# Reading file with while loop
while IFS= read -r LINE; do
    process_line "$LINE"
done < input_file.txt

# Difference between IFS settings:
# IFS= (empty)        - preserves all spaces
# IFS=' ' (default)   - collapses whitespace
# IFS=':' (custom)    - splits on colons
```

**Keypoints:**
- While condition is a command; loop continues if exit status = 0
- `while true` creates infinite loop (use `break` to exit)
- Until loop continues while condition is **false** (opposite of while)
- Always use `read -r` to prevent backslash interpretation
- Use `IFS=` to preserve whitespace in file reading
- File redirection `< file.txt` more efficient than `cat file.txt |`
- Each loop iteration is a subshell when input is piped
- Break exits loop; continue skips to next iteration

### Break and Continue

```bash
for i in {1..10}; do
    if [[ $i -eq 3 ]]; then
        continue              # Skip this iteration
    fi
    if [[ $i -eq 8 ]]; then
        break                 # Exit loop
    fi
    echo $i
done

# Output: 1 2 4 5 6 7
```

---

## Functions

### Function Definition and Calling

```bash
# Syntax 1: function keyword
function greet() {
    echo "Hello, $1!"
}

# Syntax 2: just name (POSIX)
goodbye() {
    echo "Goodbye, $1!"
}

# Calling functions
greet "Alice"              # Hello, Alice!
goodbye "Bob"              # Goodbye, Bob!
```

### Parameters and Return Values

```bash
# Function with parameters
add() {
    local NUM1=$1
    local NUM2=$2
    echo $((NUM1 + NUM2))
}

RESULT=$(add 10 20)        # 30
echo $RESULT

# Explicit return value (0-255)
is_number() {
    if [[ $1 =~ ^[0-9]+$ ]]; then
        return 0           # Success
    else
        return 1           # Failure
    fi
}

if is_number "42"; then
    echo "It's a number"
else
    echo "Not a number"
fi

# Capturing output vs return
multiply() {
    echo $((($1) * ($2)))
}

RESULT=$(multiply 5 3)     # Capture output: 15

# Check exit status
if multiply 5 3 > /dev/null; then
    echo "Success"
fi
```

### Local Variables

```bash
GLOBAL="I am global"

function demo() {
    local LOCAL="I am local"
    GLOBAL="Modified globally"
    echo "Local: $LOCAL"
    echo "Global: $GLOBAL"
}

demo
echo $GLOBAL               # Modified globally
echo $LOCAL                # (empty - doesn't exist)
```

### Variable Functions

**Theory**: Functions can be treated as first-class objects and called indirectly.

```bash
# Function names in variables
log() {
    echo "[LOG] $1"
}

FUNC_NAME="log"
$FUNC_NAME "Test message"   # Calls log function

# Conditional function selection
operate() {
    local OP=$1
    local A=$2
    local B=$3
    
    case $OP in
        add)
            return $((A + B))
            ;;
        sub)
            return $((A - B))
            ;;
    esac
}
```

---

## Input/Output

### Echo and Print

```bash
# echo variations
echo "Simple text"
echo -n "No newline"        # -n: suppress newline
echo -e "Line1\nLine2"      # -e: interpret escapes
echo -E "No escape"         # -E: disable escapes (default)

# printf (more control)
printf "%s\n" "Text"        # String
printf "%d\n" 42            # Integer
printf "%.2f\n" 3.14159     # Float with 2 decimals
printf "%10s\n" "right"     # Right-aligned, 10 chars
printf "%-10s\n" "left"     # Left-aligned, 10 chars

# String formatting
NAME="Alice"
AGE=30
printf "%s is %d years old\n" "$NAME" "$AGE"
```

### Reading Input

```bash
# read command
echo "Enter your name:"
read NAME
echo "Hello, $NAME"

# Read multiple variables
read FIRST LAST
echo "Name: $FIRST $LAST"

# Read without prompting (uses IFS)
read -p "Enter age: " AGE

# Read into array
read -a ARR
echo "${ARR[0]}"

# Read without backslash interpretation
read -r TEXT

# Timeout for read
read -t 5 INPUT            # Wait 5 seconds

# Silent input (password)
read -sp "Password: " PASS
echo ""                    # New line after input
```

### Redirection

**Theory**: Redirection changes where input comes from and output goes to.

```bash
# Output redirection
echo "Hello" > file.txt     # Overwrite
echo "World" >> file.txt    # Append

# Input redirection
cat < file.txt
sort < unsorted.txt

# Redirect both stdout and stderr
command > output.log 2>&1   # 2>&1: stderr to stdout

# Redirect only stderr
command 2> error.log

# Discard output
command > /dev/null
command 2> /dev/null

# Here document (multiline input)
cat << EOF
Line 1
Line 2
EOF

# Here string
cat <<< "Single line input"
```

### Pipes

```bash
# Basic pipe
ls -la | grep ".txt"
cat file.txt | wc -l       # Line count

# Multiple pipes
cat data.txt | sort | uniq | wc -l

# Piping to while
cat list.txt | while read LINE; do
    echo "Processing: $LINE"
done

# Process substitution
diff <(ls dir1) <(ls dir2)
```

---

## File Operations

### File and Directory Navigation

```bash
# Current directory
pwd                        # Print working directory
ls                         # List files
ls -la                     # List all with details
cd /path/to/dir           # Change directory
cd ~                       # Go to home
cd -                       # Go to previous directory

# Directory operations
mkdir newdir               # Create directory
mkdir -p a/b/c             # Create nested
rmdir emptydir             # Remove empty directory
rm -r directory            # Remove with contents
```

### File Operations

```bash
# Create/copy/move
touch newfile.txt          # Create empty file
cp source.txt dest.txt     # Copy file
cp -r srcdir/ destdir/     # Copy directory
mv oldname.txt newname.txt # Rename/move
rm file.txt                # Delete file
rm -f file.txt             # Force delete

# File permissions
chmod +x script.sh         # Add execute permission
chmod 755 script.sh        # rwxr-xr-x
chmod u=rwx,g=rx,o=rx script.sh

chown user:group file.txt  # Change owner
chgrp group file.txt       # Change group
```

### File Viewing

```bash
# View entire file
cat file.txt
cat file1.txt file2.txt    # Concatenate multiple

# View with line numbers
cat -n file.txt
nl file.txt

# View first/last lines
head file.txt              # First 10 lines
head -20 file.txt          # First 20 lines
tail file.txt              # Last 10 lines
tail -f file.txt           # Follow file (watch changes)

# View in pages
less file.txt              # Interactive pager
more file.txt              # Simpler pager

# Check file type
file filename.txt
```

### File Comparison

```bash
# Compare files
diff file1.txt file2.txt
diff -u file1.txt file2.txt # Unified format

# Compare with context
diff -c file1.txt file2.txt

# Checksum
md5sum file.txt
sha256sum file.txt
```

---

## Text Processing

### Grep - Pattern Matching

```bash
# Basic search
grep "pattern" file.txt

# Case-insensitive
grep -i "Pattern" file.txt

# Invert match (lines NOT matching)
grep -v "pattern" file.txt

# Show line numbers
grep -n "pattern" file.txt

# Recursive search in directory
grep -r "pattern" .

# Count matches
grep -c "pattern" file.txt

# Show context
grep -B 2 -A 2 "pattern" file.txt  # 2 lines before and after
grep -C 3 "pattern" file.txt       # 3 lines before and after

# Extended regex
grep -E "[0-9]{3}-[0-9]{4}" file.txt

# Show matched part only
grep -o "pattern" file.txt
```

### Sed - Stream Editor

**Detailed Theory**:
Sed is a **non-interactive editor** - it processes streams of text line-by-line without user interaction. Understanding its execution model is crucial:

**Sed Execution Model:**
1. Read one line into memory (pattern space)
2. Apply all commands to that line
3. Print the pattern space (unless -n flag)
4. Clear pattern space, read next line
5. Repeat until EOF

This differs from vim/nano where you're editing a file in memory.

```bash
# Basic substitution
# Syntax: s/pattern/replacement/flags
sed 's/old/new/' file.txt      # Replace first occurrence per line
sed 's/old/new/g' file.txt     # Replace all occurrences (g = global)
sed 's/old/new/2' file.txt     # Replace only 2nd occurrence

# Case-insensitive
sed 's/old/new/gi' file.txt

# Address ranges (which lines to apply to)
sed '5s/old/new/' file.txt     # Only line 5
sed '5,10s/old/new/' file.txt  # Lines 5-10
sed '$s/old/new/' file.txt     # Last line ($)
sed '/pattern/s/old/new/' file.txt  # Lines matching pattern

# Delete lines
sed '10d' file.txt             # Delete line 10
sed '5,10d' file.txt           # Delete lines 5-10
sed '/pattern/d' file.txt      # Delete lines matching pattern
sed '/^$/d' file.txt           # Delete empty lines

# Print only specific lines (with -n flag)
sed -n '10p' file.txt          # Print line 10 only
sed -n '5,10p' file.txt        # Print lines 5-10
sed -n '/pattern/p' file.txt   # Print matching lines

# In-place editing
sed -i 's/old/new/g' file.txt  # Modifies file directly
sed -i.bak 's/old/new/g' file.txt  # Creates backup (.bak)

# Hold space (advanced - memory for complex operations)
sed -e 's/old/new/' -e 's/foo/bar/' file.txt  # Multiple operations

# Common regex metacharacters in sed
sed 's/\.txt/.log/' file.txt   # Escape special chars: \.
sed 's/[0-9]/X/g' file.txt     # Character class
sed 's/^/PREFIX /' file.txt    # Add prefix (^ = line start)
sed 's/$/ SUFFIX/' file.txt    # Add suffix ($ = line end)

# Backreferences (capture and reuse)
sed 's/\([a-z]*\) \([0-9]*\)/\2-\1/' file.txt  # Reorder: number-word
```

**Why Sed is Powerful:**
```bash
# One-liner log processing
tail -f app.log | sed 's/ERROR/[ERROR]/g'    # Highlight errors

# Configuration file update
sed -i 's/^debug=false/debug=true/' config.ini

# Remove comments and blank lines
sed -e 's/#.*//' -e '/^$/d' script.sh

# Transform data format
echo -e "1,2,3\n4,5,6" | sed 's/,/-/g'  # CSV to TSV-like
```

**Keypoints:**
- Sed processes input line-by-line without keeping whole file in memory
- Pattern space is current line being processed
- `/pattern/` matches lines; `address` specifies which lines
- `s/from/to/` substitutes (g flag for all occurrences)
- `d` deletes lines; `p` prints lines
- `-n` suppresses automatic printing
- `-i` edits file in-place (careful!)
- Regex requires escaping: `\.` for literal dot
- Sed is most powerful for text substitution tasks

### Awk - Text Analysis and Processing

**Detailed Theory**:
Awk is a **complete programming language for text processing**. It's record-oriented and works with fields, making it ideal for structured data.

**Awk Execution Model:**
1. Read input line by line (records)
2. Split each line into fields (separated by FS - field separator)
3. Process each record through pattern-action rules
4. `BEGIN` block executes before processing
5. `END` block executes after all processing

```bash
# Basic structure
awk 'BEGIN {initialize} /pattern/ {action} END {finalize}' file.txt

# Field access
echo "Alice 30 Engineer" | awk '{print $1}'    # Alice (1st field)
echo "Alice 30 Engineer" | awk '{print $2}'    # 30 (2nd field)
echo "Alice 30 Engineer" | awk '{print $NF}'   # Engineer (last field)
echo "Alice 30 Engineer" | awk '{print NF}'    # 3 (number of fields)

# Field separator (default: whitespace)
echo "name,age,job" | awk -F',' '{print $1}'   # name
echo "a:b:c" | awk -F':' '{print $2}'          # b

# BEGIN and END blocks
awk 'BEGIN {print "Starting"}
     {print}
     END {print "Done"}' file.txt

# Pattern matching
awk '/error/ {print}' app.log                 # Print lines with "error"
awk '/error/ {count++} END {print count}' app.log  # Count errors

# Numeric comparisons
awk '$2 > 25 {print $1}' employees.txt        # Names of people over 25
awk '$3 == "Engineer" {count++} 
     END {print "Engineers: " count}' employees.txt

# Variables and calculations
awk '{sum += $2} END {print "Total: " sum}' numbers.txt
awk '{sum += $2; count++} 
     END {print "Average: " sum/count}' numbers.txt

# String functions
awk '{print tolower($0)}' file.txt            # Convert to lowercase
awk '{print substr($1, 1, 3)}' file.txt       # First 3 chars
awk '{print index($0, "pattern")}' file.txt   # Position of pattern
awk '{gsub(/old/, "new"); print}' file.txt    # Global substitute

# Formatted output
awk '{printf "%10s %5d %10s\n", $1, $2, $3}' employees.txt

# Array operations
awk '{names[$1] = $2} 
     END {for (name in names) print name, names[name]}' data.txt

# Complex example: average per group
awk '{sum[$1] += $3; count[$1]++} 
     END {for (group in sum) 
              print group, sum[group]/count[group]}' data.txt
```

**Why Awk is Powerful:**
```bash
# One-liner data transformation
ps aux | awk '{print $1, $3}' | head         # Show user and CPU usage

# Log analysis
cat app.log | awk '/ERROR/ {print $1}' | sort | uniq -c

# CSV processing
awk -F',' '{print $2 ":" $3}' data.csv       # Extract and reformat fields

# Configuration parsing
awk -F'=' '/^key=/ {print $2}' config.ini    # Extract values
```

**Awk vs Sed vs Grep:**
```bash
# These are different tools for different jobs
grep "pattern" file.txt     # Find lines matching pattern
sed 's/old/new/g' file.txt  # Transform text systematically
awk '{print $2}' file.txt   # Analyze structured data
```

**Keypoints:**
- Awk is **record and field oriented** (designed for structured text)
- Each line is a record; whitespace-separated values are fields
- `$1`, `$2`, etc. are field references; `$0` is whole line
- `NF` = number of fields; `NR` = number of records (line number)
- `-F` option sets field separator
- `BEGIN`/`END` blocks run before/after processing
- Variables don't need declaration (auto-initialized)
- Arrays are associative (key-value pairs)
- Pattern-action pairs: match pattern, then execute action
- Function calls available: length(), substr(), index(), gsub(), etc.

---

## Advanced Concepts

### Arrays

**Theory**: Bash arrays are indexed collections that can hold multiple values.

```bash
# Indexed array
FRUITS[0]="apple"
FRUITS[1]="banana"
FRUITS[2]="orange"

# Or declare and initialize
FRUITS=("apple" "banana" "orange")

# Access array
echo ${FRUITS[0]}          # apple
echo ${FRUITS[@]}          # All elements
echo ${FRUITS[*]}          # All as single string
echo ${#FRUITS[@]}         # Array length

# Iterate
for FRUIT in "${FRUITS[@]}"; do
    echo $FRUIT
done

# Associative array (key-value)
declare -A PERSON
PERSON[name]="Alice"
PERSON[age]=30
PERSON[job]="Engineer"

echo ${PERSON[name]}       # Alice
echo ${PERSON[@]}          # All values
echo ${!PERSON[@]}         # All keys

# Iterate over associative array
for KEY in "${!PERSON[@]}"; do
    echo "$KEY: ${PERSON[$KEY]}"
done
```

### String Matching and Regex

```bash
# Simple pattern matching
if [[ $FILENAME == *.txt ]]; then
    echo "Text file"
fi

# Regular expression matching
if [[ $EMAIL =~ ^[a-z]+@[a-z]+\.[a-z]+$ ]]; then
    echo "Valid email"
fi

# Capture groups (Bash 3.0+)
if [[ $DATE =~ ([0-9]{4})-([0-9]{2})-([0-9]{2}) ]]; then
    YEAR=${BASH_REMATCH[1]}
    MONTH=${BASH_REMATCH[2]}
    DAY=${BASH_REMATCH[3]}
fi
```

### Error Handling

**Theory**: Proper error handling makes scripts robust and maintainable.

```bash
# Check exit status
COMMAND
if [[ $? -eq 0 ]]; then
    echo "Success"
else
    echo "Failed with code $?"
fi

# Logical operators for error handling
cd /important/dir || exit 1
rm -r files || { echo "Delete failed"; exit 2; }

# set options for strict mode
set -e                     # Exit on error
set -u                     # Error on undefined variable
set -o pipefail           # Pipe errors propagate

# Trap errors
trap 'echo "Error on line $LINENO"' ERR

# Cleanup on exit
cleanup() {
    echo "Cleaning up..."
    rm -f /tmp/tempfile
}
trap cleanup EXIT

# Custom error handling
check_command() {
    if ! command -v "$1" &> /dev/null; then
        echo "Error: $1 is not installed"
        exit 1
    fi
}

check_command "git"
```

### Command Substitution

```bash
# Using $()
FILES=$(ls *.txt)
echo "Found: $FILES"

# Using backticks (older style)
FILES=`ls *.txt`

# Nested substitution
echo $(echo $(pwd))

# In command position
wc -l $(find . -name "*.txt")

# Arithmetic substitution
RESULT=$((2 + 2))
```

### Process Substitution

```bash
# Run command and use output as file
diff <(ls dir1) <(ls dir2)

# Write to multiple files simultaneously
tee file1.txt file2.txt <<< "content"

# Read from command
while read LINE; do
    echo "Line: $LINE"
done < <(cat file.txt)
```

### Background Processes

```bash
# Run in background
long_command &

# Get process ID
long_command &
PID=$!
wait $PID               # Wait for completion

# Run multiple in parallel
task1 &
task2 &
task3 &
wait                    # Wait for all

# Job control
jobs                    # List background jobs
fg %1                   # Bring job 1 to foreground
bg %2                   # Resume job 2 in background
```

---

## Core Concepts Deep Dive

### 1. Shell Execution Model and Process Management

**Detailed Theory:**
The shell operates on a fundamental principle: every command spawns a new process. Understanding this is crucial for writing efficient scripts. When you execute a command, the shell:

1. **Forks** - Creates a new process (child) from the parent shell
2. **Execs** - Replaces the child process image with the command
3. **Waits** - Parent waits for child to complete (unless backgrounded)

This model affects:
- **Exit codes**: Each process returns a code (0=success, 1-255=failure)
- **Environment variables**: Child processes inherit parent's variables
- **File descriptors**: Standard input/output/error streams
- **Process ID (PID)**: Unique identifier for tracking processes

**Practical Implications:**
```bash
# Exit code checking
ls /nonexistent
echo $?                          # Output: 2 (not found)

ls /home
echo $?                          # Output: 0 (success)

# Command pipeline creates multiple processes
cat file.txt | grep pattern | wc -l
# Three processes: cat, grep, wc
# Each connected via pipes (unnamed pipes/FIFOs)

# Subshells (new shell instance)
(cd /tmp; pwd)                  # Subshell - doesn't affect current directory
echo $PWD                       # Still original directory

# Background processes
long_command &
echo "Running in background"
wait                            # Wait for all background jobs
```

**Keypoints:**
- Each command is a separate process (except builtins)
- Exit codes are critical for error detection (check with `$?`)
- Pipes connect processes; data flows between stdin/stdout
- Subshells create isolated environments
- Background processes don't block shell execution
- Variable changes in subshells don't affect parent shell

---

### 2. Variable Expansion and Word Splitting

**Detailed Theory:**
Variable expansion is one of the most complex shell features. The shell performs expansion in a specific order, and understanding this prevents bugs:

**Expansion Order:**
1. **Brace Expansion** - `{a,b,c}` or `{1..5}`
2. **Tilde Expansion** - `~` becomes home directory
3. **Parameter Expansion** - `$VAR` or `${VAR}`
4. **Command Substitution** - `$(...)` or `` `...` ``
5. **Arithmetic Expansion** - `$((...))`
6. **Word Splitting** - Split on IFS (whitespace by default)
7. **Pathname Expansion** - Globbing (`*.txt`)
8. **Quote Removal** - Remove unescaped quotes

**Why This Matters:**
```bash
# Without quotes - word splitting occurs
VAR="hello world"
echo $VAR                       # Expands to: hello world (2 arguments to echo)

# With quotes - prevents word splitting
echo "$VAR"                     # Expands to: hello world (1 argument to echo)

# Glob expansion
FILES="*.txt"
ls $FILES                       # Glob expands to actual files

# Double vs single quotes
echo "$VAR"                     # Variables expanded
echo '$VAR'                     # Literal $VAR

# IFS (Internal Field Separator)
IFS=:
read A B C <<< "1:2:3"
echo $A $B $C                   # 1 2 3
```

**Keypoints:**
- Expansion occurs in a specific, predictable order
- Word splitting happens after expansion (not before)
- Always quote variables to prevent unwanted splitting
- Single quotes prevent all expansions; double quotes allow some
- IFS controls where word splitting occurs
- Glob patterns expand before command execution
- Empty expansions create empty strings, not "no argument"

---

### 3. Quoting and Escaping Mechanics

**Detailed Theory:**
Proper quoting is essential for handling special characters and spaces. The three levels provide different protection:

```bash
# Single quotes - strongest protection (literal everything)
echo 'The $VAR is ${VAR} $(cmd)'      # Prints literally

# Double quotes - moderate protection (allows $, `, \)
VAR="value"
echo "The $VAR"                       # Expands: The value

# No quotes - weakest (all expansions and splitting)
echo The $VAR                         # Splits on spaces

# Escaping individual characters
echo \$VAR                            # Prints: $VAR
echo "Path: C:\\Users\\Name"          # Backslash escaping
```

**Keypoints:**
- Single quotes: No expansion, literal text only
- Double quotes: Allow expansion of $, `, \, but not glob
- No quotes: Full expansion and word splitting
- Escape sequences with backslash work in double quotes
- Quotes can be nested using single and double

---

### 4. Redirection and File Descriptors

**Detailed Theory:**
Every process has three standard file descriptors (FDs):

| FD | Name | Default |
|----|------|---------|
| 0 | stdin | Keyboard |
| 1 | stdout | Terminal |
| 2 | stderr | Terminal |

Redirection changes where these point to:

```bash
# Redirect FD 1 (stdout) to file
command > output.txt              # Same as: command 1> output.txt

# Redirect FD 2 (stderr) to file
command 2> errors.txt

# Redirect both stdout and stderr
command > output.txt 2>&1         # Redirect stderr (2) to stdout (1)
command &> output.txt             # Same as above (Bash only)

# Append instead of overwrite
command >> output.txt             # Append stdout
command 2>> errors.txt            # Append stderr

# Discard output
command > /dev/null               # Discard stdout
command 2> /dev/null              # Discard stderr

# Redirect input
sort < unsorted.txt               # Same as: sort 0< unsorted.txt
```

**Keypoints:**
- FD 0=stdin, 1=stdout, 2=stderr
- `>` redirects stdout (FD 1), `<` redirects stdin (FD 0)
- `2>` explicitly redirects stderr
- `2>&1` redirects stderr to stdout (for combining)
- `>>` appends instead of overwriting
- `/dev/null` is a black hole for discarding output
- Redirection is processed before command execution

---

### 5. Command Substitution and Pipeline Processing

**Detailed Theory:**
Two mechanisms to use command output:

```bash
# Command substitution - captures output
RESULT=$(command)                 # Modern syntax
RESULT=`command`                  # Legacy backticks

# Key difference: nested substitution
RESULT=$(echo $(date))            # Nesting works
RESULT=`echo \`date\``            # Backticks need escaping

# Pipelines - connects processes
command1 | command2 | command3

# Each process runs CONCURRENTLY
# Not sequentially!
cat huge_file.txt | grep pattern | wc -l
# cat starts first, grep reads as cat outputs
# wc reads as grep outputs
```

**Keypoints:**
- `$()` is preferred over backticks (clearer, nestable)
- Command substitution captures output into a string
- Pipeline processes run concurrently, not sequentially
- Pipe fails if ANY command fails (unless `set -o pipefail`)
- Exit code of pipeline is exit code of LAST command
- Each pipeline stage is a subshell with inherited FDs

---

## Best Practices

### 1. **Use Meaningful Names**
```bash
# Bad
x=10
f() { echo $x; }

# Good
MAX_RETRIES=10
get_configuration() { echo $MAX_RETRIES; }
```

### 2. **Quote Variables**
```bash
# Risky - word splitting
echo $FILENAME

# Safe
echo "$FILENAME"

# Safest for arrays
echo "${FILENAME[@]}"
```

### 3. **Use [[ ]] Instead of [ ]**
```bash
# Better
if [[ $VAR =~ pattern ]]; then
    ...
fi

# Works but less safe
if [ "$VAR" = "value" ]; then
    ...
fi
```

### 4. **Comment Your Code**
```bash
#!/bin/bash
# Process log files and extract errors
# Usage: ./process_logs.sh <log_file>

LOGFILE=$1

# Check if file exists
if [[ -f "$LOGFILE" ]]; then
    grep "ERROR" "$LOGFILE"
fi
```

### 5. **Use Functions for Reusability**
```bash
# Log message to file
log_message() {
    local LEVEL=$1
    local MESSAGE=$2
    echo "$(date +'%Y-%m-%d %H:%M:%S') [$LEVEL] $MESSAGE" >> app.log
}

log_message "INFO" "Application started"
log_message "ERROR" "Something went wrong"
```

### 6. **Input Validation**
```bash
#!/bin/bash

validate_input() {
    if [[ -z "$1" ]]; then
        echo "Error: Input is empty"
        return 1
    fi
    return 0
}

if validate_input "$1"; then
    echo "Valid input: $1"
fi
```

### 7. **Use Local Variables in Functions**
```bash
# Good
increment() {
    local VALUE=$1
    ((VALUE++))
    echo $VALUE
}

# Pollutes global namespace
bad_increment() {
    VALUE=$1
    ((VALUE++))
    echo $VALUE
}
```

### 8. **Exit Codes**
```bash
#!/bin/bash
# Proper exit codes
process_file() {
    if [[ ! -f "$1" ]]; then
        echo "Error: File not found" >&2
        return 1
    fi
    return 0
}

process_file "$1" || exit 1
```

### 9. **Use ShellCheck**
```bash
# Install ShellCheck (lint tool)
shellcheck script.sh

# Fix warnings and errors before deployment
```

### 10. **Modular Structure**
```bash
#!/bin/bash
source ./config.sh
source ./functions.sh
source ./validators.sh

main() {
    process_data
    generate_report
}

main "$@"
```

---

## Common Patterns

### Looping Through Files
```bash
# Safe for filenames with spaces
find . -name "*.txt" -type f | while read -r FILE; do
    echo "Processing: $FILE"
done

# Or use for loop with globbing
for FILE in *.txt; do
    [[ -f "$FILE" ]] && echo "Processing: $FILE"
done
```

### Reading Configuration Files
```bash
# Load configuration
load_config() {
    local CONFIG_FILE=$1
    if [[ -f "$CONFIG_FILE" ]]; then
        source "$CONFIG_FILE"
    else
        echo "Error: Config file not found" >&2
        return 1
    fi
}
```

### Retry Logic
```bash
# Retry with exponential backoff
retry_command() {
    local MAX_ATTEMPTS=5
    local TIMEOUT=1
    local ATTEMPT=1
    
    while [[ $ATTEMPT -le $MAX_ATTEMPTS ]]; do
        if "$@"; then
            return 0
        fi
        echo "Attempt $ATTEMPT failed, retrying..."
        sleep $TIMEOUT
        TIMEOUT=$((TIMEOUT * 2))
        ((ATTEMPT++))
    done
    
    return 1
}

# Usage
retry_command curl https://api.example.com/data
```

### Argument Parsing
```bash
#!/bin/bash
# Parse named arguments

parse_arguments() {
    while [[ $# -gt 0 ]]; do
        case $1 in
            -f|--file)
                FILE=$2
                shift 2
                ;;
            -v|--verbose)
                VERBOSE=true
                shift
                ;;
            *)
                echo "Unknown option: $1"
                return 1
                ;;
        esac
    done
}

parse_arguments "$@"
```

---

## Interview Questions and Answers

### 1. What's the difference between `$*` and `$@` in a shell script?

**Question**: Explain when to use `$*` vs `$@` and provide an example where they differ.

**Answer**:
- `$*` expands to all arguments as a **single word**
- `$@` expands to all arguments as **separate words**

```bash
# Script: test_args.sh
function show_args() {
    echo "Using \$@:"
    for arg in "$@"; do
        echo "  [$arg]"
    done
    
    echo "Using \$*:"
    for arg in $*; do
        echo "  [$arg]"
    done
}

# Call: ./test_args.sh "hello world" "goodbye world"

# Output with $@:
#   [hello world]
#   [goodbye world]

# Output with $*:
#   [hello]
#   [world]
#   [goodbye]
#   [world]
```

**Key Point**: Always use `"$@"` to preserve argument boundaries.

**Follow-up**: What happens with `$*` vs `$@` without quotes?
- `$*` and `$*` (unquoted) both word-split, but `"$@"` preserves arguments.

---

### 2. What does `set -e` do and when should you use it?

**Question**: Explain the behavior of `set -e` and describe a scenario where it's helpful and one where it's problematic.

**Answer**:
`set -e` causes the script to **exit immediately if any command exits with non-zero status**.

```bash
#!/bin/bash
set -e  # Exit on error

cd /nonexistent          # Script exits here, never continues
echo "Never executes"
```

**When to Use**:
```bash
#!/bin/bash
set -e
set -u  # Error on undefined variables
set -o pipefail  # Pipe failures propagate

# Safe script - exits on any error
database_backup
upload_to_cloud
cleanup_temp_files
```

**When NOT to Use**:
```bash
#!/bin/bash
# Bad:
set -e
if command_that_might_fail; then  # Script exits if fails
    echo "Success"
fi

# Better:
if command_that_might_fail; then
    echo "Success"
else
    echo "Expected failure"
fi
```

**Gotchas**:
```bash
set -e

# These don't trigger exit:
false && echo "Never runs"    # && short-circuits
false || echo "Runs"          # || handles error
if false; then echo; fi       # if explicitly handles error

# This DOES trigger exit:
false | cat                   # Middle of pipeline fails
```

---

### 3. How would you create a robust error handling pattern in a bash script?

**Question**: Write a production-ready error handling pattern.

**Answer**:
```bash
#!/bin/bash
set -euo pipefail
IFS=$'\n\t'

# Setup
SCRIPT_NAME="$(basename "$0")"
LOG_FILE="/var/log/${SCRIPT_NAME%.sh}.log"

# Error handler
error_exit() {
    local line_number=$1
    local error_code=$2
    echo "ERROR [$SCRIPT_NAME:$line_number] Command exited with code $error_code" >&2
    exit "$error_code"
}

# Trap errors
trap 'error_exit ${LINENO} $?' ERR

# Cleanup handler
cleanup() {
    echo "Cleaning up..." >&2
    rm -f /tmp/tempfile_$$
}

trap cleanup EXIT

# Main logic
log_message() {
    echo "[$(date +'%Y-%m-%d %H:%M:%S')] $*" | tee -a "$LOG_FILE"
}

log_message "Script started"

# Your code here
echo "Processing..." >> "$LOG_FILE"

log_message "Script completed successfully"
```

**Key Elements**:
- `set -euo pipefail` - Strict mode
- `trap 'action' ERR` - Error handler
- `trap 'cleanup' EXIT` - Always runs
- Logging - Track execution
- Line numbers - Debugging

---

### 4. What's the difference between sourcing a script (`.`) and executing it (`bash`)?

**Question**: Explain when you'd use each approach and what the implications are.

**Answer**:

| Aspect | Source (.) | Execute (bash) |
|--------|-----------|----------------|
| Scope | Same shell | Subshell |
| Variables | Accessible after | Lost after |
| Exports | Affects current shell | Isolated |
| $0 | Script path | Subshell PID |
| Functions | Available | Not available |

```bash
# script.sh
VAR="original"
VAR="modified"

# When sourcing:
source script.sh
echo $VAR                    # modified (affected)

# When executing:
bash script.sh
echo $VAR                    # original (unchanged)

# Practical use: configuration files
source /etc/app.conf         # Load config into current shell
```

**When to Source**:
- Loading configuration files
- Importing functions/libraries
- Setting environment variables
- Shell customization (.bashrc, .zshrc)

**When to Execute**:
- Running standalone tools
- Isolating changes
- Running with different permissions
- Script safety (errors don't affect caller)

---

### 5. How would you parse command-line arguments robustly?

**Question**: Write a function to parse both positional and optional arguments.

**Answer**:
```bash
#!/bin/bash

# Setup defaults
VERBOSE=false
OUTPUT_FILE=""
INPUT_FILE=""

# Parse arguments
while [[ $# -gt 0 ]]; do
    case $1 in
        -v|--verbose)
            VERBOSE=true
            shift
            ;;
        -o|--output)
            OUTPUT_FILE="$2"
            shift 2                # Skip both flag and value
            ;;
        -i|--input)
            INPUT_FILE="$2"
            shift 2
            ;;
        -h|--help)
            echo "Usage: $0 [options] file..."
            exit 0
            ;;
        --)
            shift                  # End of options
            break
            ;;
        -*)
            echo "Unknown option: $1" >&2
            exit 1
            ;;
        *)
            # Positional argument
            break
            ;;
    esac
done

# Remaining arguments
POSITIONAL_ARGS=("$@")

# Validate
if [[ -z "$INPUT_FILE" ]]; then
    echo "Error: --input required" >&2
    exit 1
fi

# Usage
[[ $VERBOSE == true ]] && echo "Processing: $INPUT_FILE"
```

**Key Techniques**:
- `while [[ $# -gt 0 ]]` - Loop through all arguments
- `shift` and `shift 2` - Remove processed arguments
- `case` statement - Pattern matching
- `--` - End of options marker
- Validate required arguments

---

### 6. What's the difference between pipes and process substitution?

**Question**: When would you use `<(...)` vs `|` and what are the implications?

**Answer**:

| Feature | Pipe `\|` | Process Sub `<(...)` |
|---------|-----------|-------------------|
| Connection | Sequential chains | Parallel access |
| Input/output | stdin/stdout | File descriptor |
| Syntax | `cmd1 \| cmd2` | `cmd <(cmd2)` |
| Flexibility | Linear only | Non-linear possible |

```bash
# Pipe - linear
cat file.txt | grep pattern | wc -l
# cat → grep → wc (sequential)

# Process substitution - parallel comparison
diff <(ls dir1) <(ls dir2)
# Both ls commands run simultaneously
# diff reads from both file descriptors

# Cannot do with pipes:
diff <(sort file1.txt) <(sort file2.txt)
# Must use process substitution for multiple inputs

# Reading file in while loop without subshell
while read line; do
    COUNT=$((COUNT + 1))
done < <(cat file.txt)

# With pipe - subshell created
cat file.txt | while read line; do
    COUNT=$((COUNT + 1))  # Lost after pipe
done
echo $COUNT               # Still 0
```

**When to Use**:
- **Pipes**: Chaining commands (one output to next input)
- **Process Sub**: Multiple simultaneous inputs or avoiding subshells

---

### 7. How do you handle special characters and spaces in file names?

**Question**: Write a script that safely processes files with spaces and special characters.

**Answer**:
```bash
#!/bin/bash

# Safe file processing
process_files() {
    # Use find with null separator
    find . -maxdepth 1 -type f -print0 | while IFS= read -r -d '' file; do
        echo "Processing: $file"
        # Safe variable expansion
        wc -l "$file"                 # ALWAYS quote
    done
}

# Bad practices:
dangerous() {
    for file in $(ls)                 # Breaks on spaces
    for file in *                     # Breaks on spaces and glob issues
}

# Good practices:
safe() {
    # Array with proper globbing
    local files=( * )
    for file in "${files[@]}"; do
        [[ -f "$file" ]] && echo "$file"
    done
    
    # Find with null separator
    find . -type f -print0 | \
        xargs -0 grep pattern
    
    # While loop with read
    ls -1 | while IFS= read -r line; do
        echo "$line"
    done
}

# Filename variables
FILENAME="my file (1).txt"
ls "$FILENAME"                         # Works
ls $FILENAME                           # FAILS
```

**Golden Rules**:
- Always quote variables: `"$VAR"` not `$VAR`
- Use arrays: `"${ARRAY[@]}"`
- Use find with `-print0` and `xargs -0`
- Avoid unquoted globbing: `$(*)`

---

### 8. What's the difference between `[`, `[[`, and `test`?

**Question**: Explain when to use each and provide examples where they differ.

**Answer**:

```bash
# All three are conditionals, but with differences:

# [ ] - POSIX standard (external command)
test -f file.txt           # Same as [ -f file.txt ]
[ -f file.txt ]

# [[ ]] - Bash specific (keyword)
[[ -f file.txt ]]

# Differences:
VAR="hello world"

# [ ] fails without quotes
[ $VAR = hello ]           # Error: too many arguments

# [[ ]] works without quotes (word splitting prevented)
[[ $VAR = hello ]]         # false (correct)

# Pattern matching only in [[ ]]
[[ $VAR == h* ]]           # true
[ "$VAR" = h* ]            # false (literal match)

# Regex only in [[ ]]
[[ $VAR =~ ^h.*d$ ]]       # true
[ "$VAR" =~ pattern ]      # Error in POSIX

# Portability:
# Use [ ] for scripts that must run on sh
# Use [[ ]] for bash-specific scripts

# [ ] requires spaces:
[$VAR=value]               # Error
[[ $VAR=value ]]           # Error (different - no assignment in condition)
```

**Recommendation**: Use `[[ ]]` in bash scripts; use `[ ]` only for POSIX portability.

---

### 9. How would you implement a retry mechanism with exponential backoff?

**Question**: Write a retry function for unreliable network calls.

**Answer**:
```bash
#!/bin/bash

# Retry with exponential backoff
retry_with_backoff() {
    local max_attempts=5
    local timeout=1
    local attempt=1
    
    while [[ $attempt -le $max_attempts ]]; do
        if "$@"; then
            echo "Success on attempt $attempt" >&2
            return 0
        fi
        
        if [[ $attempt -lt $max_attempts ]]; then
            echo "Attempt $attempt failed, retrying in ${timeout}s..." >&2
            sleep "$timeout"
            timeout=$((timeout * 2))  # Exponential backoff
        fi
        
        ((attempt++))
    done
    
    echo "Failed after $max_attempts attempts" >&2
    return 1
}

# Usage:
retry_with_backoff curl -f https://api.example.com/data
retry_with_backoff wget https://example.com/file.tar.gz
retry_with_backoff ssh user@host 'important command'

# With custom max attempts:
retry_with_backoff() {
    local max_attempts=${2:-5}
    local timeout=1
    local attempt=1
    
    while [[ $attempt -le $max_attempts ]]; do
        if "$@"; then
            return 0
        fi
        if [[ $attempt -lt $max_attempts ]]; then
            sleep "$timeout"
            timeout=$((timeout * 2))
        fi
        ((attempt++))
    done
    return 1
}

# Usage:
retry_with_backoff curl https://api.example.com/data 3
```

---

### 10. What are common pitfalls in shell scripting and how do you avoid them?

**Question**: List 5 common mistakes and how to prevent them.

**Answer**:

```bash
# 1. Unquoted variables - word splitting and globbing
# WRONG:
echo $VAR                    # Splits on spaces
ls $PATTERN                  # Globs *
# RIGHT:
echo "$VAR"
ls "$PATTERN"

# 2. Not checking command existence
# WRONG:
python script.py             # May not exist
# RIGHT:
if ! command -v python &> /dev/null; then
    echo "Python not found" >&2
    exit 1
fi
python script.py

# 3. Using [ ] without quotes
# WRONG:
if [ $VAR = value ]; then    # Breaks with spaces
# RIGHT:
if [[ $VAR = value ]]; then
if [ "$VAR" = value ]; then

# 4. Not using local in functions
# WRONG:
my_func() {
    VAR="local"              # Modifies global
}
# RIGHT:
my_func() {
    local VAR="local"
}

# 5. Not handling empty input
# WRONG:
for item in $@; do           # Fails if no args
# RIGHT:
for item in "$@"; do
    [[ -n "$item" ]] && echo "$item"
done

# 6. Ignoring exit codes
# WRONG:
grep pattern file.txt        # Returns 1 if no match
echo "Done"
# RIGHT:
if grep -q pattern file.txt; then
    echo "Found"
else
    echo "Not found"
fi

# Bonus: Use ShellCheck (linter)
shellcheck script.sh         # Catches many issues
```

---

## Resources and References

- GNU Bash Manual: https://www.gnu.org/software/bash/manual/
- ShellCheck: https://www.shellcheck.net/
- Regular Expressions: https://www.regular-expressions.info/
- Linux man pages: https://man7.org/
