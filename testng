# TestNG Complete Notes and Theory

## Table of Contents

1. [Introduction to TestNG](#introduction-to-testng)
2. [Core Concepts](#core-concepts)
3. [Setup and Installation](#setup-and-installation)
4. [Annotations - Complete Guide](#annotations---complete-guide)
5. [Test Organization](#test-organization)
6. [Assertions and Verification](#assertions-and-verification)
7. [Parameterized Testing](#parameterized-testing)
8. [Data Providers](#data-providers)
9. [Test Dependencies](#test-dependencies)
10. [Parallel Execution](#parallel-execution)
11. [Test Grouping](#test-grouping)
12. [Listeners and Reporters](#listeners-and-reporters)
13. [Advanced Topics](#advanced-topics)
14. [Selenium Integration](#selenium-integration)
15. [Best Practices](#best-practices)
16. [Real-World Examples](#real-world-examples)

---

## Introduction to TestNG

### What is TestNG?

**TestNG** (Test Next Generation) is a powerful testing framework for Java inspired by JUnit and NUnit. It's designed to support test automation at multiple levels:
- Unit testing
- Integration testing
- Functional testing
- End-to-end testing

**Key Features:**
- ✅ Flexible annotations for setup/teardown
- ✅ Grouping and prioritization of tests
- ✅ Parameterized testing with multiple data sets
- ✅ Data-driven testing with @DataProvider
- ✅ Parallel execution across multiple threads
- ✅ Test dependencies (execution order control)
- ✅ Powerful reporting and logging
- ✅ Integration with Selenium, Appium, and other tools
- ✅ XML-based test configuration
- ✅ Listener mechanisms for custom reporting

### TestNG vs JUnit

| Feature | TestNG | JUnit 4 | JUnit 5 |
|---------|--------|---------|---------|
| **Annotations** | @Test, @Before/After | @Test, @Before/After | @Test, @Before/After |
| **Test Groups** | ✅ Native support | ❌ No | ❌ No |
| **Prioritization** | ✅ @Test(priority=1) | ❌ No | ❌ No |
| **Parameterization** | ✅ @DataProvider | ❌ Limited | ✅ @ParameterizedTest |
| **Parallel Execution** | ✅ Built-in | ❌ Limited | ⚠️ Complex |
| **Test Dependencies** | ✅ dependsOnMethods | ❌ No | ❌ No |
| **Reporting** | ✅ HTML/XML Reports | ❌ Basic | ❌ Basic |
| **Learning Curve** | Medium | Easy | Medium |
| **Best For** | Complex test automation | Simple unit tests | Modern frameworks |

---

## Core Concepts

### 1. Test Lifecycle

TestNG follows a specific execution lifecycle:

```
Test Suite Start
    ↓
BeforeSuite (once per suite)
    ↓
BeforeTest (per <test> tag)
    ↓
BeforeClass (per test class)
    ↓
BeforeMethod (before each @Test)
    ↓
@Test (actual test method)
    ↓
AfterMethod (after each @Test)
    ↓
AfterClass (after all methods in class)
    ↓
AfterTest (after <test> tag)
    ↓
AfterSuite (once per suite)
    ↓
Test Suite End
```

### 2. Test Annotations

**Common Annotations:**

```java
@Test                // Mark method as test method
@BeforeSuite         // Before entire test suite
@BeforeTest          // Before test in XML
@BeforeClass         // Before all methods in class
@BeforeMethod        // Before each test method
@AfterMethod         // After each test method
@AfterClass          // After all methods in class
@AfterTest           // After test in XML
@AfterSuite          // After entire suite
@DataProvider        // Provide test data
@Parameters          // Pass parameters from XML
```

### 3. Assertions

TestNG uses the `Assert` class from `org.testng.Assert`:

```java
// Basic assertions
Assert.assertEquals(actual, expected);
Assert.assertNotEquals(actual, expected);
Assert.assertTrue(condition);
Assert.assertFalse(condition);
Assert.assertNull(object);
Assert.assertNotNull(object);

// With custom message
Assert.assertEquals(actual, expected, "Custom error message");
Assert.fail("Test failed with message");
```

### 4. Test Report Generation

TestNG automatically generates:
- **HTML Reports**: `test-output/index.html`
- **XML Reports**: `test-output/testng-results.xml`
- **Logging**: Console output captured

---

## Setup and Installation

### Prerequisites

```
Java JDK 8 or higher
Maven or Gradle (build tool)
IDE: IntelliJ IDEA or Eclipse
```

### Maven Setup

**Add Dependency to pom.xml:**

```xml
<dependency>
    <groupId>org.testng</groupId>
    <artifactId>testng</artifactId>
    <version>7.8.1</version>
    <scope>test</scope>
</dependency>

<!-- For Selenium integration -->
<dependency>
    <groupId>org.seleniumhq.selenium</groupId>
    <artifactId>selenium-java</artifactId>
    <version>4.15.0</version>
</dependency>

<!-- For assertions -->
<dependency>
    <groupId>org.testng</groupId>
    <artifactId>testng</artifactId>
    <version>7.8.1</version>
</dependency>
```

### Gradle Setup

```gradle
testImplementation 'org.testng:testng:7.8.1'
testImplementation 'org.seleniumhq.selenium:selenium-java:4.15.0'
```

### Create First Test

```java
import org.testng.Assert;
import org.testng.annotations.Test;

public class FirstTestNGTest {
    
    @Test
    public void testAddition() {
        int result = 2 + 2;
        Assert.assertEquals(result, 4);
    }
}
```

**Run Test:**

```bash
# Maven
mvn test

# IDE: Right-click test class → Run As → TestNG Test
```

---

## Detailed Concept Theory: Basic to Advanced

### 1. Test Execution Model

#### BASIC: What is a Test Execution Model?

A **test execution model** defines how TestNG discovers, organizes, and runs test methods. It's the core mechanism that transforms your test code into actionable test execution.

**Key Components:**
- **Test Discovery**: How TestNG finds test methods (@Test annotation)
- **Ordering**: Sequence in which tests execute (priority, dependencies, groups)
- **Lifecycle**: When setup/teardown methods run
- **Scope**: Class-level vs method-level vs suite-level execution

#### INTERMEDIATE: Internal Execution Flow

```
1. TestNG discovers all test classes and methods
2. Creates test suite from XML or annotations
3. For each test:
   a. Run @BeforeSuite (once)
   b. Run @BeforeTest (per <test> tag)
   c. Run @BeforeClass (per test class)
   d. Run @BeforeMethod
   e. Run @Test method
   f. Run @AfterMethod
   g. Capture result (PASS/FAIL/SKIP)
4. Aggregate results
5. Run @AfterClass, @AfterTest, @AfterSuite
6. Generate reports
```

**Internal Mechanisms:**
- TestNG uses **Reflection API** to scan for annotations
- Maintains a **test queue** prioritized by priority/dependency
- Uses **thread pool** for parallel execution
- Tracks **test results** in in-memory data structures

#### ADVANCED: Optimization and Edge Cases

```java
// Edge case: Circular dependencies
@Test(dependsOnMethods = {"testB"})
public void testA() {}

@Test(dependsOnMethods = {"testA"})
public void testB() {}
// Result: Neither runs (circular dependency detected)

// Optimization: Execution order with groups
@Test(groups = "smoke", priority = 1)
public void testFast() {}

@Test(groups = "regression", priority = 2)
public void testSlow() {}
// TestNG optimizes by running both simultaneously if parallel execution enabled
```

**Keypoints:**
- ✅ TestNG uses priority for ordering within same method/group
- ✅ dependsOnMethods creates hard execution order
- ✅ Circular dependencies are detected and prevented
- ✅ Test execution order is deterministic with same configuration
- ✅ BeforeMethod runs before EACH @Test (not once per class)
- ✅ Reflection scanning happens at suite startup (minimal overhead)

---

### 2. Annotations System

#### BASIC: What are Annotations?

**Annotations** are metadata markers that tell TestNG what role each method plays in test execution. They're Java's way of adding information to code without modifying the code logic itself.

```java
@Test              // This method is a test
@BeforeMethod      // This runs before each test
@DataProvider      // This provides test data
```

**Why Annotations?**
- Declarative: You declare intent, not implementation
- Cleaner code: Separates test logic from lifecycle logic
- Discoverable: TestNG finds annotated methods automatically
- Flexible: Same method can have multiple roles

#### INTERMEDIATE: Annotation Processing

**Execution Sequence:**
```
1. Annotation Discovery (Reflection Scanning)
   - TestNG scans all loaded classes
   - Identifies methods with TestNG annotations
   - Stores metadata in internal data structures

2. Annotation Validation
   - Validates annotation attributes
   - Checks for conflicts (@Test + @DataProvider)
   - Validates method signatures

3. Annotation Interpretation
   - Maps annotations to execution roles
   - Builds execution graph
   - Creates test instance factory

4. Annotation Enforcement
   - Calls annotated methods at appropriate times
   - Handles exceptions and results
   - Logs execution trace
```

**Internal Data Structure:**
```java
// Simplified representation
class TestNGMethod {
    Method method;
    TestNGAnnotation annotation;  // @Test, @Before, etc.
    Map<String, Object> parameters;
    List<String> dependsOnMethods;
    String[] groups;
    int priority;
    // ... more metadata
}
```

#### ADVANCED: Custom Annotation Processors

```java
// Create custom annotation
@Retention(RetentionPolicy.RUNTIME)
@Target(ElementType.METHOD)
public @interface Retry {
    int times() default 3;
    long delay() default 1000;
}

// Implement IAnnotationTransformer for custom processing
public class CustomAnnotationProcessor implements IAnnotationTransformer {
    
    @Override
    public void transform(ITestAnnotation annotation, Class testClass,
            Constructor testConstructor, Method testMethod) {
        
        if(testMethod.isAnnotationPresent(Retry.class)) {
            Retry retry = testMethod.getAnnotation(Retry.class);
            
            // Dynamically modify @Test annotation
            annotation.setRetryAnalyzer(
                new RetryAnalyzer(retry.times(), retry.delay())
            );
        }
    }
}
```

**Keypoints:**
- ✅ Annotations are metadata, not code logic
- ✅ Multiple annotations can be combined on same method
- ✅ Annotation attributes can have default values
- ✅ IAnnotationTransformer allows runtime annotation modification
- ✅ Annotation scanning is thread-safe
- ✅ Annotation validation prevents conflicting configurations

---

### 3. Test Lifecycle Management

#### BASIC: What is Lifecycle?

**Lifecycle** defines the sequence of setup and teardown operations around test execution. It ensures each test runs in a clean, predictable state.

**Three Levels of Lifecycle:**
1. **Suite Level**: Before/After entire test suite
2. **Test Level**: Before/After each `<test>` tag in XML
3. **Class Level**: Before/After all methods in class
4. **Method Level**: Before/After each @Test method

#### INTERMEDIATE: Lifecycle State Management

```java
// TestNG maintains internal state machine
public class LifecycleStateDemo {
    
    // Suite State: Initialized once
    private static SharedResources suiteResources;
    
    // Test State: Initialized per <test> tag
    private TestContext testContext;
    
    // Class State: Initialized per test class
    private WebDriver driver;
    
    // Method State: Fresh for each test method
    private TestData testData;
    
    @BeforeSuite
    public static void beforeSuite() {
        // Suite state initialized (single instance)
        suiteResources = new SharedResources();
    }
    
    @BeforeTest
    public void beforeTest(ITestContext context) {
        // Access suite context
        testContext = context;
    }
    
    @BeforeClass
    public void beforeClass() {
        // Initialize class state
        driver = new ChromeDriver();
    }
    
    @BeforeMethod
    public void beforeMethod() {
        // Fresh state for each test
        testData = new TestData();
    }
    
    @Test
    public void test1() {
        // testData is fresh
        // driver is same instance as test2
    }
    
    @Test
    public void test2() {
        // testData is fresh
        // driver is same instance as test1
    }
    
    @AfterMethod
    public void afterMethod() {
        // Called after each test
        testData = null;
    }
    
    @AfterClass
    public void afterClass() {
        // Called after all methods in class
        driver.quit();
    }
    
    @AfterTest
    public void afterTest() {
        // Called after <test> tag completes
    }
    
    @AfterSuite
    public static void afterSuite() {
        // Called at very end
        suiteResources.cleanup();
    }
}
```

**Lifecycle State Transitions:**
```
BEFORE_SUITE: Shared resources initialized
    ↓
FOR EACH <test> tag:
    ↓
BEFORE_TEST: Test-specific context
    ↓
FOR EACH test class:
    ↓
BEFORE_CLASS: Class-level resources
    ↓
FOR EACH @Test method:
    ↓
BEFORE_METHOD: Method-level setup
    ↓
TEST EXECUTION
    ↓
AFTER_METHOD: Cleanup for this method
    ↓
AFTER_CLASS: Cleanup for class
    ↓
AFTER_TEST: Cleanup for test tag
    ↓
AFTER_SUITE: Final cleanup
```

#### ADVANCED: Lifecycle with Exceptions

```java
public class LifecycleExceptionHandling {
    
    private WebDriver driver;
    
    @BeforeClass
    public void beforeClass() throws Exception {
        driver = new ChromeDriver();
        // If exception here, all methods in this class are SKIPPED
    }
    
    @BeforeMethod
    public void beforeMethod() throws Exception {
        // If exception here, this specific test is SKIPPED
        driver.navigate().to("http://localhost");
    }
    
    @Test
    public void testA() {
        // If this fails, afterMethod still runs
    }
    
    @AfterMethod
    public void afterMethod() {
        // Runs even if test fails (always runs)
        driver.manage().deleteAllCookies();
    }
    
    @AfterClass
    public void afterClass() {
        // Always runs, even if test method fails
        if(driver != null) driver.quit();
    }
}

// Behavior:
// - BeforeClass exception → All methods skipped
// - BeforeMethod exception → Only that test skipped
// - Test exception → Test fails, AfterMethod still runs
// - AfterMethod exception → Test result already recorded
// - AfterClass exception → Test results already recorded
```

**Keypoints:**
- ✅ BeforeClass exception → Entire class skipped
- ✅ BeforeMethod exception → Only that test skipped
- ✅ AfterMethod/AfterClass always run (use finally pattern)
- ✅ Each level has single instance except @BeforeMethod/@AfterMethod
- ✅ Lifecycle methods can access ITestContext for metadata
- ✅ Static @BeforeSuite/@AfterSuite run once for entire JVM

---

### 4. Assertion and Verification Strategy

#### BASIC: What are Assertions?

**Assertions** are statements that verify expected behavior. They're the heart of any test - without assertions, you're just executing code without verification.

```java
// Assertion = Verification Point
Assert.assertEquals(actual, expected);  // Verify equality
Assert.assertTrue(condition);           // Verify condition is true
```

**Two Assertion Strategies:**
1. **Hard Assert**: Test stops on first failure
2. **Soft Assert**: Test collects all failures, reports at end

#### INTERMEDIATE: Assertion Implementation

```java
// Internal mechanism of Assert.assertEquals
public class Assert {
    public static void assertEquals(Object actual, Object expected, String message) {
        if(!Objects.equals(actual, expected)) {
            // Create failure message
            String failureMessage = String.format(
                "%s: expected %s but was %s",
                message,
                expected,
                actual
            );
            
            // Throw AssertionError (stops test)
            throw new AssertionError(failureMessage);
        }
    }
}

// SoftAssert collects failures instead of throwing
public class SoftAssert {
    private List<AssertionError> failures = new ArrayList<>();
    
    public void assertEquals(Object actual, Object expected, String message) {
        try {
            Assert.assertEquals(actual, expected, message);
        } catch(AssertionError e) {
            // Collect failure instead of throwing
            failures.add(e);
        }
    }
    
    public void assertAll() {
        if(!failures.isEmpty()) {
            // Now throw combined error
            throw new AssertionError(failures.toString());
        }
    }
}
```

**Assertion Execution Flow:**
```
1. Actual value computed
2. Expected value known
3. Values compared
4. If equal → Pass (test continues)
5. If not equal:
   - Hard Assert: Throw error (test stops)
   - Soft Assert: Record error (test continues)
6. Result recorded
```

#### ADVANCED: Custom Assertion Framework

```java
public class PageAssertions {
    
    private WebElement element;
    
    public PageAssertions(WebElement element) {
        this.element = element;
    }
    
    // Fluent API for assertions
    public PageAssertions isVisible() {
        if(!element.isDisplayed()) {
            throw new AssertionError("Element not visible");
        }
        return this;
    }
    
    public PageAssertions isClickable() {
        if(!element.isEnabled()) {
            throw new AssertionError("Element not clickable");
        }
        return this;
    }
    
    public PageAssertions hasText(String expectedText) {
        String actualText = element.getText();
        if(!actualText.equals(expectedText)) {
            throw new AssertionError(
                String.format("Expected '%s' but got '%s'", 
                    expectedText, actualText)
            );
        }
        return this;
    }
    
    public PageAssertions hasAttribute(String attrName, String attrValue) {
        String actualValue = element.getAttribute(attrName);
        if(!actualValue.equals(attrValue)) {
            throw new AssertionError(
                String.format("Attribute '%s': expected '%s' but got '%s'",
                    attrName, attrValue, actualValue)
            );
        }
        return this;
    }
}

// Usage with fluent API
@Test
public void testButton() {
    WebElement button = driver.findElement(By.id("submit"));
    
    new PageAssertions(button)
        .isVisible()
        .isClickable()
        .hasText("Submit")
        .hasAttribute("type", "button");
}
```

**Keypoints:**
- ✅ Hard Assert throws immediately, stops test execution
- ✅ Soft Assert collects failures, reports together
- ✅ Custom assertions can be chained (fluent API)
- ✅ Assertion messages should be descriptive
- ✅ Use SoftAssert when testing multiple related conditions
- ✅ Assert early, assert often (fail fast principle)

---

### 5. Test Grouping and Organization

#### BASIC: Why Group Tests?

**Test Groups** allow logical organization and selective execution of tests. Instead of running all tests, you can run only smoke tests, or all critical tests, or exclude slow tests.

```java
@Test(groups = {"smoke"})
public void testLogin() {}

@Test(groups = {"smoke", "critical"})
public void testDashboard() {}

@Test(groups = {"regression"})
public void testComplexScenario() {}
```

**Use Cases:**
- Smoke tests before each build
- Critical tests for deployment gates
- Exclude slow tests for quick feedback
- Run only API tests, not UI tests

#### INTERMEDIATE: Group Execution Engine

```java
// How TestNG processes groups
public class GroupExecutionEngine {
    
    // 1. Discovery phase - collect all groups
    Map<String, List<TestMethod>> groupMap = new HashMap<>();
    
    // 2. Filter phase - apply include/exclude
    public List<TestMethod> filterTests(
            List<TestMethod> allTests,
            String[] includeGroups,
            String[] excludeGroups) {
        
        List<TestMethod> filtered = new ArrayList<>();
        
        for(TestMethod test : allTests) {
            boolean isIncluded = false;
            
            // Check if test belongs to any included group
            for(String group : test.getGroups()) {
                for(String includeGroup : includeGroups) {
                    if(group.equals(includeGroup)) {
                        isIncluded = true;
                        break;
                    }
                }
            }
            
            // Check if test is in excluded groups
            for(String excludeGroup : excludeGroups) {
                for(String group : test.getGroups()) {
                    if(group.equals(excludeGroup)) {
                        isIncluded = false;
                        break;
                    }
                }
            }
            
            if(isIncluded) {
                filtered.add(test);
            }
        }
        
        return filtered;
    }
}
```

**Group Filtering Logic:**
```
Include Pattern: (Group1 OR Group2) AND NOT ExcludeGroup

Example: @tags("smoke" OR "critical") AND NOT "slow"

Test belongs to: [smoke, database]
Result: INCLUDE (has smoke, not in slow)

Test belongs to: [regression, slow]
Result: EXCLUDE (not in smoke/critical, in slow)

Test belongs to: [critical, slow]
Result: EXCLUDE (even though critical, also slow)
```

#### ADVANCED: Dynamic Group Assignment

```java
public class DynamicGrouping {
    
    // Assign groups based on business logic
    private String getGroupForTest(String testName) {
        int testDuration = estimateDuration(testName);
        String environment = System.getenv("TEST_ENV");
        
        String groups = "regression";
        
        if(testDuration < 2000) {
            groups += ",smoke,quick";
        }
        
        if(testDuration > 30000) {
            groups += ",slow";
        }
        
        if("production".equals(environment)) {
            groups += ",prod-safe";
        }
        
        return groups;
    }
    
    private int estimateDuration(String testName) {
        // Estimate based on test name or metadata
        return 1000;
    }
}
```

**Advanced Grouping Patterns:**
```xml
<!-- Complex group expressions -->
<groups>
    <run>
        <!-- (smoke OR critical) AND NOT (slow OR flaky) -->
        <include name="smoke"/>
        <include name="critical"/>
        <exclude name="slow"/>
        <exclude name="flaky"/>
    </run>
</groups>
```

**Keypoints:**
- ✅ Groups are include/exclude filters on test execution
- ✅ One test can belong to multiple groups
- ✅ Groups are strings, case-sensitive
- ✅ Group filtering happens before test execution
- ✅ Dynamic group assignment possible via IAnnotationTransformer
- ✅ Groups enable flexible test suites for CI/CD pipelines

---

### 6. Data-Driven Testing Framework

#### BASIC: What is Data-Driven Testing?

**Data-Driven Testing** means running the same test logic with different input data. Instead of creating multiple test methods with hard-coded data, you create one test method and feed it different data.

```java
// Non-Data-Driven (Bad)
@Test
public void testLogin1() {
    login("user1@test.com", "pass123");
}

@Test
public void testLogin2() {
    login("user2@test.com", "pass456");
}

// Data-Driven (Good)
@Test(dataProvider = "loginData")
public void testLogin(String email, String password) {
    login(email, password);
}

@DataProvider
public Object[][] loginData() {
    return new Object[][] {
        {"user1@test.com", "pass123"},
        {"user2@test.com", "pass456"}
    };
}
```

**Benefits:**
- Reduced code duplication
- Easy to add new test cases
- Better test maintenance
- Clear separation of test logic and test data

#### INTERMEDIATE: DataProvider Execution Model

```java
public class DataProviderExecutionModel {
    
    // How TestNG processes DataProvider
    public void executeTestWithDataProvider() {
        
        // 1. Discover @Test method with dataProvider
        Method testMethod = getMethod("testLogin");
        String dataProviderName = testMethod.getAnnotation(Test.class)
            .dataProvider();
        
        // 2. Call @DataProvider method
        Method providerMethod = getMethod(dataProviderName);
        Object[][] testData = (Object[][]) providerMethod.invoke(null);
        
        // 3. For each data row, run test method
        for(Object[] dataRow : testData) {
            // Create new test instance
            Object testInstance = createTestInstance();
            
            // Run BeforeMethod
            runBeforeMethod(testInstance);
            
            // Run @Test with this data row
            testMethod.invoke(testInstance, dataRow);
            
            // Run AfterMethod
            runAfterMethod(testInstance);
            
            // Record result
            recordResult();
        }
    }
}

// Key Insight: Each data row = separate test invocation
// This means:
// - BeforeMethod runs for each row
// - Each row is independent
// - Failure of row 1 doesn't skip row 2
```

**DataProvider Return Types:**

```java
// Option 1: 2D Object Array
@DataProvider
public Object[][] getArrayData() {
    return new Object[][] {
        {1, 2, 3},
        {4, 5, 9}
    };
}

// Option 2: Iterator (more memory efficient)
@DataProvider
public Iterator<Object[]> getIteratorData() {
    List<Object[]> data = new ArrayList<>();
    data.add(new Object[]{1, 2, 3});
    data.add(new Object[]{4, 5, 9});
    return data.iterator();
}

// Option 3: IDataProvider interface (advanced)
public class CustomDataProvider implements IDataProvider<Object[]> {
    @Override
    public Iterator<Object[]> iterator() {
        // Custom data loading logic
        return null;
    }
}
```

#### ADVANCED: DataProvider with Complex Data Sources

```java
public class AdvancedDataProvider {
    
    // DataProvider with external data source
    @DataProvider(name = "externalData", parallel = true)
    public Object[][] getExternalData() throws Exception {
        
        // Could come from:
        // 1. Database
        List<Object[]> data = loadFromDatabase();
        
        // 2. API
        data.addAll(loadFromAPI());
        
        // 3. Excel
        data.addAll(loadFromExcel());
        
        // 4. JSON
        data.addAll(loadFromJSON());
        
        return data.toArray(new Object[0][0]);
    }
    
    @DataProvider(name = "parallelData", parallel = true)
    public Object[][] getParallelData() {
        // TestNG can parallelize DataProvider execution
        return new Object[][] {
            {"data1"},
            {"data2"},
            {"data3"}
        };
    }
    
    // Lazy-loaded DataProvider
    @DataProvider(name = "lazyData")
    public Iterator<Object[]> getLazyData() {
        return new Iterator<Object[]>() {
            private int count = 0;
            private int maxCount = 1000;
            
            @Override
            public boolean hasNext() {
                return count < maxCount;
            }
            
            @Override
            public Object[] next() {
                return new Object[]{
                    "row_" + count,
                    count++
                };
            }
        };
    }
}

// DataProvider with ITestContext
@DataProvider
public Object[][] getContextData(ITestContext context) {
    String testName = context.getCurrentXmlTest().getName();
    
    if("SmokeTests".equals(testName)) {
        return new Object[][]{{1, 2}};  // Less data for smoke
    } else {
        return new Object[][]{{1, 2}, {3, 4}, {5, 6}};  // More data for regression
    }
}
```

**Keypoints:**
- ✅ DataProvider executes for each row independently
- ✅ BeforeMethod/AfterMethod run for each row
- ✅ Iterator is more memory-efficient than 2D arrays
- ✅ DataProvider can be parallelized
- ✅ ITestContext available in DataProvider parameters
- ✅ Test name includes row index (testLogin[0], testLogin[1], etc.)

---

### 7. Test Dependencies and Execution Order

#### BASIC: Why Dependencies?

**Dependencies** control the execution order of tests. Sometimes test B should only run if test A succeeds. This creates a dependency relationship.

```java
@Test
public void testCreateUser() {
    // Create user
}

@Test(dependsOnMethods = {"testCreateUser"})
public void testUpdateUser() {
    // Can only work if user was created
}
```

**Key Difference from Priority:**
- **Priority**: Just ordering (test B runs after test A, but independently)
- **Dependency**: Test B is skipped if test A fails

#### INTERMEDIATE: Dependency Resolution

```java
public class DependencyResolution {
    
    // Build dependency graph
    public class DependencyGraph {
        
        // node = test method, edge = dependency
        Map<String, List<String>> dependencyMap = new HashMap<>();
        
        // Example graph:
        // testA depends on nothing
        // testB depends on testA
        // testC depends on testB
        // Creates chain: testA → testB → testC
        
        public void resolveDependencies() {
            
            // 1. Detect circular dependencies
            if(hasCircularDependency()) {
                throw new TestNGException("Circular dependency detected");
            }
            
            // 2. Topological sort
            List<String> executionOrder = topologicalSort();
            // Result: [testA, testB, testC]
            
            // 3. Mark for skipping if dependency fails
            for(String test : executionOrder) {
                List<String> dependencies = dependencyMap.get(test);
                for(String dependency : dependencies) {
                    if(testResult.get(dependency).isFailed()) {
                        skipTest(test);
                    }
                }
            }
        }
    }
}

// Execution flow with dependencies:
/*
@Test(priority=1)
public void testA() { /* creates user */}

@Test(priority=2, dependsOnMethods={"testA"})
public void testB() { /* updates user */}

@Test(priority=3, dependsOnMethods={"testB"})
public void testC() { /* deletes user */}

Execution:
- testA runs (SUCCESS)
  - testB runs (depends on testA, success)
    - testC runs (depends on testB, success)

If testA FAILS:
  - testB is SKIPPED (dependency failed)
    - testC is SKIPPED (testB was skipped)
*/
```

#### ADVANCED: Complex Dependency Scenarios

```java
public class ComplexDependencies {
    
    // Multiple dependencies
    @Test
    public void testA() {}
    
    @Test
    public void testB() {}
    
    @Test(dependsOnMethods = {"testA", "testB"})
    public void testC() {
        // Runs only if both testA AND testB pass
    }
    
    // Dependency on groups
    @Test(groups = "setup")
    public void setupUser() {}
    
    @Test(groups = "setup")
    public void setupDatabase() {}
    
    @Test(dependsOnGroups = "setup")
    public void testMainFlow() {
        // Runs after all tests in "setup" group
    }
    
    // Handling failures
    @Test(alwaysRun = true)
    public void cleanup() {
        // Runs even if dependencies failed
        // Used for cleanup that must run
    }
}
```

**Dependency Execution Strategies:**

```java
// Strategy 1: Strict dependency (most common)
@Test
public void testA() { }

@Test(dependsOnMethods = "testA")
public void testB() { }
// testB skipped if testA fails

// Strategy 2: Optional dependency (rare)
@Test(dependsOnMethods = "testA", alwaysRun = true)
public void testB() { }
// testB runs even if testA fails (cleanup pattern)

// Strategy 3: Group dependency
@Test(dependsOnGroups = "smoke")
public void testRegression() { }
// Runs after all smoke tests (any pass/fail)
```

**Keypoints:**
- ✅ dependsOnMethods = strict execution order
- ✅ Test is SKIPPED if dependency fails
- ✅ Circular dependencies are detected and prevented
- ✅ Topological sort determines execution order
- ✅ Multiple dependencies (AND logic)
- ✅ Group dependencies wait for entire group
- ✅ alwaysRun overrides dependency skip

---

## Annotations - Complete Guide

### @Test Annotation

**Basic Usage:**

```java
@Test
public void testLogin() {
    // Test code
}
```

**With Parameters:**

```java
@Test(
    enabled = true,           // Enable/disable test
    priority = 1,            // Execution order (lower = earlier)
    groups = {"smoke", "critical"},  // Test groups
    dependsOnMethods = {"testLogin"},  // Dependency
    timeoutMillis = 5000,    // Timeout in milliseconds
    invocationCount = 3,     // Run this test 3 times
    threadPoolSize = 2,      // Run in 2 threads (requires invocationCount)
    dataProvider = "loginData"  // Provide test data
)
public void testAdvanced() {
    // Complex test
}
```

### Lifecycle Annotations

**@BeforeSuite / @AfterSuite:**
```java
@BeforeSuite
public void setupSuite() {
    System.out.println("Before entire test suite");
    // Initialize test environment
    // Setup database
    // Start server
}

@AfterSuite
public void teardownSuite() {
    System.out.println("After entire test suite");
    // Cleanup resources
    // Stop server
    // Close connections
}
```

**@BeforeTest / @AfterTest:**
```java
@BeforeTest
public void setupTest() {
    System.out.println("Before <test> tag in XML");
}

@AfterTest
public void teardownTest() {
    System.out.println("After <test> tag in XML");
}
```

**@BeforeClass / @AfterClass:**
```java
public class LoginTests {
    
    private WebDriver driver;
    
    @BeforeClass
    public void setupClass() {
        System.out.println("Before all methods in class");
        driver = new ChromeDriver();
    }
    
    @AfterClass
    public void teardownClass() {
        System.out.println("After all methods in class");
        if(driver != null) {
            driver.quit();
        }
    }
    
    @Test
    public void testLogin() {
        // Use driver instance
    }
}
```

**@BeforeMethod / @AfterMethod:**
```java
public class ProductTests {
    
    private Product product;
    
    @BeforeMethod
    public void setupMethod() {
        System.out.println("Before each test method");
        product = new Product();
    }
    
    @AfterMethod
    public void teardownMethod() {
        System.out.println("After each test method");
        // Reset or cleanup
        product = null;
    }
    
    @Test
    public void testCreateProduct() {
        // product is fresh for this test
    }
    
    @Test
    public void testUpdateProduct() {
        // product is fresh for this test too
    }
}
```

### Lifecycle Execution Order

```java
public class LifecycleDemo {
    
    @BeforeSuite
    public void beforeSuite() { System.out.println("1. BeforeSuite"); }
    
    @BeforeTest
    public void beforeTest() { System.out.println("2. BeforeTest"); }
    
    @BeforeClass
    public static void beforeClass() { System.out.println("3. BeforeClass"); }
    
    @BeforeMethod
    public void beforeMethod() { System.out.println("4. BeforeMethod"); }
    
    @Test(priority = 1)
    public void testA() { System.out.println("5. Test A"); }
    
    @AfterMethod
    public void afterMethod() { System.out.println("6. AfterMethod"); }
    
    @BeforeMethod
    public void beforeMethodB() { System.out.println("7. BeforeMethod (for Test B)"); }
    
    @Test(priority = 2)
    public void testB() { System.out.println("8. Test B"); }
    
    @AfterMethod
    public void afterMethodB() { System.out.println("9. AfterMethod"); }
    
    @AfterClass
    public static void afterClass() { System.out.println("10. AfterClass"); }
    
    @AfterTest
    public void afterTest() { System.out.println("11. AfterTest"); }
    
    @AfterSuite
    public void afterSuite() { System.out.println("12. AfterSuite"); }
}

/* Output:
1. BeforeSuite
2. BeforeTest
3. BeforeClass
4. BeforeMethod
5. Test A
6. AfterMethod
7. BeforeMethod (for Test B)
8. Test B
9. AfterMethod
10. AfterClass
11. AfterTest
12. AfterSuite
*/
```

---

## Test Organization

### Project Structure

```
project/
├── src/
│   ├── main/
│   │   └── java/
│   │       └── com/example/
│   │           ├── User.java
│   │           ├── Product.java
│   │           └── Calculator.java
│   └── test/
│       └── java/
│           └── com/example/
│               ├── tests/
│               │   ├── UserTests.java
│               │   ├── ProductTests.java
│               │   └── CalculatorTests.java
│               ├── base/
│               │   └── BaseTest.java
│               ├── utils/
│               │   ├── TestDataProvider.java
│               │   └── TestUtils.java
│               └── listeners/
│                   └── TestListener.java
├── testng.xml
└── pom.xml
```

### Base Test Class

```java
public class BaseTest {
    
    protected WebDriver driver;
    protected Logger logger = LoggerFactory.getLogger(this.getClass());
    
    @BeforeSuite
    public void suiteSetup() {
        System.out.println("Setting up test environment");
    }
    
    @BeforeClass
    public void classSetup() {
        driver = new ChromeDriver();
        driver.manage().window().maximize();
    }
    
    @BeforeMethod
    public void methodSetup() {
        logger.info("Starting test: {}", getTestMethodName());
    }
    
    @AfterMethod
    public void methodTeardown(ITestResult result) {
        if(result.getStatus() == ITestResult.FAILURE) {
            logger.error("Test failed: {}", result.getThrowable());
            takeScreenshot();
        }
    }
    
    @AfterClass
    public void classTeardown() {
        if(driver != null) {
            driver.quit();
        }
    }
    
    @AfterSuite
    public void suiteTeardown() {
        System.out.println("Tearing down test environment");
    }
    
    protected void takeScreenshot() {
        TakesScreenshot ts = (TakesScreenshot) driver;
        File srcFile = ts.getScreenshotAs(OutputType.FILE);
        // Save file
    }
    
    protected String getTestMethodName() {
        return Thread.currentThread().getStackTrace()[2].getMethodName();
    }
}
```

### Extending Base Test

```java
public class LoginTests extends BaseTest {
    
    private LoginPage loginPage;
    
    @BeforeClass
    public void setup() {
        super.classSetup();
        loginPage = new LoginPage(driver);
    }
    
    @Test(priority = 1)
    public void testValidLogin() {
        loginPage.navigate();
        loginPage.login("test@example.com", "password");
        Assert.assertTrue(loginPage.isDashboardVisible());
    }
    
    @Test(priority = 2)
    public void testInvalidLogin() {
        loginPage.navigate();
        loginPage.login("invalid@example.com", "wrong");
        Assert.assertTrue(loginPage.isErrorMessageDisplayed());
    }
}
```

---

## Assertions and Verification

### TestNG Assert Class

**Equality Assertions:**

```java
// Exact equality
Assert.assertEquals(actual, expected);
Assert.assertEquals(actual, expected, "Custom message");

// Not equal
Assert.assertNotEquals(actual, expected);

// With delta for floating point
Assert.assertEquals(actual, expected, delta);
```

**Boolean Assertions:**

```java
// True/False
Assert.assertTrue(condition);
Assert.assertFalse(condition);

// With message
Assert.assertTrue(condition, "Expected true but got false");
```

**Null Assertions:**

```java
// Null checks
Assert.assertNull(object);
Assert.assertNotNull(object);
```

**Identity Assertions:**

```java
// Same reference
Assert.assertSame(object1, object2);
Assert.assertNotSame(object1, object2);
```

**Array Assertions:**

```java
// Array equality
int[] expected = {1, 2, 3};
int[] actual = {1, 2, 3};
Assert.assertEquals(actual, expected);
```

### SoftAssert (Non-stopping Assertions)

**Hard Assertions (Stop on Failure):**
```java
@Test
public void testHardAssert() {
    Assert.assertEquals(1, 2);  // Test stops here
    Assert.assertEquals(2, 2);  // This won't run
}
```

**Soft Assertions (Continue on Failure):**
```java
@Test
public void testSoftAssert() {
    SoftAssert softAssert = new SoftAssert();
    
    softAssert.assertEquals(1, 2);  // Fails but continues
    softAssert.assertEquals(2, 2);  // This runs
    softAssert.assertEquals("a", "b");  // Fails but continues
    
    // All failures are reported here
    softAssert.assertAll();
}
```

### Custom Assertions

```java
public class CustomAssertions {
    
    public static void assertWebElementVisible(WebElement element) {
        if(!element.isDisplayed()) {
            throw new AssertionError("Element is not visible");
        }
    }
    
    public static void assertWebElementEnabled(WebElement element) {
        if(!element.isEnabled()) {
            throw new AssertionError("Element is not enabled");
        }
    }
    
    public static void assertWebElementContainsText(WebElement element, String text) {
        if(!element.getText().contains(text)) {
            throw new AssertionError(
                String.format("Element does not contain text: %s. Actual: %s", 
                    text, element.getText())
            );
        }
    }
}

// Usage
@Test
public void testCustomAssertions() {
    WebElement button = driver.findElement(By.id("submit"));
    CustomAssertions.assertWebElementVisible(button);
    CustomAssertions.assertWebElementEnabled(button);
    CustomAssertions.assertWebElementContainsText(button, "Submit");
}
```

---

## Parameterized Testing

### @Parameters with XML

**testng.xml:**
```xml
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE suite SYSTEM "http://testng.org/testng-1.0.dtd">
<suite name="Login Suite">
    <test name="Login Test">
        <parameter name="username" value="user@example.com"/>
        <parameter name="password" value="password123"/>
        <classes>
            <class name="com.example.tests.LoginTests"/>
        </classes>
    </test>
</suite>
```

**Test Class:**
```java
public class LoginTests {
    
    @Test
    @Parameters({"username", "password"})
    public void testLogin(String username, String password) {
        LoginPage loginPage = new LoginPage();
        loginPage.login(username, password);
        Assert.assertTrue(loginPage.isDashboardVisible());
    }
}
```

### Multiple Parameter Sets

**testng.xml:**
```xml
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE suite SYSTEM "http://testng.org/testng-1.0.dtd">
<suite name="Multi-User Login Suite">
    <test name="User 1 Login">
        <parameter name="username" value="user1@example.com"/>
        <parameter name="password" value="pass123"/>
        <classes>
            <class name="com.example.tests.LoginTests"/>
        </classes>
    </test>
    
    <test name="User 2 Login">
        <parameter name="username" value="user2@example.com"/>
        <parameter name="password" value="pass456"/>
        <classes>
            <class name="com.example.tests.LoginTests"/>
        </classes>
    </test>
</suite>
```

---

## Data Providers

### Basic @DataProvider

```java
public class UserTests {
    
    // Define data provider
    @DataProvider(name = "loginData")
    public Object[][] getLoginData() {
        return new Object[][] {
            {"user1@test.com", "pass123", true},     // Valid user
            {"user2@test.com", "pass456", true},     // Valid user
            {"invalid@test.com", "wrong", false},    // Invalid
            {"", "", false}                           // Empty fields
        };
    }
    
    // Use data provider
    @Test(dataProvider = "loginData")
    public void testLogin(String email, String password, boolean expectedSuccess) {
        LoginPage loginPage = new LoginPage();
        loginPage.login(email, password);
        
        if(expectedSuccess) {
            Assert.assertTrue(loginPage.isDashboardVisible());
        } else {
            Assert.assertTrue(loginPage.isErrorMessageDisplayed());
        }
    }
}
```

### DataProvider with Iteration Methods

```java
public class ProductTests {
    
    @DataProvider(name = "productData")
    public Iterator<Object[]> getProductData() {
        List<Object[]> data = new ArrayList<>();
        data.add(new Object[]{"Laptop", 1000, "Electronics"});
        data.add(new Object[]{"Phone", 500, "Electronics"});
        data.add(new Object[]{"Book", 20, "Books"});
        return data.iterator();
    }
    
    @Test(dataProvider = "productData")
    public void testAddProduct(String name, double price, String category) {
        ProductService service = new ProductService();
        Product product = service.addProduct(name, price, category);
        Assert.assertNotNull(product.getId());
    }
}
```

### DataProvider with External Data

**From CSV File:**

```java
public class ExcelDataProvider {
    
    @DataProvider(name = "excelData")
    public Object[][] getDataFromExcel() throws IOException {
        // Read Excel file
        FileInputStream fis = new FileInputStream("testdata.xlsx");
        Workbook workbook = new XSSFWorkbook(fis);
        Sheet sheet = workbook.getSheetAt(0);
        
        int rowCount = sheet.getPhysicalNumberOfRows();
        Object[][] data = new Object[rowCount - 1][2];
        
        for(int i = 1; i < rowCount; i++) {
            Row row = sheet.getRow(i);
            data[i-1][0] = row.getCell(0).getStringCellValue();
            data[i-1][1] = row.getCell(1).getStringCellValue();
        }
        
        workbook.close();
        fis.close();
        
        return data;
    }
    
    @Test(dataProvider = "excelData")
    public void testWithExcelData(String username, String password) {
        LoginPage loginPage = new LoginPage();
        loginPage.login(username, password);
        Assert.assertTrue(loginPage.isDashboardVisible());
    }
}
```

**From Database:**

```java
public class DatabaseDataProvider {
    
    @DataProvider(name = "dbData")
    public Object[][] getDataFromDatabase() throws SQLException {
        List<Object[]> data = new ArrayList<>();
        
        Connection conn = DriverManager.getConnection(
            "jdbc:mysql://localhost:3306/testdb", 
            "user", 
            "password"
        );
        
        Statement stmt = conn.createStatement();
        ResultSet rs = stmt.executeQuery("SELECT username, password FROM test_users");
        
        while(rs.next()) {
            data.add(new Object[]{
                rs.getString("username"),
                rs.getString("password")
            });
        }
        
        conn.close();
        
        return data.toArray(new Object[0][0]);
    }
}
```

### DataProvider with Named Parameters

```java
public class NamedDataProvider {
    
    @DataProvider(name = "usersByRole")
    public Object[][] getUsersByRole() {
        return new Object[][] {
            {new User("admin@test.com", "admin", "ADMIN")},
            {new User("user@test.com", "user123", "USER")},
            {new User("guest@test.com", "guest", "GUEST")}
        };
    }
    
    @Test(dataProvider = "usersByRole")
    public void testUserPermissions(User user) {
        UserService service = new UserService();
        List<String> permissions = service.getPermissions(user);
        
        switch(user.getRole()) {
            case "ADMIN":
                Assert.assertTrue(permissions.contains("DELETE_USER"));
                break;
            case "USER":
                Assert.assertFalse(permissions.contains("DELETE_USER"));
                break;
        }
    }
}
```

---

## Test Dependencies

### dependsOnMethods

**Simple Dependency:**

```java
public class OrderTests {
    
    @Test
    public void testCreateUser() {
        User user = new User("test@test.com", "password");
        userService.save(user);
        Assert.assertNotNull(user.getId());
    }
    
    @Test(dependsOnMethods = {"testCreateUser"})
    public void testCreateOrder() {
        // This runs after testCreateUser
        Order order = new Order("user@test.com", "Laptop", 1000);
        orderService.save(order);
        Assert.assertNotNull(order.getId());
    }
}
```

**Multiple Dependencies:**

```java
public class CheckoutTests {
    
    @Test(priority = 1)
    public void testAddProduct() {
        cart.addProduct("Laptop");
    }
    
    @Test(priority = 2, dependsOnMethods = {"testAddProduct"})
    public void testCalculateTotal() {
        double total = cart.calculateTotal();
        Assert.assertGreater(total, 0);
    }
    
    @Test(priority = 3, 
          dependsOnMethods = {"testAddProduct", "testCalculateTotal"})
    public void testCheckout() {
        Order order = cart.checkout();
        Assert.assertNotNull(order);
    }
}
```

**Dependency on Group:**

```java
public class PaymentTests {
    
    @Test(groups = {"orderSetup"})
    public void testAddToCart() {
        cart.addProduct("item");
    }
    
    @Test(groups = {"orderSetup"})
    public void testApplyDiscount() {
        cart.applyDiscount("SAVE10");
    }
    
    @Test(dependsOnGroups = {"orderSetup"})
    public void testProcessPayment() {
        Payment payment = new Payment(cart.getTotal());
        Assert.assertTrue(payment.process());
    }
}
```

**Handling Dependency Failure:**

```java
public class DependencyFailureTests {
    
    @Test
    public void testRequiredSetup() {
        // If this fails, dependent tests skip
        throw new Exception("Setup failed");
    }
    
    @Test(dependsOnMethods = {"testRequiredSetup"})
    public void testSkippedTest() {
        // This is SKIPPED because dependency failed
    }
}
```

---

## Parallel Execution

### XML Configuration

**Serial Execution (Default):**

```xml
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE suite SYSTEM "http://testng.org/testng-1.0.dtd">
<suite name="Serial Suite" parallel="false">
    <test name="Test 1">
        <classes>
            <class name="com.example.tests.LoginTests"/>
        </classes>
    </test>
</suite>
```

**Parallel Tests:**

```xml
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE suite SYSTEM "http://testng.org/testng-1.0.dtd">
<suite name="Parallel Suite" parallel="tests" thread-count="4">
    <test name="Login Tests">
        <classes>
            <class name="com.example.tests.LoginTests"/>
        </classes>
    </test>
    
    <test name="Product Tests">
        <classes>
            <class name="com.example.tests.ProductTests"/>
        </classes>
    </test>
</suite>
```

**Parallel Methods:**

```xml
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE suite SYSTEM "http://testng.org/testng-1.0.dtd">
<suite name="Parallel Methods" parallel="methods" thread-count="5">
    <test name="All Tests">
        <classes>
            <class name="com.example.tests.AllTests"/>
        </classes>
    </test>
</suite>
```

**Parallel Classes:**

```xml
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE suite SYSTEM "http://testng.org/testng-1.0.dtd">
<suite name="Parallel Classes" parallel="classes" thread-count="3">
    <test name="Tests">
        <classes>
            <class name="com.example.tests.LoginTests"/>
            <class name="com.example.tests.ProductTests"/>
            <class name="com.example.tests.OrderTests"/>
        </classes>
    </test>
</suite>
```

### Parallel Execution Modes

| Mode | Parallel | Thread Count | Use Case |
|------|----------|-------------|----------|
| serial | false | N/A | Single-threaded, debugging |
| tests | tests | N/A | Run different `<test>` tags in parallel |
| methods | methods | N/A | Run @Test methods in parallel |
| classes | classes | N/A | Run test classes in parallel |
| instances | instances | N/A | Run test instances in parallel |

### Thread-Safe Test Implementation

```java
public class ThreadSafeTests extends BaseTest {
    
    private ThreadLocal<WebDriver> driver = new ThreadLocal<>();
    
    @BeforeMethod
    public void setupThread() {
        // Each thread gets its own WebDriver
        WebDriver threadDriver = new ChromeDriver();
        driver.set(threadDriver);
    }
    
    @AfterMethod
    public void teardownThread() {
        WebDriver threadDriver = driver.get();
        if(threadDriver != null) {
            threadDriver.quit();
        }
        driver.remove();
    }
    
    @Test(invocationCount = 5, threadPoolSize = 5)
    public void testMultiThreaded() {
        // Each invocation runs in separate thread with own driver
        WebDriver currentDriver = driver.get();
        currentDriver.navigate().to("http://example.com");
        Assert.assertTrue(currentDriver.getTitle().length() > 0);
    }
}
```

---

## Test Grouping

### Defining Groups

```java
public class CrossFunctionalTests {
    
    @Test(groups = {"smoke"})
    public void testLoginSmoke() {
        // Quick smoke test
    }
    
    @Test(groups = {"smoke", "critical"})
    public void testDashboardSmoke() {
        // Part of both smoke and critical
    }
    
    @Test(groups = {"regression"})
    public void testComplexScenario() {
        // Longer regression test
    }
    
    @Test(groups = {"slow"})
    public void testSlowOperation() {
        // Time-consuming test
    }
}
```

### Running Specific Groups

**testng.xml:**

```xml
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE suite SYSTEM "http://testng.org/testng-1.0.dtd">
<suite name="Test Suite">
    <test name="Smoke Tests">
        <groups>
            <run>
                <include name="smoke"/>
                <exclude name="slow"/>
            </run>
        </groups>
        <classes>
            <class name="com.example.tests.AllTests"/>
        </classes>
    </test>
</suite>
```

**Command Line:**

```bash
# Run smoke tests only
mvn test -Dgroups=smoke

# Run smoke and critical tests
mvn test -Dgroups=smoke,critical

# Exclude slow tests
mvn test -DexcludedGroups=slow

# Run (smoke OR critical) AND NOT slow
mvn test -Dgroups=smoke,critical -DexcludedGroups=slow
```

### Group Hierarchy

```java
public class HierarchicalGroupTests {
    
    @Test(groups = {"ui", "login"})
    public void testUILogin() {}
    
    @Test(groups = {"api", "login"})
    public void testAPILogin() {}
    
    @Test(groups = {"database", "user"})
    public void testUserDB() {}
    
    @Test(groups = {"smoke"})
    public void testSmoke() {}
}
```

**testng.xml with Group Inheritance:**

```xml
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE suite SYSTEM "http://testng.org/testng-1.0.dtd">
<suite name="Suite">
    <test name="Login Tests">
        <groups>
            <run>
                <include name="login"/>
            </run>
        </groups>
        <classes>
            <class name="com.example.tests.AllTests"/>
        </classes>
    </test>
</suite>
```

---

## Listeners and Reporters

### ITestListener Interface

```java
import org.testng.ITestListener;
import org.testng.ITestContext;
import org.testng.ITestResult;

public class CustomTestListener implements ITestListener {
    
    @Override
    public void onStart(ITestContext context) {
        System.out.println("Test suite started: " + context.getName());
    }
    
    @Override
    public void onTestStart(ITestResult result) {
        System.out.println("Test started: " + result.getMethod().getMethodName());
    }
    
    @Override
    public void onTestSuccess(ITestResult result) {
        System.out.println("✓ Test passed: " + result.getMethod().getMethodName());
        // Log success details
    }
    
    @Override
    public void onTestFailure(ITestResult result) {
        System.out.println("✗ Test failed: " + result.getMethod().getMethodName());
        // Take screenshot
        // Log error
        Throwable throwable = result.getThrowable();
        System.out.println("Error: " + throwable.getMessage());
    }
    
    @Override
    public void onTestSkipped(ITestResult result) {
        System.out.println("⊘ Test skipped: " + result.getMethod().getMethodName());
    }
    
    @Override
    public void onFinish(ITestContext context) {
        System.out.println("Test suite finished: " + context.getName());
        System.out.println("Total: " + context.getAllTestMethods().length);
        System.out.println("Passed: " + context.getPassedTests().size());
        System.out.println("Failed: " + context.getFailedTests().size());
        System.out.println("Skipped: " + context.getSkippedTests().size());
    }
}
```

### Register Listener

**In testng.xml:**

```xml
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE suite SYSTEM "http://testng.org/testng-1.0.dtd">
<suite name="Suite">
    <listeners>
        <listener class-name="com.example.listeners.CustomTestListener"/>
    </listeners>
    
    <test name="Test">
        <classes>
            <class name="com.example.tests.AllTests"/>
        </classes>
    </test>
</suite>
```

**In Code:**

```java
@Listeners(CustomTestListener.class)
public class TestsWithListener {
    
    @Test
    public void testSomething() {
        Assert.assertTrue(true);
    }
}
```

### Screenshot on Failure

```java
public class ScreenshotListener implements ITestListener {
    
    @Override
    public void onTestFailure(ITestResult result) {
        Object testClass = result.getInstance();
        WebDriver driver = getWebDriver(testClass);
        
        if(driver != null) {
            takeScreenshot(driver, result.getMethod().getMethodName());
        }
    }
    
    private void takeScreenshot(WebDriver driver, String testName) {
        try {
            TakesScreenshot ts = (TakesScreenshot) driver;
            File srcFile = ts.getScreenshotAs(OutputType.FILE);
            File destFile = new File("screenshots/" + testName + ".png");
            FileUtils.copyFile(srcFile, destFile);
            System.out.println("Screenshot saved: " + destFile.getAbsolutePath());
        } catch(IOException e) {
            System.out.println("Failed to take screenshot: " + e.getMessage());
        }
    }
    
    private WebDriver getWebDriver(Object testClass) {
        try {
            Field field = testClass.getClass().getDeclaredField("driver");
            field.setAccessible(true);
            return (WebDriver) field.get(testClass);
        } catch(NoSuchFieldException | IllegalAccessException e) {
            return null;
        }
    }
}
```

### Custom Reporting

```java
public class ExtentReportListener implements ITestListener {
    
    private ExtentReports extentReports;
    private ExtentTest extentTest;
    
    @Override
    public void onStart(ITestContext context) {
        extentReports = new ExtentReports(
            "test-output/ExtentReports.html", 
            true
        );
    }
    
    @Override
    public void onTestStart(ITestResult result) {
        String methodName = result.getMethod().getMethodName();
        extentTest = extentReports.startTest(methodName);
    }
    
    @Override
    public void onTestSuccess(ITestResult result) {
        extentTest.log(LogStatus.PASS, "Test passed");
        extentReports.endTest(extentTest);
    }
    
    @Override
    public void onTestFailure(ITestResult result) {
        Throwable throwable = result.getThrowable();
        extentTest.log(LogStatus.FAIL, "Test failed: " + throwable.getMessage());
        extentReports.endTest(extentTest);
    }
    
    @Override
    public void onFinish(ITestContext context) {
        extentReports.flush();
        extentReports.close();
    }
}
```

---

## Advanced Topics

### Test Retry Logic

```java
public class RetryAnalyzer implements IRetryAnalyzer {
    
    private int retryCount = 0;
    private static final int MAX_RETRIES = 2;
    
    @Override
    public boolean retry(ITestResult result) {
        if(retryCount < MAX_RETRIES) {
            retryCount++;
            System.out.println("Retrying test: " + 
                result.getMethod().getMethodName() + 
                " (Attempt " + retryCount + ")");
            return true;
        }
        return false;
    }
}

@Test(retryAnalyzer = RetryAnalyzer.class)
public void testWithRetry() {
    // If this fails, it will be retried up to 2 times
    Assert.assertTrue(true);
}
```

### Conditional Test Execution

```java
public class SkipTestAnalyzer implements IAnnotationTransformer {
    
    @Override
    public void transform(ITestAnnotation annotation, Class testClass,
            Constructor testConstructor, Method testMethod) {
        
        if(testMethod.isAnnotationPresent(SkipIfOS.class)) {
            SkipIfOS skipIfOS = testMethod.getAnnotation(SkipIfOS.class);
            String os = System.getProperty("os.name").toLowerCase();
            
            if(os.contains(skipIfOS.value())) {
                annotation.setEnabled(false);
            }
        }
    }
}

@Retention(RetentionPolicy.RUNTIME)
@Target(ElementType.METHOD)
public @interface SkipIfOS {
    String value();
}

@Test
@SkipIfOS("windows")
public void testOnlyOnLinux() {
    // Skipped on Windows
}
```

### TestNG with Reports

**pom.xml - Add Reporting Dependencies:**

```xml
<dependency>
    <groupId>com.aventstack</groupId>
    <artifactId>extentreports</artifactId>
    <version>5.0.9</version>
</dependency>
```

**Generate HTML Report:**

```bash
# TestNG creates default report in test-output/
# Access: test-output/index.html

# For ExtentReports:
# Access: test-output/ExtentReports.html
```

---

## Selenium Integration

### Selenium with TestNG

**Page Object Model:**

```java
public class LoginPage {
    
    private WebDriver driver;
    
    // Locators
    private By emailInput = By.id("email");
    private By passwordInput = By.id("password");
    private By loginButton = By.css("button[type='submit']");
    private By errorMessage = By.className("error");
    
    public LoginPage(WebDriver driver) {
        this.driver = driver;
    }
    
    public void navigate() {
        driver.navigate().to("http://localhost/login");
    }
    
    public void login(String email, String password) {
        driver.findElement(emailInput).clear();
        driver.findElement(emailInput).sendKeys(email);
        driver.findElement(passwordInput).clear();
        driver.findElement(passwordInput).sendKeys(password);
        driver.findElement(loginButton).click();
    }
    
    public boolean isDashboardVisible() {
        return driver.findElements(By.className("dashboard")).size() > 0;
    }
    
    public boolean isErrorMessageDisplayed() {
        return driver.findElements(errorMessage).size() > 0;
    }
}
```

**Test with POM:**

```java
public class LoginTests extends BaseTest {
    
    private LoginPage loginPage;
    
    @BeforeClass
    public void setupPage() {
        super.classSetup();
        loginPage = new LoginPage(driver);
    }
    
    @Test(priority = 1)
    public void testValidLogin() {
        loginPage.navigate();
        loginPage.login("test@example.com", "password123");
        Assert.assertTrue(loginPage.isDashboardVisible());
    }
    
    @Test(priority = 2)
    public void testInvalidLogin() {
        loginPage.navigate();
        loginPage.login("invalid@example.com", "wrong");
        Assert.assertTrue(loginPage.isErrorMessageDisplayed());
    }
}
```

---

## Best Practices

### 1. Naming Conventions

```java
// ✅ GOOD: Descriptive test method names
@Test
public void testValidUserLoginSuccessfully() {}

@Test
public void testLoginWithInvalidCredentialsShowsError() {}

@Test
public void testAddProductToCartIncrementsTotal() {}

// ❌ BAD: Non-descriptive names
@Test
public void test1() {}

@Test
public void testSomething() {}
```

### 2. One Assertion Per Test (Or SoftAssert)

```java
// ✅ GOOD: Focused test with one primary assertion
@Test
public void testLoginSuccess() {
    loginPage.login("user@test.com", "password");
    Assert.assertTrue(dashboardPage.isVisible());
}

// ✅ GOOD: Multiple assertions with SoftAssert
@Test
public void testUserProfile() {
    SoftAssert softAssert = new SoftAssert();
    User user = getUserDetails();
    
    softAssert.assertEquals(user.getName(), "John");
    softAssert.assertEquals(user.getEmail(), "john@test.com");
    softAssert.assertTrue(user.isActive());
    
    softAssert.assertAll();
}

// ❌ BAD: Multiple unrelated assertions
@Test
public void testEverything() {
    loginPage.login("user", "pass");
    Assert.assertTrue(dashboardPage.isVisible());
    
    cartPage.addProduct("Laptop");
    Assert.assertTrue(cartPage.getCount() > 0);
    
    checkoutPage.checkout();
    Assert.assertTrue(orderPage.orderExists());
}
```

### 3. Avoid Test Dependencies

```java
// ❌ BAD: Test depends on order
@Test(priority = 1)
public void testCreateUser() { }

@Test(priority = 2)
public void testUpdateUser() {
    // Depends on testCreateUser
}

// ✅ GOOD: Each test is independent
@Test
public void testCreateUser() {
    User user = userService.create("John", "john@test.com");
    Assert.assertNotNull(user.getId());
}

@Test
public void testUpdateUser() {
    User user = userService.create("John", "john@test.com");
    user.setName("Jane");
    User updated = userService.update(user);
    Assert.assertEquals(updated.getName(), "Jane");
}
```

### 4. Proper Resource Management

```java
public class ResourceManagementTests {
    
    private WebDriver driver;
    private DatabaseConnection dbConn;
    
    @BeforeClass
    public void setupResources() {
        driver = new ChromeDriver();
        dbConn = new DatabaseConnection();
    }
    
    @AfterClass
    public void cleanupResources() {
        // Always cleanup even if test fails
        if(driver != null) {
            driver.quit();
        }
        if(dbConn != null) {
            dbConn.close();
        }
    }
    
    @Test
    public void testWithResources() {
        // Use driver and dbConn
    }
}
```

### 5. Meaningful Error Messages

```java
// ✅ GOOD: Descriptive error message
Assert.assertEquals(actualValue, expectedValue, 
    String.format("Expected dashboard to show user name '%s' but got '%s'",
        expectedValue, actualValue));

// ❌ BAD: Generic error message
Assert.assertEquals(actualValue, expectedValue);
```

### 6. Use Data Providers for Multiple Data Sets

```java
// ✅ GOOD: DataProvider for different scenarios
@Test(dataProvider = "loginData")
public void testLogin(String email, String password, boolean shouldSucceed) {
    loginPage.login(email, password);
    boolean isLoggedIn = dashboardPage.isVisible();
    Assert.assertEquals(isLoggedIn, shouldSucceed);
}

@DataProvider
public Object[][] loginData() {
    return new Object[][] {
        {"user@test.com", "password", true},
        {"invalid@test.com", "wrong", false}
    };
}

// ❌ BAD: Multiple similar tests
@Test
public void testValidLogin() {
    loginPage.login("user@test.com", "password");
    Assert.assertTrue(dashboardPage.isVisible());
}

@Test
public void testInvalidLogin() {
    loginPage.login("invalid@test.com", "wrong");
    Assert.assertFalse(dashboardPage.isVisible());
}
```

---

## Real-World Examples

### Complete E-Commerce Test Suite

```java
public class ECommerceTests extends BaseTest {
    
    private ProductPage productPage;
    private CartPage cartPage;
    private CheckoutPage checkoutPage;
    
    @BeforeClass
    public void setupPages() {
        super.classSetup();
        productPage = new ProductPage(driver);
        cartPage = new CartPage(driver);
        checkoutPage = new CheckoutPage(driver);
    }
    
    @Test(groups = {"smoke"})
    public void testProductSearch() {
        productPage.navigate();
        productPage.searchProduct("Laptop");
        Assert.assertTrue(productPage.getResultCount() > 0);
    }
    
    @Test(groups = {"smoke"})
    public void testAddProductToCart() {
        productPage.navigate();
        productPage.searchProduct("Laptop");
        productPage.selectProduct(0);
        productPage.addToCart();
        
        SoftAssert softAssert = new SoftAssert();
        softAssert.assertTrue(productPage.isAddedToCartMessageVisible());
        softAssert.assertEquals(cartPage.getItemCount(), 1);
        softAssert.assertAll();
    }
    
    @Test(groups = {"critical"}, 
          dataProvider = "checkoutData",
          dependsOnMethods = {"testAddProductToCart"})
    public void testCheckout(String firstName, String lastName, String email) {
        checkoutPage.navigate();
        checkoutPage.fillBillingInfo(firstName, lastName, email);
        checkoutPage.selectPaymentMethod("CREDIT_CARD");
        checkoutPage.placeOrder();
        
        Assert.assertTrue(checkoutPage.isOrderConfirmationVisible());
    }
    
    @DataProvider(name = "checkoutData")
    public Object[][] checkoutData() {
        return new Object[][] {
            {"John", "Doe", "john@example.com"},
            {"Jane", "Smith", "jane@example.com"}
        };
    }
}
```

### Complete User Management Test Suite

```java
public class UserManagementTests extends BaseTest {
    
    private UserService userService;
    private UserPage userPage;
    
    @BeforeClass
    public void setup() {
        super.classSetup();
        userService = new UserService();
        userPage = new UserPage(driver);
    }
    
    @Test(priority = 1, groups = {"smoke"})
    public void testCreateUser() {
        User user = userService.createUser("john@test.com", "password");
        Assert.assertNotNull(user.getId());
    }
    
    @Test(priority = 2, 
          dependsOnMethods = {"testCreateUser"},
          groups = {"critical"})
    public void testUserLogin() {
        userPage.navigate();
        userPage.login("john@test.com", "password");
        Assert.assertTrue(userPage.isDashboardVisible());
    }
    
    @Test(groups = {"regression"},
          dataProvider = "userRoles")
    public void testUserRolePermissions(String role, List<String> expectedPermissions) {
        List<String> actualPermissions = userService.getPermissions(role);
        Assert.assertEquals(actualPermissions, expectedPermissions);
    }
    
    @DataProvider(name = "userRoles")
    public Object[][] userRoles() {
        return new Object[][] {
            {"ADMIN", Arrays.asList("CREATE_USER", "DELETE_USER", "EDIT_USER")},
            {"USER", Arrays.asList("EDIT_PROFILE", "VIEW_DASHBOARD")},
            {"GUEST", Arrays.asList("VIEW_DASHBOARD")}
        };
    }
}
```

---

## Common Issues and Solutions

### Issue 1: Test Timeout

**Problem:**
```java
@Test(timeoutMillis = 1000)
public void slowTest() {
    Thread.sleep(2000);  // Exceeds timeout!
}
```

**Solution:**
```java
@Test(timeoutMillis = 5000)  // Increase timeout
public void slowTest() {
    driver.wait(Duration.ofSeconds(3));
}
```

### Issue 2: Flaky Tests

**Problem:**
```java
@Test
public void flakyTest() {
    // Element might not be loaded yet
    driver.findElement(By.id("myElement")).click();
}
```

**Solution:**
```java
@Test
public void reliableTest() {
    // Wait for element to be clickable
    WebDriverWait wait = new WebDriverWait(driver, Duration.ofSeconds(5));
    wait.until(ExpectedConditions.elementToBeClickable(By.id("myElement")))
        .click();
}
```

### Issue 3: Resource Leaks

**Problem:**
```java
@BeforeMethod
public void setup() {
    driver = new ChromeDriver();
}

// @AfterMethod missing!
```

**Solution:**
```java
@BeforeMethod
public void setup() {
    driver = new ChromeDriver();
}

@AfterMethod
public void teardown() {
    if(driver != null) {
        driver.quit();
    }
}
```

---

## Summary

TestNG is a powerful testing framework that provides:
- ✅ Flexible annotations and lifecycle management
- ✅ Powerful data-driven testing capabilities
- ✅ Test grouping and prioritization
- ✅ Parallel execution support
- ✅ Comprehensive reporting and logging
- ✅ Integration with Selenium and other tools
- ✅ Listener mechanisms for custom functionality

**Key Takeaways:**
1. Always use proper lifecycle annotations
2. Keep tests independent and isolated
3. Use DataProviders for data-driven testing
4. Implement listeners for advanced reporting
5. Configure parallel execution for speed
6. Follow naming conventions and best practices
7. Use SoftAssert for multiple assertions
8. Manage resources properly in setup/teardown
9. Avoid test dependencies when possible
10. Use meaningful error messages for debugging
